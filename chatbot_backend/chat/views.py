from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
import logging
import json
import openai
import anthropic
from groq import Groq
from django.conf import settings
from bs4 import BeautifulSoup
logger = logging.getLogger(__name__)
import re
import json
import logging

def fetch_and_clean_url(url, timeout=10):
    """
    ì£¼ì–´ì§„ URLì˜ HTMLì„ ìš”ì²­í•´, ìŠ¤í¬ë¦½íŠ¸Â·ìŠ¤íƒ€ì¼ ì œê±° í›„ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    resp = requests.get(url, timeout=timeout)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "html.parser")
    # ìŠ¤í¬ë¦½íŠ¸Â·ìŠ¤íƒ€ì¼Â·ë„¤ë¹„ê²Œì´ì…˜ íƒœê·¸ ì œê±°
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()

    text = soup.get_text(separator="\n")
    # ë¹ˆ ì¤„ ì œê±°
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return "\n".join(lines)

# Add this function to your ChatBot class or as a standalone function
def sanitize_and_parse_json(text, selected_models, responses):
    """
    Sanitize and parse the JSON response from AI models.
    Handles various edge cases and formatting issues.
    """
    import re
    import json
    import logging
    
    logger = logging.getLogger(__name__)
    
    try:
        # Step 1: Basic cleanup
        text = text.strip()
        
        # Step 2: Handle code blocks
        if text.startswith('```json') and '```' in text:
            text = re.sub(r'```json(.*?)```', r'\1', text, flags=re.DOTALL).strip()
        elif text.startswith('```') and text.endswith('```'):
            text = text[3:-3].strip()
            
        # Step 3: Extract JSON object if embedded in other text
        json_pattern = r'({[\s\S]*})'
        json_matches = re.findall(json_pattern, text)
        if json_matches:
            text = json_matches[0]
            
        # Step 4: Handle escaped backslashes in the text
        # First identify all occurrences of escaped backslashes followed by characters like "_"
        text = re.sub(r'\\([_"])', r'\1', text)
        
        # Step 5: Attempt to parse the JSON
        result = json.loads(text)
        
        # Ensure the required fields exist
        required_fields = ["preferredModel", "best_response", "analysis", "reasoning"]
        for field in required_fields:
            if field not in result:
                if field == "best_response" and "bestResponse" in result:
                    result["best_response"] = result["bestResponse"]
                else:
                    result[field] = "" if field != "analysis" else {}
        
        return result
        
    except Exception as e:
        logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
        logger.error(f"ì›ë³¸ í…ìŠ¤íŠ¸: {text[:200]}..." if len(text) > 200 else text)
        
        # Advanced recovery attempt for malformed JSON
        try:
            # Remove problematic escaped characters
            fixed_text = text.replace("\\_", "_").replace('\\"', '"')
            
            # Try to fix common issues with JSON (missing quotes, commas, etc.)
            fixed_text = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', fixed_text)
            fixed_text = re.sub(r':\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*([,}])', r':"\1"\2', fixed_text)
            
            # Handle unclosed strings
            for match in re.finditer(r':\s*"([^"\\]*(\\.[^"\\]*)*)', fixed_text):
                if not re.search(r':\s*"([^"\\]*(\\.[^"\\]*)*)"', match.group(0)):
                    pos = match.end()
                    fixed_text = fixed_text[:pos] + '"' + fixed_text[pos:]
            
            result = json.loads(fixed_text)
            logger.info("âœ… Recovered JSON after fixing format issues")
            return result
        except:
            # Last resort: construct a sensible fallback response
            error_analysis = {}
            for model in selected_models:
                model_lower = model.lower()
                error_analysis[model_lower] = {"ì¥ì ": "ë¶„ì„ ì‹¤íŒ¨", "ë‹¨ì ": "ë¶„ì„ ì‹¤íŒ¨"}
            
            # Find the largest response to use as best_response
            best_response = ""
            if responses:
                best_response = max(responses.values(), key=len) 
            
            return {
                "preferredModel": "FALLBACK",
                "best_response": best_response,
                "analysis": error_analysis,
                "reasoning": "ì‘ë‹µ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            }

# src/chatbot_backend/chat/bot.py

# import logging
# import openai
# import anthropic
# import base64
# import imghdr
# from groq import Groq
# from io import BytesIO

# logger = logging.getLogger(__name__)

# class ChatBot:
#     def __init__(self, api_key, model, api_type):
#         self.conversation_history = []
#         self.api_type = api_type
#         self.api_key = api_key

#         # Anthropic ë©€í‹°ëª¨ë‹¬ì€ Opus ëª¨ë¸ ê¶Œì¥
#         if api_type == 'anthropic' and not model.startswith('claude-3-opus-20240229'):
#             logger.info(f"Overriding Anthropic model '{model}' to 'claude-3-opus-20240229' for image support")
#             self.model = 'claude-3-opus-20240229'
#         else:
#             self.model = model

#         if api_type == 'openai':
#             openai.api_key = api_key
#         elif api_type == 'anthropic':
#             # Anthropic Python SDK ì´ˆê¸°í™”
#             self.client = anthropic.Client(api_key=api_key)
#         elif api_type == 'groq':
#             self.client = Groq(api_key=api_key)
#         else:
#             raise ValueError(f"Unsupported api_type: {api_type}")

#     def chat(self, prompt=None, user_input=None, image_file=None, analysis_mode=None, user_language=None):
#         """
#         prompt       : í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (í‚¤ì›Œë“œ)
#         user_input   : í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ìœ„ì¹˜ ì¸ì)
#         image_file   : íŒŒì¼ ê°ì²´ (BytesIO, InMemoryUploadedFile ë“±)
#         analysis_mode: 'describe'|'ocr'|'objects'
#         user_language: 'ko','en'
#         """
#         text = prompt if prompt is not None else user_input
#         try:
#             logger.info(f"[{self.api_type}] Received input: {text}")

#             # ëª¨ë¸ë³„ í˜¸ì¶œ
#             if self.api_type == 'openai':
#                 # GPT-4 Vision ì§€ì›
#                 params = {
#                     'model': self.model,
#                     'messages': self.conversation_history + [{"role": "user", "content": text}],
#                     'temperature': 0.7,
#                     'max_tokens': 1024
#                 }
#                 if image_file:
#                     params['files'] = [("image", image_file)]
#                 resp = openai.ChatCompletion.create(**params)
#                 assistant_response = resp.choices[0].message.content

#             elif self.api_type == 'anthropic':
#                 # Claude 3 Opus: ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ì§€ì› via Messages API
#                 messages = []
#                 # í† í° ìˆ˜ ì„¤ì •
#                 max_tokens = 1024 if image_file else 4096
#                 if image_file:
#                     # ì´ë¯¸ì§€ ë°”ì´ë„ˆë¦¬ ì½ê¸° ë° ë¯¸ë””ì–´ íƒ€ì… ìë™ ê°ì§€
#                     image_file.seek(0)
#                     data_bytes = image_file.read()
#                     ext = imghdr.what(None, h=data_bytes) or 'jpeg'
#                     mime_map = {
#                         'jpeg': 'image/jpeg', 'jpg': 'image/jpeg',
#                         'png': 'image/png', 'gif': 'image/gif',
#                         'bmp': 'image/bmp', 'webp': 'image/webp'
#                     }
#                     media_type = mime_map.get(ext, 'image/jpeg')
#                     b64 = base64.b64encode(data_bytes).decode('utf-8')

#                     # ì´ë¯¸ì§€ ë¸”ë¡ê³¼ í…ìŠ¤íŠ¸ ë¸”ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ êµ¬ì„±
#                     image_block = {
#                         'type': 'image',
#                         'source': {'type': 'base64', 'media_type': media_type, 'data': b64}
#                     }
#                     text_block = {'type': 'text', 'text': text}
#                     content_blocks = [image_block, text_block]

#                     # ë‹¨ì¼ ë©”ì‹œì§€ì— ë¸”ë¡ ë¦¬ìŠ¤íŠ¸ ì „ë‹¬
#                     messages.append({'role': 'user', 'content': content_blocks})
#                 else:
#                     # í…ìŠ¤íŠ¸ ì „ìš© ë©”ì‹œì§€
#                     messages.append({'role': 'user', 'content': [{'type': 'text', 'text': text}]})

#                 # Messages API í˜¸ì¶œ
#                 resp = self.client.messages.create(
#                     model=self.model,
#                     messages=messages,
#                     max_tokens=max_tokens
#                 )
#                 # ì‘ë‹µ ë¸”ë¡ì—ì„œ í…ìŠ¤íŠ¸ë§Œ í•©ì¹˜ê¸°
#                 assistant_response = ' '.join(getattr(block, 'text', '') for block in resp.content)

#             elif self.api_type == 'groq':
#                 # Groq Chat API
#                 resp = self.client.chat.completions.create(
#                     model=self.model,
#                     messages=self.conversation_history + [{"role": "user", "content": text}],
#                     temperature=0.7,
#                     max_tokens=1024
#                 )
#                 assistant_response = resp.choices[0].message.content

#             else:
#                 raise ValueError(f"Unsupported api_type: {self.api_type}")

#             # ì‘ë‹µ ê¸°ë¡ ë° ë°˜í™˜
#             self.conversation_history.append({"role": "assistant", "content": assistant_response})
#             logger.info(f"[{self.api_type}] Response: {assistant_response[:100]}...")
#             return assistant_response

#         except Exception as e:
#             logger.error(f"Error in chat method ({self.api_type}): {e}", exc_info=True)
#             raise



class ChatBot:
   def __init__(self, api_key, model, api_type):
       self.conversation_history = []
       self.model = model
       self.api_type = api_type
       self.api_key = api_key
       
       if api_type == 'openai':
           openai.api_key = api_key
       elif api_type == 'anthropic':
           self.client = anthropic.Anthropic(api_key=api_key)
       elif api_type == 'groq':
           self.client = Groq(api_key=api_key)
   
   def chat(self, user_input, image_file=None, analysis_mode=None, user_language=None):
       try:
           logger.info(f"Processing chat request for {self.api_type}")
           logger.info(f"User input: {user_input}")
           
           # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
           if image_file:
               # ì˜ˆì‹œë¡œ system ë©”ì‹œì§€ì— ëª¨ë“œì™€ ì–¸ì–´ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤
               self.conversation_history = [{
                   "role": "system",
                   "content": f"ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë“œ: {analysis_mode}, ì‘ë‹µ ì–¸ì–´: {user_language}"
               }]
               messages = [
                   {"role": "user", "content": user_input}
               ]
           else:
               self.conversation_history.append({"role": "user", "content": user_input})
               messages = self.conversation_history

        #    self.conversation_history.append({"role": "user", "content": user_input})
           
           try:
               if self.api_type == 'openai':
                   response = openai.ChatCompletion.create(
                       model=self.model,
                       messages=self.conversation_history,
                       temperature=0.7,
                       max_tokens=1024
                   )
                   assistant_response = response['choices'][0]['message']['content']
                   # chat ë©”ì†Œë“œì˜ anthropic ë¶€ë¶„ ìˆ˜ì •
               elif self.api_type == 'anthropic':
                    try:
                        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ ì°¾ê¸°
                        system_message = next((msg['content'] for msg in self.conversation_history 
                                            if msg['role'] == 'system'), '')
                        
                        # ì‚¬ìš©ì ë©”ì‹œì§€ ì°¾ê¸°
                        user_content = next((msg['content'] for msg in self.conversation_history 
                                        if msg['role'] == 'user'), '')

                        message = self.client.messages.create(
                            model=self.model,
                            max_tokens=4096,
                            temperature=0,
                            system=system_message,  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ë¥¼ system íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬
                            messages=[{
                                "role": "user",
                                "content": user_content
                            }]
                        )
                        assistant_response = message.content[0].text
                        logger.info(f"Anthropic response with system message: {system_message[:100]}")
                        
                    except Exception as e:
                        logger.error(f"Anthropic API error: {str(e)}")
                        raise

                # analyze_responses ë©”ì†Œë“œì˜ anthropic ë¶€ë¶„ ìˆ˜ì •
               
               elif self.api_type == 'anthropic':
                   messages = []
                   for msg in self.conversation_history:
                       if msg["role"] != "system":
                           messages.append({
                               "role": msg["role"],
                               "content": msg["content"]
                           })
                   
                   message = self.client.messages.create(
                       model=self.model,
                       max_tokens=4096,
                       temperature=0,
                    #    messages=messages
                   )
                   assistant_response = message.content[0].text
                   
                   
               elif self.api_type == 'groq':
                   response = self.client.chat.completions.create(
                       model=self.model,
                       messages=self.conversation_history,
                       temperature=0.7,
                       max_tokens=1024
                   )
                   assistant_response = response.choices[0].message.content
               
               # ì‘ë‹µ ê¸°ë¡
               self.conversation_history.append({
                   "role": "assistant",
                   "content": assistant_response
               })
               
               logger.info(f"Generated response: {assistant_response[:100]}...")
               return assistant_response
               
           except Exception as e:
               logger.error(f"API error in {self.api_type}: {str(e)}", exc_info=True)
               raise
               
       except Exception as e:
           logger.error(f"Error in chat method: {str(e)}", exc_info=True)
           raise

   def analyze_responses(self, responses, query, user_language, selected_models):


            try:
                logger.info("\n" + "="*100)
                logger.info("ğŸ“Š ë¶„ì„ ì‹œì‘")
                logger.info(f"ğŸ¤– ë¶„ì„ ìˆ˜í–‰ AI: {self.api_type.upper()}")
                logger.info(f"ğŸ” ì„ íƒëœ ëª¨ë¸ë“¤: {', '.join(selected_models)}")
                logger.info("="*100)

                # ì„ íƒëœ ëª¨ë¸ë“¤ë§Œ ë¶„ì„ì— í¬í•¨
                responses_section = ""
                analysis_section = ""
                
                for model in selected_models:
                    model_lower = model.lower()
                    responses_section += f"\n{model.upper()} ì‘ë‹µ: ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì‘ì„± {responses.get(model_lower, 'ì‘ë‹µ ì—†ìŒ')}"
                    
                    analysis_section += f"""
                            "{model_lower}": {{
                                "ì¥ì ": "ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì‘ì„± {model.upper()} ë‹µë³€ì˜ ì¥ì ",
                                "ë‹¨ì ": "ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì‘ì„± {model.upper()} ë‹µë³€ì˜ ë‹¨ì "
                            }}{"," if model_lower != selected_models[-1].lower() else ""}"""

                # The prompt remains the same
                analysis_prompt = f"""ë‹¤ìŒì€ ë™ì¼í•œ ì§ˆë¬¸ì— ëŒ€í•œ {len(selected_models)}ê°€ì§€ AIì˜ ì‘ë‹µì„ ë¶„ì„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
                        ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ëŠ” '{user_language}'ì…ë‹ˆë‹¤.
                        ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ìµœì ì˜ ë‹µì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
                        ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì¥ì ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
                        ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ë‹¨ì ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
                        ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ë¶„ì„ ê·¼ê±°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

                        ì§ˆë¬¸: {query}
                        {responses_section}

                        [ìµœì ì˜ ì‘ë‹µì„ ë§Œë“¤ ë•Œ ê³ ë ¤í•  ì‚¬í•­]

                        ëª¨ë“  AIì˜ ë‹µë³€ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì ì˜ ë‹µë³€ìœ¼ë¡œ ë°˜ë“œì‹œ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.

                        ì¦‰, ê¸°ì¡´ AIì˜ ë‹µë³€ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ì•ˆë©ë‹ˆë‹¤.

                        ë‹¤ìˆ˜ì˜ AIê°€ ê³µí†µìœ¼ë¡œ ì œê³µí•œ ì •ë³´ëŠ” ê°€ì¥ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì˜¬ë°”ë¥¸ ì •ë³´ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.

                        íŠ¹ì • AIê°€ ë‹¤ìˆ˜ì˜ AIì™€ ë‹¤ë¥¸ ì •ë³´ë¥¼ ì œê³µí•˜ë©´, ì‹ ë¢°ì„±ì´ ë‚®ì€ ì •ë³´ë¡œ íŒë‹¨í•˜ì—¬ ìµœì ì˜ ë‹µë³€ì—ì„œ ì œì™¸í•˜ê³ , 'ë‹¨ì ' í•­ëª©ì— ë³„ë„ë¡œ ëª…ì‹œí•©ë‹ˆë‹¤.

                        ì—¬ëŸ¬ AIì˜ ë‹µë³€ì—ì„œ ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ì •ë³´ë§Œ ì„ íƒí•˜ì—¬ ë°˜ì˜í•©ë‹ˆë‹¤.

                        ì¤‘ë³µëœ ì •ë³´ê°€ ìˆì„ ê²½ìš° í‘œí˜„ì´ ë” ëª…í™•í•˜ê³  ìƒì„¸í•œ ë‚´ìš©ì„ ìš°ì„  ì„ íƒí•©ë‹ˆë‹¤.

                        ë…¼ë¦¬ì  íë¦„ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì‘ì„±í•©ë‹ˆë‹¤.

                        ì½”ë“œë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì¼ë•ŒëŠ”, AIì˜ ë‹µë³€ ì¤‘ ì œì¼ ì¢‹ì€ ë‹µë³€ì„ ì„ íƒí•´ì„œ ì¬êµ¬ì„±í•´ì¤˜ 

                        ì½”ë“œëŠ” ë°”ë¡œ ë³µì‚¬í•´ì„œ ì‚¬ìš©ê°€ëŠ¥í•˜ë„ë¡ í•´ì¤˜

                        ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì‹¤í–‰ ë²„íŠ¼ë§Œ ëˆ„ë¥´ë©´ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡ ì‘ì„±í•´ì•¼í•©ë‹ˆë‹¤.

                        ì½”ë“œì™€ ì½”ë“œê°€ ì•„ë‹Œ ë¶€ë¶„ì„ êµ¬ë³„ë˜ê²Œ ë³´ì—¬ì¤˜

                        ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

                        ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•œ ê²½ìš° ìœ¡í•˜ì›ì¹™ìœ¼ë¡œ ë‹µë³€í•´ì¤˜

                        [ì¶œë ¥ í˜•ì‹]
                        {{
                            "preferredModel": "{self.api_type.upper()}",
                            "best_response": "ìµœì ì˜ ë‹µë³€ ({user_language}ë¡œ ì‘ì„±)",
                            "analysis": {{
                                {analysis_section}
                            }},
                            "reasoning": "ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì‘ì„± ìµœì ì˜ ì‘ë‹µì„ ì„ íƒí•œ ì´ìœ "
                        }}"""

                # API íƒ€ì…ì— ë”°ë¥¸ ë¶„ê¸° ì²˜ë¦¬
                if self.api_type == 'openai':
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "You are a helpful assistant. Always respond with valid JSON ONLY, no additional text or explanations."},
                            {"role": "user", "content": analysis_prompt}
                        ],
                        temperature=0,
                        max_tokens=4096
                    )
                    analysis_text = response['choices'][0]['message']['content']
                    
                elif self.api_type == 'anthropic':
                    # ì‹œìŠ¤í…œ ë©”ì‹œì§€ì—ì„œ ì–¸ì–´ ì„¤ì • ì¶”ì¶œ
                    system_message = next((msg['content'] for msg in self.conversation_history 
                                        if msg['role'] == 'system'), '')
                    
                    message = self.client.messages.create(
                        model=self.model,
                        max_tokens=4096,
                        temperature=0,
                        system=f"{system_message}\nYou must respond with valid JSON only in the specified language. No other text or formatting.",
                        messages=[{
                            "role": "user", 
                            "content": analysis_prompt
                        }]
                    )
                    analysis_text = message.content[0].text.strip()
                
                elif self.api_type == 'groq':
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=[
                            {"role": "system", "content": "You are a helpful assistant. Always respond with valid JSON ONLY, no additional text or explanations."},
                            {"role": "user", "content": analysis_prompt}
                        ],
                        temperature=0,
                        max_tokens=4096
                    )
                    analysis_text = response.choices[0].message.content

                logger.info("âœ… ë¶„ì„ ì™„ë£Œ\n")
                
                # Use our new sanitize_and_parse_json function
                analysis_result = sanitize_and_parse_json(analysis_text, selected_models, responses)
                analysis_result['preferredModel'] = self.api_type.upper()
                
                return analysis_result
            
            except Exception as e:
                logger.error(f"âŒ Analysis error: {str(e)}")
                # Fallback response in case of a major error
                error_analysis = {}
                for model in selected_models:
                    model_lower = model.lower()
                    error_analysis[model_lower] = {"ì¥ì ": "ë¶„ì„ ì‹¤íŒ¨", "ë‹¨ì ": "ë¶„ì„ ì‹¤íŒ¨"}
                
                return {
                    "preferredModel": self.api_type.upper(),
                    "best_response": max(responses.values(), key=len) if responses else "",
                    "analysis": error_analysis,
                    "reasoning": "ì‘ë‹µ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì—¬ ìµœì ì˜ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
                }


# class ChatView(APIView):
#     permission_classes = [AllowAny]

#     def post(self, request, preferredModel):
#         try:
#             logger.info(f"Received chat request for {preferredModel}")
            
#             data = request.data
#             user_message = data.get('message')
#             compare_responses = data.get('compare', True)
            
#             # ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°: ì„ íƒëœ ëª¨ë¸ë“¤
#             selected_models = data.get('selectedModels', ['gpt', 'claude', 'mixtral'])
            
#             # ì„ íƒëœ ëª¨ë¸ ë¡œê·¸
#             logger.info(f"Selected models: {selected_models}")
            
#             # í† í° ìœ ë¬´ì— ë”°ë¥¸ ì–¸ì–´ ë° ì„ í˜¸ ëª¨ë¸ ì²˜ë¦¬
#             token = request.headers.get('Authorization')
#             if not token:
#                 # ë¹„ë¡œê·¸ì¸: ê¸°ë³¸ ì–¸ì–´ëŠ” ko, ì„ í˜¸ ëª¨ë¸ì€ GPTë¡œ ê³ ì •
#                 user_language = 'ko'
#                 preferredModel = 'gpt'
#             else:
#                 # ë¡œê·¸ì¸: ìš”ì²­ ë°ì´í„°ì˜ ì–¸ì–´ ì‚¬ìš© (í˜¹ì€ ì‚¬ìš©ìì˜ ì„¤ì •ì„ ë”°ë¦„)
#                 user_language = data.get('language', 'ko')
#                 # URLì— ì „ë‹¬ëœ preferredModelì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©ì ì„¤ì • ë°˜ì˜)

#             logger.info(f"Received language setting: {user_language}")

#             if not user_message:
#                 return Response({'error': 'No message provided'}, 
#                                 status=status.HTTP_400_BAD_REQUEST)

#             # ë¹„ë™ê¸° ì‘ë‹µì„ ìœ„í•œ StreamingHttpResponse ì‚¬ìš©
#             from django.http import StreamingHttpResponse
#             import json
#             import time

#             def stream_responses():
#                 try:
#                     system_message = {
#                         "role": "system",
#                         "content": f"ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ëŠ” '{user_language}'ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ëª¨ë“  ì‘ë‹µì„ ì´ ì–¸ì–´({user_language})ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
#                     }
                    
#                     responses = {}
                    
#                     # í˜„ì¬ ìš”ì²­ì— ëŒ€í•œ ê³ ìœ  ì‹ë³„ì ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í™œìš©)
#                     request_id = str(time.time())
                    
#                     # ì„ íƒëœ ëª¨ë¸ë“¤ë§Œ ëŒ€í™”ì— ì°¸ì—¬ì‹œí‚´
#                     selected_chatbots = {model: chatbots.get(model) for model in selected_models if model in chatbots}
                    
#                     # ê° ë´‡ì˜ ì‘ë‹µì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ ì‘ë‹µ
#                     for bot_id, bot in selected_chatbots.items():
#                         if bot is None:
#                             logger.warning(f"Selected model {bot_id} not available in chatbots")
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': f"Model {bot_id} is not available"
#                             }) + '\n'
#                             continue
                            
#                         try:
#                             # ë§¤ë²ˆ ìƒˆë¡œìš´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì´ì „ ë‚´ìš© ì´ˆê¸°í™”)
#                             bot.conversation_history = [system_message]
#                             response = bot.chat(user_message)
#                             responses[bot_id] = response
                            
#                             # ê° ë´‡ ì‘ë‹µì„ ì¦‰ì‹œ ì „ì†¡
#                             yield json.dumps({
#                                 'type': 'bot_response',
#                                 'botId': bot_id,
#                                 'response': response,
#                                 'requestId': request_id  # ìš”ì²­ ID ì¶”ê°€
#                             }) + '\n'
                            
#                         except Exception as e:
#                             logger.error(f"Error from {bot_id}: {str(e)}")
#                             responses[bot_id] = f"Error: {str(e)}"
                            
#                             # ì—ëŸ¬ë„ ì¦‰ì‹œ ì „ì†¡
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': str(e),
#                                 'requestId': request_id  # ìš”ì²­ ID ì¶”ê°€
#                             }) + '\n'
                    
#                     # ì„ íƒëœ ëª¨ë¸ì´ ìˆê³  ì‘ë‹µì´ ìˆì„ ë•Œë§Œ ë¶„ì„ ìˆ˜í–‰
#                     if selected_models and responses:
#                         # ë¶„ì„(ë¹„êµ)ì€ ë¡œê·¸ì¸ ì‹œ ì‚¬ìš©ìì˜ ì„ í˜¸ ëª¨ë¸ì„, ë¹„ë¡œê·¸ì¸ ì‹œ GPTë¥¼ ì‚¬ìš©
#                         if token:
#                             analyzer_bot = chatbots.get(preferredModel) or chatbots.get('gpt')
#                         else:
#                             analyzer_bot = chatbots.get('gpt')
                        
#                         # ë¶„ì„ìš© ë´‡ë„ ìƒˆë¡œìš´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
#                         analyzer_bot.conversation_history = [system_message]
                        
#                         # ë¶„ì„ ì‹¤í–‰ (í•­ìƒ ìƒˆë¡­ê²Œ ì‹¤í–‰)
#                         analysis = analyzer_bot.analyze_responses(responses, user_message, user_language, selected_models)
                        
#                         # ë¶„ì„ ê²°ê³¼ ì „ì†¡
#                         yield json.dumps({
#                             'type': 'analysis',
#                             'preferredModel': analyzer_bot and analyzer_bot.api_type.upper(),
#                             'best_response': analysis.get('best_response', ''),
#                             'analysis': analysis.get('analysis', {}),
#                             'reasoning': analysis.get('reasoning', ''),
#                             'language': user_language,
#                             'requestId': request_id,  # ìš”ì²­ ID ì¶”ê°€
#                             'timestamp': time.time()  # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
#                         }) + '\n'
#                     else:
#                         logger.warning("No selected models or responses to analyze")
                    
#                 except Exception as e:
#                     logger.error(f"Stream processing error: {str(e)}", exc_info=True)
#                     yield json.dumps({
#                         'type': 'error',
#                         'error': f"Stream processing error: {str(e)}"
#                     }) + '\n'

#             # StreamingHttpResponse ë°˜í™˜
#             response = StreamingHttpResponse(
#                 streaming_content=stream_responses(),
#                 content_type='text/event-stream'
#             )
#             response['Cache-Control'] = 'no-cache'
#             response['X-Accel-Buffering'] = 'no'
#             return response
                
#         except Exception as e:
#             logger.error(f"Unexpected error: {str(e)}", exc_info=True)
#             return Response({
#                 'error': str(e)
#             }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
import logging
import json
from django.http import StreamingHttpResponse
import time
import numpy as np

logger = logging.getLogger(__name__)

# JSON ì§ë ¬í™” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì¶”ê°€
def convert_to_serializable(obj):
    """ëª¨ë“  ê°ì²´ë¥¼ JSON ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤"""
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.integer):  # ì •ìˆ˜í˜• íƒ€ì… ì²˜ë¦¬
        return int(obj)
    elif isinstance(obj, (np.float16, np.float32, np.float64)):  # float_ ì œê±°í•˜ê³  êµ¬ì²´ì ì¸ íƒ€ì…ë§Œ ì‚¬ìš©
        return float(obj)
    elif isinstance(obj, (set, tuple)):
        return list(obj)
    elif hasattr(obj, 'isoformat'):  # datetime ê°ì²´ ì²˜ë¦¬
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(i) for i in obj]
    else:
        try:
            # str() ì‚¬ìš© ì‹œë„
            return str(obj)
        except:
            return repr(obj)

# class ChatView(APIView):
#     permission_classes = [AllowAny]
    
#     def __init__(self, **kwargs):
#         super().__init__(**kwargs)
#         # SimilarityAnalyzer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
#         self.similarity_analyzer = SimilarityAnalyzer(threshold=0.85)

#     def post(self, request, preferredModel):
#         try:
#             logger.info(f"Received chat request for {preferredModel}")
            
#             data = request.data
#             user_message = data.get('message')
#             compare_responses = data.get('compare', True)
            
#             # ì„ íƒëœ ëª¨ë¸ë“¤
#             selected_models = data.get('selectedModels', ['gpt', 'claude', 'mixtral'])
            
#             # ì„ íƒëœ ëª¨ë¸ ë¡œê·¸
#             logger.info(f"Selected models: {selected_models}")
            
#             # í† í° ìœ ë¬´ì— ë”°ë¥¸ ì–¸ì–´ ë° ì„ í˜¸ ëª¨ë¸ ì²˜ë¦¬
#             token = request.headers.get('Authorization')
#             if not token:
#                 # ë¹„ë¡œê·¸ì¸: ê¸°ë³¸ ì–¸ì–´ëŠ” ko, ì„ í˜¸ ëª¨ë¸ì€ GPTë¡œ ê³ ì •
#                 user_language = 'ko'
#                 preferredModel = 'gpt'
#             else:
#                 # ë¡œê·¸ì¸: ìš”ì²­ ë°ì´í„°ì˜ ì–¸ì–´ ì‚¬ìš© (í˜¹ì€ ì‚¬ìš©ìì˜ ì„¤ì •ì„ ë”°ë¦„)
#                 user_language = data.get('language', 'ko')
#                 # URLì— ì „ë‹¬ëœ preferredModelì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì‚¬ìš©ì ì„¤ì • ë°˜ì˜)

#             logger.info(f"Received language setting: {user_language}")

#             if not user_message:
#                 return Response({'error': 'No message provided'}, 
#                                 status=status.HTTP_400_BAD_REQUEST)

#             # ë¹„ë™ê¸° ì‘ë‹µì„ ìœ„í•œ StreamingHttpResponse ì‚¬ìš©
#             def stream_responses():
#                 try:
#                     system_message = {
#                         "role": "system",
#                         "content": f"ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ëŠ” '{user_language}'ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ëª¨ë“  ì‘ë‹µì„ ì´ ì–¸ì–´({user_language})ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."
#                     }
                    
#                     responses = {}
                    
#                     # í˜„ì¬ ìš”ì²­ì— ëŒ€í•œ ê³ ìœ  ì‹ë³„ì ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ í™œìš©)
#                     request_id = str(time.time())
                    
#                     # ì„ íƒëœ ëª¨ë¸ë“¤ë§Œ ëŒ€í™”ì— ì°¸ì—¬ì‹œí‚´
#                     selected_chatbots = {model: chatbots.get(model) for model in selected_models if model in chatbots}
                    
#                     # ê° ë´‡ì˜ ì‘ë‹µì„ ê°œë³„ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ì¦‰ì‹œ ì‘ë‹µ
#                     for bot_id, bot in selected_chatbots.items():
#                         if bot is None:
#                             logger.warning(f"Selected model {bot_id} not available in chatbots")
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': f"Model {bot_id} is not available"
#                             }) + '\n'
#                             continue
                            
#                         try:
#                             # ë§¤ë²ˆ ìƒˆë¡œìš´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì´ì „ ë‚´ìš© ì´ˆê¸°í™”)
#                             bot.conversation_history = [system_message]
#                             response = bot.chat(user_message)
#                             responses[bot_id] = response
                            
#                             # ê° ë´‡ ì‘ë‹µì„ ì¦‰ì‹œ ì „ì†¡
#                             yield json.dumps({
#                                 'type': 'bot_response',
#                                 'botId': bot_id,
#                                 'response': response,
#                                 'requestId': request_id  # ìš”ì²­ ID ì¶”ê°€
#                             }) + '\n'
                            
#                         except Exception as e:
#                             logger.error(f"Error from {bot_id}: {str(e)}")
#                             responses[bot_id] = f"Error: {str(e)}"
                            
#                             # ì—ëŸ¬ë„ ì¦‰ì‹œ ì „ì†¡
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': str(e),
#                                 'requestId': request_id  # ìš”ì²­ ID ì¶”ê°€
#                             }) + '\n'
                    
#                     # ì‘ë‹µì´ 2ê°œ ì´ìƒì¼ ë•Œë§Œ ìœ ì‚¬ë„ ë¶„ì„ ìˆ˜í–‰
#                     if len(responses) >= 2:
#                         try:
#                             # ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ê³„ì‚°
#                             similarity_result = self.similarity_analyzer.cluster_responses(responses)
                            
#                             # ê²°ê³¼ë¥¼ ì§ë ¬í™” ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜
#                             serializable_result = convert_to_serializable(similarity_result)
                            
#                             # ë””ë²„ê¹…ì„ ìœ„í•œ ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ë¡œê¹…
#                             logger.info(f"Similarity analysis result: {serializable_result}")
                            
#                             # ìœ ì‚¬ë„ ë¶„ì„ ê²°ê³¼ ì „ì†¡
#                             yield json.dumps({
#                                 'type': 'similarity_analysis',
#                                 'result': serializable_result,
#                                 'requestId': request_id,
#                                 'timestamp': time.time(),
#                                 'userMessage': user_message  # ì‚¬ìš©ì ë©”ì‹œì§€ í¬í•¨
#                             }) + '\n'
                            
#                         except Exception as e:
#                             logger.error(f"Error in similarity analysis: {str(e)}", exc_info=True)
#                             yield json.dumps({
#                                 'type': 'similarity_error',
#                                 'error': f"Similarity analysis error: {str(e)}",
#                                 'requestId': request_id
#                             }) + '\n'
                    
#                     # ì„ íƒëœ ëª¨ë¸ì´ ìˆê³  ì‘ë‹µì´ ìˆì„ ë•Œë§Œ ë¶„ì„ ìˆ˜í–‰
#                     if selected_models and responses:
#                         # ë¶„ì„(ë¹„êµ)ì€ ë¡œê·¸ì¸ ì‹œ ì‚¬ìš©ìì˜ ì„ í˜¸ ëª¨ë¸ì„, ë¹„ë¡œê·¸ì¸ ì‹œ GPTë¥¼ ì‚¬ìš©
#                         if token:
#                             analyzer_bot = chatbots.get(preferredModel) or chatbots.get('gpt')
#                         else:
#                             analyzer_bot = chatbots.get('gpt')
                        
#                         # ë¶„ì„ìš© ë´‡ë„ ìƒˆë¡œìš´ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
#                         analyzer_bot.conversation_history = [system_message]
                        
#                         # ë¶„ì„ ì‹¤í–‰ (í•­ìƒ ìƒˆë¡­ê²Œ ì‹¤í–‰)
#                         analysis = analyzer_bot.analyze_responses(responses, user_message, user_language, selected_models)
                        
#                         # ë¶„ì„ ê²°ê³¼ ì „ì†¡
#                         yield json.dumps({
#                             'type': 'analysis',
#                             'preferredModel': analyzer_bot and analyzer_bot.api_type.upper(),
#                             'best_response': analysis.get('best_response', ''),
#                             'analysis': analysis.get('analysis', {}),
#                             'reasoning': analysis.get('reasoning', ''),
#                             'language': user_language,
#                             'requestId': request_id,  # ìš”ì²­ ID ì¶”ê°€
#                             'timestamp': time.time(),  # íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
#                             'userMessage': user_message  # ì‚¬ìš©ì ë©”ì‹œì§€ í¬í•¨
#                         }) + '\n'
#                     else:
#                         logger.warning("No selected models or responses to analyze")
                    
#                 except Exception as e:
#                     logger.error(f"Stream processing error: {str(e)}", exc_info=True)
#                     yield json.dumps({
#                         'type': 'error',
#                         'error': f"Stream processing error: {str(e)}"
#                     }) + '\n'

#             # StreamingHttpResponse ë°˜í™˜
#             response = StreamingHttpResponse(
#                 streaming_content=stream_responses(),
#                 content_type='text/event-stream'
#             )
#             response['Cache-Control'] = 'no-cache'
#             response['X-Accel-Buffering'] = 'no'
#             return response
                
#         except Exception as e:
#             logger.error(f"Unexpected error: {str(e)}", exc_info=True)
#             return Response({
#                 'error': str(e)
#             }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
class ChatView(APIView):
    permission_classes = [AllowAny]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.similarity_analyzer = SimilarityAnalyzer(threshold=0.85)

    def post(self, request, preferredModel):
        try:
            logger.info(f"Received chat request for {preferredModel}")
            data = request.data
            user_message = data.get('message')
            selected_models = data.get('selectedModels', ['gpt', 'claude', 'mixtral'])
            token = request.headers.get('Authorization')
            user_language = 'ko' if not token else data.get('language', 'ko')
            if not user_message:
                return Response({'error': 'No message provided'}, status=status.HTTP_400_BAD_REQUEST)

            # ë§í¬ë§Œ ìˆì„ ê²½ìš° í˜ì´ì§€ ë‚´ìš©ìœ¼ë¡œ ë¶„ì„ ìš”ì²­
            url_pattern = r'^(https?://\S+)$'
            match = re.match(url_pattern, user_message.strip())
            if match:
                url = match.group(1)
                try:
                    page_text = fetch_and_clean_url(url)
                    if len(page_text) > 10000:
                        page_text = page_text[:5000] + "\n\nâ€¦(ì¤‘ëµ)â€¦\n\n" + page_text[-5000:]
                    user_message = (
                        f"ë‹¤ìŒ ì›¹í˜ì´ì§€ì˜ ë‚´ìš©ì„ ë¶„ì„í•´ ì£¼ì„¸ìš”:\n"
                        f"URL: {url}\n\n"
                        f"{page_text}"
                    )
                except Exception as e:
                    logger.error(f"URL fetch error: {e}")
                    return Response({'error': f"URLì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {e}"}, status=status.HTTP_400_BAD_REQUEST)

            def stream_responses():
                try:
                    system_message = {
                        'role': 'system',
                        'content': f"ì‚¬ìš©ìê°€ ì„ íƒí•œ ì–¸ì–´ëŠ” '{user_language}'ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì´ ì–¸ì–´({user_language})ë¡œ ì‘ë‹µí•˜ì„¸ìš”."
                    }
                    responses = {}
                    request_id = str(time.time())
                    # ê° ëª¨ë¸ë³„ ì±—ë´‡ ì¸ìŠ¤í„´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
                    selected_chatbots = {m: chatbots.get(m) for m in selected_models if chatbots.get(m)}

                    # ëª¨ë¸ ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°
                    for bot_id, bot in selected_chatbots.items():
                        try:
                            bot.conversation_history = [system_message]
                            resp_text = bot.chat(user_message)
                            responses[bot_id] = resp_text
                            yield json.dumps({'type':'bot_response','botId':bot_id,'response':resp_text,'requestId':request_id}) + '\n'
                        except Exception as e:
                            yield json.dumps({'type':'bot_error','botId':bot_id,'error':str(e),'requestId':request_id}) + '\n'

                    # ìœ ì‚¬ë„ ë¶„ì„
                    if len(responses) >= 2:
                        sim_res = self.similarity_analyzer.cluster_responses(responses)
                        serial = convert_to_serializable(sim_res)
                        yield json.dumps({'type':'similarity_analysis','result':serial,'requestId':request_id,'timestamp':time.time(),'userMessage':user_message}) + '\n'

                    # ìµœì¢… ë¹„êµ ë° ë¶„ì„
                    analyzer_bot = chatbots.get(preferredModel) or chatbots.get('gpt')
                    analyzer_bot.conversation_history = [system_message]
                    analysis = analyzer_bot.analyze_responses(responses, user_message, user_language, list(responses.keys()))
                    yield json.dumps({
                        'type':'analysis',
                        'preferredModel': analyzer_bot.api_type.upper(),
                        'best_response': analysis.get('best_response',''),
                        'analysis': analysis.get('analysis',{}),
                        'reasoning': analysis.get('reasoning',''),
                        'language': user_language,
                        'requestId': request_id,
                        'timestamp': time.time(),
                        'userMessage': user_message
                    }) + '\n'
                except Exception as e:
                    yield json.dumps({'type':'error','error':f"Stream error: {e}"}) + '\n'

            return StreamingHttpResponse(stream_responses(), content_type='text/event-stream')

        except Exception as e:
            logger.error(f"Unexpected error: {e}", exc_info=True)
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# API í‚¤ ì„¤ì •
OPENAI_API_KEY = "***REMOVED***"
ANTHROPIC_API_KEY = "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"
GROQ_API_KEY = "***REMOVED***"


chatbots = {
    'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
    'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
    'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
}
# chatbots = {
#     'gpt': ChatBot(OPENAI_API_KEY, 'gpt-4-turbo', 'openai'),
#     'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-opus-20240229', 'anthropic'), 
#     'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
# }


from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import IsAuthenticated
from .models import UserProfile, UserSettings
from .serializers import UserSerializer

class UserSettingsView(APIView):
    permission_classes = [IsAuthenticated]

    def get(self, request):
        try:
            user_settings, created = UserSettings.objects.get_or_create(
                user=request.user,
                defaults={
                    'language': 'ko',
                    'analyzer_bot': 'claude'
                }
            )
            serializer = UserSerializer(user_settings)
            return Response(serializer.data)
        except Exception as e:
            return Response({
                'language': 'ko', 
                'analyzer_bot': 'claude'
            }, status=status.HTTP_200_OK)

    def post(self, request):
        try:
            user_settings, created = UserSettings.objects.get_or_create(
                user=request.user,
                defaults={
                    'language': request.data.get('language', 'ko'),
                    'analyzer_bot': request.data.get('analyzer_bot', 'claude')
                }
            )

            # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì—…ë°ì´íŠ¸
            if not created:
                user_settings.language = request.data.get('language', user_settings.language)
                user_settings.analyzer_bot = request.data.get('analyzer_bot', user_settings.analyzer_bot)
                user_settings.save()

            serializer = UserSettingsSerializer(user_settings)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_400_BAD_REQUEST)
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
import requests
import logging
from django.contrib.auth import get_user_model
from .models import SocialAccount

import uuid

logger = logging.getLogger(__name__)
User = get_user_model()

# def generate_unique_username(email, name=None):
#     """ê³ ìœ í•œ username ìƒì„±"""
#     base = name or email.split('@')[0]
#     username = base
#     suffix = 1
    
#     # usernameì´ ê³ ìœ í•  ë•Œê¹Œì§€ ìˆ«ì ì¶”ê°€
#     while User.objects.filter(username=username).exists():
#         username = f"{base}_{suffix}"
#         suffix += 1
    
#     return username

def generate_unique_username(email, name=None):
    """username ìƒì„± - ì´ë©”ì¼ ì•ë¶€ë¶„ ë˜ëŠ” ì´ë¦„ ì‚¬ìš©"""
    if name:
        return name  # ì´ë¦„ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    return email.split('@')[0]  # ì´ë¦„ì´ ì—†ìœ¼ë©´ ì´ë©”ì¼ ì•ë¶€ë¶„ ì‚¬ìš©
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import AllowAny
from rest_framework.authtoken.models import Token
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
# views.py
from django.db import transaction, IntegrityError

# @api_view(['GET'])
# @authentication_classes([TokenAuthentication])
# @permission_classes([AllowAny])
# @api_view(['GET'])
# @permission_classes([AllowAny])
# def google_callback(request):
#     logger.info("Starting Google callback process")  # ë¡œê¹… ì¶”ê°€
#     try:
#         with transaction.atomic():
#             # 1. ì‚¬ìš©ì ì •ë³´ ê°€ì ¸ì˜¤ê¸°
#             auth_header = request.headers.get('Authorization', '')
#             access_token = auth_header.split(' ')[1]
            
#             user_info_response = requests.get(
#                 'https://www.googleapis.com/oauth2/v3/userinfo',
#                 headers={'Authorization': f'Bearer {access_token}'}
#             )
            
#             user_info = user_info_response.json()
#             email = user_info.get('email')
#             name = user_info.get('name')

#             logger.info(f"Processing user: {email}")  # ë¡œê¹… ì¶”ê°€

#             # 2. User ê°ì²´ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
#             user = User.objects.filter(email=email).first()
#             if not user:
#                 user = User.objects.create(
#                     username=email,
#                     email=email,
#                     first_name=name or '',
#                     is_active=True
#                 )
#                 logger.info(f"Created new user: {user.id}")
#             else:
#                 logger.info(f"Found existing user: {user.id}")

#             # 3. ê¸°ì¡´ UserSettings ì‚­ì œ (ìˆë‹¤ë©´)
#             UserSettings.objects.filter(user=user).delete()
#             logger.info("Deleted any existing settings")

#             # 4. ìƒˆë¡œìš´ UserSettings ìƒì„±
#             settings = UserSettings.objects.create(
#                 user=user,
#                 language='ko',
#                 preferred_model='default'
#             )
#             logger.info(f"Created new settings for user: {user.id}")

#             # 5. í† í° ìƒì„±
#             token, _ = Token.objects.get_or_create(user=user)
            
#             return Response({
#                 'user': {
#                     'id': user.id,
#                     'email': user.email,
#                     'username': user.username,
#                     'first_name': user.first_name,
#                     'settings': {
#                         'language': settings.language,
#                         'preferred_model': settings.preferred_model
#                     }
#                 },
#                 'access_token': token.key
#             })
#     except Exception as e:
#         logger.error(f"Error in google_callback: {str(e)}")
#         return Response(
#             {'error': str(e)},
#             status=status.HTTP_400_BAD_REQUEST
        # )
@api_view(['GET'])
@authentication_classes([TokenAuthentication])
@permission_classes([AllowAny])
def google_callback(request):
    try:
        # ì•¡ì„¸ìŠ¤ í† í° ì¶”ì¶œ
        auth_header = request.headers.get('Authorization', '')
        if not auth_header.startswith('Bearer '):
            return Response(
                {'error': 'ì˜ëª»ëœ ì¸ì¦ í—¤ë”'}, 
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        access_token = auth_header.split(' ')[1]

        # Google APIë¡œ ì‚¬ìš©ì ì •ë³´ ìš”ì²­
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v3/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )

        if user_info_response.status_code != 200:
            return Response(
                {'error': 'Googleì—ì„œ ì‚¬ìš©ì ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        user_info = user_info_response.json()
        email = user_info.get('email')
        name = user_info.get('name')
        
        if not email:
            return Response(
                {'error': 'ì´ë©”ì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # ê¸°ì¡´ ì‚¬ìš©ì ê²€ìƒ‰
            user = User.objects.get(email=email)
        except User.DoesNotExist:
            # ìƒˆë¡œìš´ ì‚¬ìš©ì ìƒì„±
            username = generate_unique_username(email, name)
            user = User.objects.create(
                username=username,
                email=email,
                is_active=True
            )
            
            # ê¸°ë³¸ ë¹„ë°€ë²ˆí˜¸ ì„¤ì • (ì„ íƒì )
            random_password = uuid.uuid4().hex
            user.set_password(random_password)
            user.save()

        # ì†Œì…œ ê³„ì • ì •ë³´ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        social_account, created = SocialAccount.objects.get_or_create(
            email=email,
            provider='google',
            defaults={'user': user}
        )

        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()

        # í† í° ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        token, created = Token.objects.get_or_create(user=user)
        logger.info(f"GOOGLE Token created: {created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")


        # ì‚¬ìš©ì ë°ì´í„° ë°˜í™˜
        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token ë°˜í™˜
            'token_created': created,
            'google_access_token': access_token,  # Google OAuth ì•¡ì„¸ìŠ¤ í† í°

        })

    except Exception as e:
        logger.error(f"Error in google_callback: {str(e)}")
        return Response(
            {'error': str(e)}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )
import requests
import json
import requests
from django.conf import settings
from django.http import JsonResponse
from django.shortcuts import redirect
from .models import User  # User ëª¨ë¸ì„ ì„í¬íŠ¸


@api_view(['GET'])
@permission_classes([AllowAny])
def kakao_callback(request):
    try:
        auth_code = request.GET.get('code')
        logger.info(f"Received Kakao auth code: {auth_code}")
        
        # ì¹´ì¹´ì˜¤ í† í° ë°›ê¸°
        token_url = "https://kauth.kakao.com/oauth/token"
        data = {
            "grant_type": "authorization_code",
            "client_id": settings.KAKAO_CLIENT_ID,
            "redirect_uri": settings.KAKAO_REDIRECT_URI,
            "code": auth_code,
        }
        
        token_response = requests.post(token_url, data=data)
        
        if not token_response.ok:
            return Response({
                'error': 'ì¹´ì¹´ì˜¤ í† í° ë°›ê¸° ì‹¤íŒ¨',
                'details': token_response.text
            }, status=status.HTTP_400_BAD_REQUEST)
        
        token_data = token_response.json()
        access_token = token_data.get('access_token')
        
        if not access_token:
            return Response({
                'error': 'ì•¡ì„¸ìŠ¤ í† í° ì—†ìŒ',
                'details': token_data
            }, status=status.HTTP_400_BAD_REQUEST)

        # ì¹´ì¹´ì˜¤ ì‚¬ìš©ì ì •ë³´ ë°›ê¸°
        user_info_url = "https://kapi.kakao.com/v2/user/me"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-type": "application/x-www-form-urlencoded;charset=utf-8"
        }
        
        user_info_response = requests.get(
            user_info_url,
            headers=headers,
            params={
                'property_keys': json.dumps([
                    "kakao_account.email",
                    "kakao_account.profile",
                    "kakao_account.name"
                ])
            }
        )
        
        if not user_info_response.ok:
            return Response({
                'error': 'ì‚¬ìš©ì ì •ë³´ ë°›ê¸° ì‹¤íŒ¨',
                'details': user_info_response.text
            }, status=status.HTTP_400_BAD_REQUEST)
        
        user_info = user_info_response.json()
        kakao_account = user_info.get('kakao_account', {})
        email = kakao_account.get('email')
        profile = kakao_account.get('profile', {})
        nickname = profile.get('nickname')
        
        logger.info(f"Kakao user info - email: {email}, nickname: {nickname}")
        
        if not email:
            return Response({
                'error': 'ì´ë©”ì¼ ì •ë³´ ì—†ìŒ',
                'details': 'ì¹´ì¹´ì˜¤ ê³„ì •ì˜ ì´ë©”ì¼ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)

        # ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        try:
            user = User.objects.get(email=email)
            logger.info(f"Updated existing user with nickname: {nickname}")
        except User.DoesNotExist:
            unique_username = generate_unique_username(email, nickname)
            user = User.objects.create(
                email=email,
                username=unique_username,
                is_active=True
            )            
            logger.info(f"Created new user with nickname: {nickname}")

        # ì†Œì…œ ê³„ì • ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸
        social_account, created = SocialAccount.objects.update_or_create(
            email=email,
            provider='kakao',
            defaults={
                'user': user,
                'nickname': nickname
            }
        )
        logger.info(f"Social account updated - email: {email}, nickname: {nickname}")

        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()

        # í† í° ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        token, token_created = Token.objects.get_or_create(user=user)
        logger.info(f"KAKAO Token created: {token_created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")

        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token ë°˜í™˜
            'token_created': created,
            'kakao_access_token': access_token,  # Google OAuth ì•¡ì„¸ìŠ¤ í† í°

        })


        
    except Exception as e:
        logger.exception("Unexpected error in kakao_callback")
        return Response({
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from rest_framework.authtoken.models import Token  # Token ëª¨ë¸ ì¶”ê°€

@api_view(['GET'])
@permission_classes([AllowAny])
def naver_callback(request):
    try:
        code = request.GET.get('code')
        state = request.GET.get('state')
        logger.info(f"Received Naver auth code: {code}")

        # ë„¤ì´ë²„ í† í° ë°›ê¸°
        token_url = "https://nid.naver.com/oauth2.0/token"
        token_params = {
            "grant_type": "authorization_code",
            "client_id": settings.NAVER_CLIENT_ID,
            "client_secret": settings.NAVER_CLIENT_SECRET,
            "code": code,
            "state": state
        }

        token_response = requests.get(token_url, params=token_params)

        if not token_response.ok:
            return Response({
                'error': 'ë„¤ì´ë²„ í† í° ë°›ê¸° ì‹¤íŒ¨',
                'details': token_response.text
            }, status=status.HTTP_400_BAD_REQUEST)

        token_data = token_response.json()
        access_token = token_data.get('access_token')

        if not access_token:
            return Response({
                'error': 'ì•¡ì„¸ìŠ¤ í† í° ì—†ìŒ',
                'details': token_data
            }, status=status.HTTP_400_BAD_REQUEST)

        # ë„¤ì´ë²„ ì‚¬ìš©ì ì •ë³´ ë°›ê¸°
        user_info_url = "https://openapi.naver.com/v1/nid/me"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-type": "application/x-www-form-urlencoded;charset=utf-8"
        }

        user_info_response = requests.get(user_info_url, headers=headers)

        if not user_info_response.ok:
            return Response({
                'error': 'ì‚¬ìš©ì ì •ë³´ ë°›ê¸° ì‹¤íŒ¨',
                'details': user_info_response.text
            }, status=status.HTTP_400_BAD_REQUEST)

        user_info = user_info_response.json()
        response = user_info.get('response', {})
        email = response.get('email')
        nickname = response.get('nickname')
        username = email.split('@')[0]

        if not email:
            return Response({
                'error': 'ì´ë©”ì¼ ì •ë³´ ì—†ìŒ',
                'details': 'ë„¤ì´ë²„ ê³„ì •ì˜ ì´ë©”ì¼ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)

        # ì‚¬ìš©ì ìƒì„± ë˜ëŠ” ì¡°íšŒ
        user, created = User.objects.get_or_create(
            email=email,
            defaults={'username': generate_unique_username(email, username), 'is_active': True}
        )

        # ì†Œì…œ ê³„ì • ì¡°íšŒ ë° ì—…ë°ì´íŠ¸
        social_account, social_created = SocialAccount.objects.update_or_create(
            provider='naver',
            email=email,
            defaults={'user': user, 'nickname': nickname}
        )

        logger.info(f"Social account updated - email: {email}, nickname: {nickname}")

        # âœ… Django REST Framework Token ìƒì„±
        token, token_created = Token.objects.get_or_create(user=user)
        logger.info(f"Naver Token created: {token_created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")

        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token ë°˜í™˜
            'token_created': created,
            'naver_access_token': access_token,  # ë„¤ì´ë²„ ì•¡ì„¸ìŠ¤ í† í°
        })

    except Exception as e:
        logger.exception("Unexpected error in naver_callback")
        return Response({
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# views.py
import logging
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.contrib.auth import get_user_model

# logger = logging.getLogger(__name__)

# @api_view(['PUT'])
# @permission_classes([IsAuthenticated])
# def update_user_settings(request):
#     # ì¶”ê°€ ë¡œê¹… ë° ë””ë²„ê¹…
#     logger.info(f"User authentication status: {request.user.is_authenticated}")
#     logger.info(f"User: {request.user}")
#     logger.info(f"Request headers: {request.headers}")
    
#     try:
#         # ì¸ì¦ ìƒíƒœ ëª…ì‹œì  í™•ì¸
#         if not request.user.is_authenticated:
#             logger.error("Unauthenticated user attempt")
#             return Response({
#                 'status': 'error',
#                 'message': 'ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ìì…ë‹ˆë‹¤.'
#             }, status=401)
        
#         # UserProfile ëª¨ë¸ì´ ìˆë‹¤ê³  ê°€ì •
#         user = request.user
#         user_profile = user.userprofile
        
#         # ì„¤ì • ì—…ë°ì´íŠ¸
#         settings_data = request.data
#         user_profile.language = settings_data.get('language', user_profile.language)
#         user_profile.preferred_model = settings_data.get('preferredModel', user_profile.preferred_model)
#         user_profile.save()
        
#         return Response({
#             'status': 'success',
#             'message': 'ì„¤ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.',
#             'settings': {
#                 'language': user_profile.language,
#                 'preferredModel': user_profile.preferred_model
#             }
#         })
    
#     except Exception as e:
#         print("Error:", str(e))  # ì—ëŸ¬ ë¡œê¹…
#         logger.error(f"Settings update error: {str(e)}")
#         return Response({
#             'status': 'error',
#             'message': f'ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
#         }, status=400)
# views.py
# ë°±ì—”ë“œì—ì„œ í† í° í˜•ì‹ í™•ì¸
@api_view(['PUT'])
@authentication_classes([TokenAuthentication])
@permission_classes([IsAuthenticated])
def update_user_settings(request):
    try:
        # í† í° ë¡œê¹… ì¶”ê°€
        token_header = request.headers.get('Authorization')
        if not token_header or not token_header.startswith('Token '):
            return Response({'error': 'ì˜ëª»ëœ í† í° í˜•ì‹'}, status=status.HTTP_401_UNAUTHORIZED)
        
        user = request.user
        if not user.is_authenticated:
            return Response({'error': 'ì¸ì¦ë˜ì§€ ì•Šì€ ì‚¬ìš©ì'}, status=status.HTTP_401_UNAUTHORIZED)
        
        settings_data = request.data
        print(f"Received settings data: {settings_data}")  # ë°ì´í„° ë¡œê¹… ì¶”ê°€
        
        # UserSettings ì—…ë°ì´íŠ¸ ë˜ëŠ” ìƒì„±
        settings, created = UserSettings.objects.get_or_create(user=user)
        
        # í•„ë“œ ì—…ë°ì´íŠ¸
        if 'language' in settings_data:
            settings.language = settings_data['language']
        if 'preferredModel' in settings_data:
            settings.preferred_model = settings_data['preferredModel']
        
        settings.save()
        
        return Response({
            'message': 'Settings updated successfully',
            'settings': {
                'language': settings.language,
                'preferredModel': settings.preferred_model
            }
        })
        
    except Exception as e:
        logger.error(f"Settings update error: {str(e)}")
        return Response(
            {'error': str(e)},
            status=status.HTTP_400_BAD_REQUEST
        )
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.core.exceptions import ObjectDoesNotExist

@api_view(['PUT'])
@authentication_classes([TokenAuthentication])
@permission_classes([IsAuthenticated])
def update_user_settings(request):
    try:
        user = request.user
        settings_data = request.data
        
        # UserProfile í™•ì¸ ë° ìƒì„±
        try:
            profile = user.userprofile
        except ObjectDoesNotExist:
            profile = UserProfile.objects.create(user=user)
            
        # UserSettings í™•ì¸ ë° ìƒì„±/ì—…ë°ì´íŠ¸
        settings, created = UserSettings.objects.get_or_create(
            user=user,
            defaults={
                'language': settings_data.get('language', 'en'),
                'preferred_model': settings_data.get('preferredModel', 'default')
            }
        )
        
        if not created:
            settings.language = settings_data.get('language', settings.language)
            settings.preferred_model = settings_data.get('preferredModel', settings.preferred_model)
            settings.save()
            
        return Response({
            'message': 'Settings updated successfully',
            'settings': {
                'language': settings.language,
                'preferredModel': settings.preferred_model
            }
        })
            
    except Exception as e:
        print(f"Settings update error: {str(e)}")
        return Response(
            {'error': str(e)},
            status=status.HTTP_400_BAD_REQUEST
        )

import logging
import re
import math
import numpy as np
from collections import Counter
from typing import Dict, List, Union, Any
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
logger = logging.getLogger(__name__)

class SimilarityAnalyzer:
    """
    AI ëª¨ë¸ ì‘ë‹µ ê°„ì˜ ìœ ì‚¬ë„ë¥¼ ë¶„ì„í•˜ê³  ì‘ë‹µ íŠ¹ì„±ì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤
    ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•´ paraphrase-multilingual-MiniLM-L12-v2 ëª¨ë¸ ì‚¬ìš©
    """
    
    def __init__(self, threshold=0., use_transformer=True):
        """
        ì´ˆê¸°í™”
        
        Args:
            threshold (float): ìœ ì‚¬ ì‘ë‹µìœ¼ë¡œ ë¶„ë¥˜í•  ì„ê³„ê°’ (0~1)
            use_transformer (bool): SentenceTransformer ëª¨ë¸ ì‚¬ìš© ì—¬ë¶€
        """
        self.threshold = threshold
        self.use_transformer = use_transformer
        
        # ë‹¤êµ­ì–´ SentenceTransformer ëª¨ë¸ ë¡œë“œ
        if use_transformer:
            try:
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                logger.info("ë‹¤êµ­ì–´ SentenceTransformer ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"SentenceTransformer ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                self.use_transformer = False
                
        # Fallbackìš© TF-IDF ë²¡í„°ë¼ì´ì €
        from sklearn.feature_extraction.text import TfidfVectorizer
        self.vectorizer = TfidfVectorizer(
            min_df=1, 
            analyzer='word',
            ngram_range=(1, 2),
            stop_words=None  # ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•´ stop_words ì œê±°
        )
    
    def preprocess_text(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        
        Args:
            text (str): ì „ì²˜ë¦¬í•  í…ìŠ¤íŠ¸
            
        Returns:
            str: ì „ì²˜ë¦¬ëœ í…ìŠ¤íŠ¸
        """
        # ì†Œë¬¸ì ë³€í™˜ (ì˜ì–´ í…ìŠ¤íŠ¸ë§Œ í•´ë‹¹)
        # ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•´ ì˜ì–´ê°€ ì•„ë‹Œ ê²½ìš° ì›ë˜ ì¼€ì´ìŠ¤ ìœ ì§€
        if text.isascii():
            text = text.lower()
        
        # ì½”ë“œ ë¸”ë¡ ì œê±° (ë¶„ì„ì—ì„œ ì œì™¸)
        text = re.sub(r'```.*?```', ' CODE_BLOCK ', text, flags=re.DOTALL)
        
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<.*?>', '', text)
        
        # íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬ (ë‹¤êµ­ì–´ ì§€ì›ì„ ìœ„í•´ ì™„ì „ ì œê±°í•˜ì§€ ì•ŠìŒ)
        text = re.sub(r'[^\w\s\u0080-\uFFFF]', ' ', text)
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ ì¹˜í™˜
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def calculate_similarity_matrix(self, responses: Dict[str, str]) -> Dict[str, Dict[str, float]]:
        """
        ëª¨ë¸ ì‘ë‹µ ê°„ì˜ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
        
        Args:
            responses (dict): ëª¨ë¸ IDë¥¼ í‚¤ë¡œ, ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            
        Returns:
            dict: ëª¨ë¸ ê°„ ìœ ì‚¬ë„ í–‰ë ¬
        """
        try:
            model_ids = list(responses.keys())
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            preprocessed_texts = [self.preprocess_text(responses[model_id]) for model_id in model_ids]
            
            if self.use_transformer and self.model:
                # SentenceTransformerë¥¼ ì‚¬ìš©í•œ ì„ë² ë”© ìƒì„±
                try:
                    embeddings = self.model.encode(preprocessed_texts)
                    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    similarity_matrix = cosine_similarity(embeddings)
                except Exception as e:
                    logger.error(f"SentenceTransformer ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    # Fallback: TF-IDF ì‚¬ìš©
                    tfidf_matrix = self.vectorizer.fit_transform(preprocessed_texts)
                    similarity_matrix = cosine_similarity(tfidf_matrix)
            else:
                # TF-IDF ë²¡í„°í™”
                tfidf_matrix = self.vectorizer.fit_transform(preprocessed_texts)
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                similarity_matrix = cosine_similarity(tfidf_matrix)
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            result = {}
            for i, model1 in enumerate(model_ids):
                result[model1] = {}
                for j, model2 in enumerate(model_ids):
                    result[model1][model2] = float(similarity_matrix[i][j])
            
            return result
            
        except Exception as e:
            logger.error(f"ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ í–‰ë ¬ ë°˜í™˜
            return {model_id: {other_id: 0.0 for other_id in responses} for model_id in responses}
    
      
    def cluster_responses(self, responses):
        """
        ì‘ë‹µì„ ìœ ì‚¬ë„ì— ë”°ë¼ êµ°ì§‘í™”
        
        Args:
            responses (dict): ëª¨ë¸ IDë¥¼ í‚¤ë¡œ, ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê°’ìœ¼ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
            
        Returns:
            dict: êµ°ì§‘í™” ê²°ê³¼
        """
        try:
            model_ids = list(responses.keys())
            if len(model_ids) <= 1:
                return {
                    "similarGroups": [model_ids],
                    "outliers": [],
                    "similarityMatrix": {}
                }
            
            # ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°
            similarity_matrix = self.calculate_similarity_matrix(responses)
            
            # ê³„ì¸µì  í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
            clusters = [[model_id] for model_id in model_ids]
            
            merge_happened = True
            while merge_happened and len(clusters) > 1:
                merge_happened = False
                max_similarity = -1
                merge_indices = [-1, -1]
                
                # ê°€ì¥ ìœ ì‚¬í•œ ë‘ í´ëŸ¬ìŠ¤í„° ì°¾ê¸°
                for i in range(len(clusters)):
                    for j in range(i + 1, len(clusters)):
                        # ë‘ í´ëŸ¬ìŠ¤í„° ê°„ í‰ê·  ìœ ì‚¬ë„ ê³„ì‚°
                        cluster_similarity = 0
                        pair_count = 0
                        
                        for model1 in clusters[i]:
                            for model2 in clusters[j]:
                                cluster_similarity += similarity_matrix[model1][model2]
                                pair_count += 1
                        
                        avg_similarity = cluster_similarity / max(1, pair_count)
                        
                        if avg_similarity > max_similarity:
                            max_similarity = avg_similarity
                            merge_indices = [i, j]
                
                # ì„ê³„ê°’ë³´ë‹¤ ìœ ì‚¬ë„ê°€ ë†’ìœ¼ë©´ í´ëŸ¬ìŠ¤í„° ë³‘í•©
                if max_similarity >= self.threshold:
                    i, j = merge_indices
                    clusters[i].extend(clusters[j])
                    clusters.pop(j)
                    merge_happened = True
            
            # í´ëŸ¬ìŠ¤í„° í¬ê¸°ì— ë”°ë¼ ì •ë ¬
            clusters.sort(key=lambda x: -len(x))
            
            # ì£¼ìš” ê·¸ë£¹ê³¼ ì´ìƒì¹˜ êµ¬ë¶„
            main_group = clusters[0] if clusters else []
            outliers = [model for cluster in clusters[1:] for model in cluster]
            
            # ì‘ë‹µ íŠ¹ì„± ì¶”ì¶œ
            response_features = {model_id: self.extract_response_features(responses[model_id]) 
                                for model_id in model_ids}
            
            return {
                "similarGroups": clusters,
                "mainGroup": main_group,
                "outliers": outliers,
                "similarityMatrix": similarity_matrix,
                "responseFeatures": response_features
            }
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ êµ°ì§‘í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª¨ë“  ëª¨ë¸ì„ í•˜ë‚˜ì˜ ê·¸ë£¹ìœ¼ë¡œ ë°˜í™˜
            return {
                "similarGroups": [model_ids],
                "mainGroup": model_ids,
                "outliers": [],
                "similarityMatrix": {},
                "responseFeatures": {}
            }
    
    
    def extract_response_features(self, text: str) -> Dict[str, Union[int, float, bool]]:
        """
        ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
        
        Args:
            text (str): ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            dict: ì‘ë‹µ íŠ¹ì„± ì •ë³´
        """
        try:
            # ì‘ë‹µ ê¸¸ì´
            length = len(text)
            
            # ì½”ë“œ ë¸”ë¡ ê°œìˆ˜
            code_blocks = re.findall(r'```[\s\S]*?```', text)
            code_block_count = len(code_blocks)
            
            # ë§í¬ ê°œìˆ˜
            links = re.findall(r'\[.*?\]\(.*?\)', text) or re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)
            link_count = len(links)
            
            # ëª©ë¡ í•­ëª© ê°œìˆ˜
            list_items = re.findall(r'^[\s]*[-*+] |^[\s]*\d+\. ', text, re.MULTILINE)
            list_item_count = len(list_items)
            
            # ë¬¸ì¥ ë¶„ë¦¬ (ë‹¤êµ­ì–´ ì§€ì›)
            sentences = re.split(r'[.!?ã€‚ï¼ï¼Ÿ]+', text)
            sentences = [s.strip() for s in sentences if s.strip()]
            
            # í‰ê·  ë¬¸ì¥ ê¸¸ì´
            avg_sentence_length = sum(len(s) for s in sentences) / max(1, len(sentences))
            
            # ì–´íœ˜ ë‹¤ì–‘ì„± (ê³ ìœ  ë‹¨ì–´ ë¹„ìœ¨)
            words = re.findall(r'\b\w+\b', text.lower())
            unique_words = set(words)
            vocabulary_diversity = len(unique_words) / max(1, len(words))
            
            # ì–¸ì–´ ê°ì§€ (ì¶”ê°€ ê¸°ëŠ¥)
            lang_features = self.detect_language_features(text)
            
            features = {
                "length": length,
                "codeBlockCount": code_block_count,
                "linkCount": link_count,
                "listItemCount": list_item_count,
                "sentenceCount": len(sentences),
                "avgSentenceLength": avg_sentence_length,
                "vocabularyDiversity": vocabulary_diversity,
                "hasCode": code_block_count > 0
            }
            
            # ì–¸ì–´ íŠ¹ì„± ì¶”ê°€
            features.update(lang_features)
            
            return features
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ íŠ¹ì„± ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "length": len(text),
                "codeBlockCount": 0,
                "linkCount": 0,
                "listItemCount": 0,
                "sentenceCount": 1,
                "avgSentenceLength": len(text),
                "vocabularyDiversity": 0,
                "hasCode": False,
                "detectedLang": "unknown"
            }
    
    def detect_language_features(self, text: str) -> Dict[str, Any]:
        """
        í…ìŠ¤íŠ¸ì˜ ì–¸ì–´ íŠ¹ì„± ê°ì§€
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            
        Returns:
            dict: ì–¸ì–´ íŠ¹ì„± ì •ë³´
        """
        try:
            # ì–¸ì–´ íŠ¹ì„± ê°ì§€ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±
            # ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” langdetect ë“±ì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
            
            # í•œêµ­ì–´ íŠ¹ì„± (í•œê¸€ ë¹„ìœ¨)
            korean_chars = len(re.findall(r'[ã„±-ã…ã…-ã…£ê°€-í£]', text))
            
            # ì˜ì–´ íŠ¹ì„± (ì˜ë¬¸ ë¹„ìœ¨)
            english_chars = len(re.findall(r'[a-zA-Z]', text))
            
            # ì¼ë³¸ì–´ íŠ¹ì„± (ì¼ë³¸ì–´ ë¬¸ì ë¹„ìœ¨)
            japanese_chars = len(re.findall(r'[ã-ã‚“ã‚¡-ãƒ³ä¸€-é¾¯]', text))
            
            # ì¤‘êµ­ì–´ íŠ¹ì„± (ì¤‘êµ­ì–´ ë¬¸ì ë¹„ìœ¨)
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
            
            # ê¸°íƒ€ ë¬¸ì (ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ì œì™¸)
            total_chars = len(re.findall(r'[^\d\s\W]', text))
            
            # ë¹„ìœ¨ ê³„ì‚°
            total = max(1, total_chars)
            korean_ratio = korean_chars / total
            english_ratio = english_chars / total
            japanese_ratio = japanese_chars / total
            chinese_ratio = chinese_chars / total
            
            # ì£¼ìš” ì–¸ì–´ ê²°ì •
            lang_ratios = {
                "ko": korean_ratio,
                "en": english_ratio,
                "ja": japanese_ratio,
                "zh": chinese_ratio,
                "other": 1.0 - (korean_ratio + english_ratio + japanese_ratio + chinese_ratio)
            }
            
            detected_lang = max(lang_ratios.items(), key=lambda x: x[1])[0]
            
            return {
                "detectedLang": detected_lang,
                "langRatios": lang_ratios
            }
            
        except Exception as e:
            logger.error(f"ì–¸ì–´ íŠ¹ì„± ê°ì§€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "detectedLang": "unknown",
                "langRatios": {"unknown": 1.0}
            }
    
    def compare_responses(self, response1: str, response2: str) -> Dict[str, Any]:
        """
        ë‘ ì‘ë‹µ ê°„ì˜ ìœ ì‚¬ë„ì™€ ì°¨ì´ì  ë¶„ì„
        
        Args:
            response1 (str): ì²« ë²ˆì§¸ ì‘ë‹µ
            response2 (str): ë‘ ë²ˆì§¸ ì‘ë‹µ
            
        Returns:
            dict: ìœ ì‚¬ë„ ë° ì°¨ì´ì  ë¶„ì„ ê²°ê³¼
        """
        try:
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            text1 = self.preprocess_text(response1)
            text2 = self.preprocess_text(response2)
            
            # ì„ë² ë”© ìƒì„± ë° ìœ ì‚¬ë„ ê³„ì‚°
            if self.use_transformer and self.model:
                embeddings = self.model.encode([text1, text2])
                similarity = float(cosine_similarity([embeddings[0]], [embeddings[1]])[0][0])
            else:
                # TF-IDFë¥¼ ì‚¬ìš©í•œ ìœ ì‚¬ë„ ê³„ì‚°
                tfidf_matrix = self.vectorizer.fit_transform([text1, text2])
                similarity = float(cosine_similarity(tfidf_matrix)[0][1])
            
            # ì‘ë‹µ íŠ¹ì„± ë¹„êµ
            features1 = self.extract_response_features(response1)
            features2 = self.extract_response_features(response2)
            
            # íŠ¹ì„± ì°¨ì´ ê³„ì‚°
            feature_diffs = {}
            for key in set(features1.keys()) & set(features2.keys()):
                if isinstance(features1[key], (int, float)) and isinstance(features2[key], (int, float)):
                    feature_diffs[key] = features2[key] - features1[key]
            
            # ì£¼ìš” ì°¨ì´ì  ê³ ìœ  ë‹¨ì–´ ë¶„ì„
            words1 = re.findall(r'\b\w+\b', text1.lower())
            words2 = re.findall(r'\b\w+\b', text2.lower())
            
            counter1 = Counter(words1)
            counter2 = Counter(words2)
            
            unique_to_1 = [word for word, count in counter1.items() if word not in counter2]
            unique_to_2 = [word for word, count in counter2.items() if word not in counter1]
            
            # ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ ê³ ìœ  ë‹¨ì–´ (ìµœëŒ€ 10ê°œ)
            top_unique_to_1 = sorted(
                [(word, counter1[word]) for word in unique_to_1], 
                key=lambda x: x[1], 
                reverse=True
            )[:10]
            
            top_unique_to_2 = sorted(
                [(word, counter2[word]) for word in unique_to_2], 
                key=lambda x: x[1], 
                reverse=True
            )[:10]
            
            return {
                "similarity": similarity,
                "isSimilar": similarity >= self.threshold,
                "features1": features1,
                "features2": features2,
                "featureDiffs": feature_diffs,
                "uniqueWordsTo1": top_unique_to_1,
                "uniqueWordsTo2": top_unique_to_2
            }
            
        except Exception as e:
            logger.error(f"ì‘ë‹µ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "similarity": 0.0,
                "isSimilar": False,
                "error": str(e)
            }
        
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
import logging
import json
import openai
import anthropic
from groq import Groq
from django.conf import settings
import time


logger = logging.getLogger(__name__)

class TextSimplificationView(APIView):
    """
    í…ìŠ¤íŠ¸ë¥¼ ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” API ë·°
    íŠ¹ì • ëŒ€ìƒ(ì–´ë¦°ì´, ê³ ë ¹ì, ì™¸êµ­ì¸ í•™ìŠµì ë“±)ì— ë§ì¶° ë³€í™˜
    """
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            logger.info("ì‰¬ìš´ í‘œí˜„ ë³€í™˜ ìš”ì²­ ë°›ìŒ")
            
            data = request.data
            original_text = data.get('message')
            target_audience = data.get('targetAudience', 'general')
            language = data.get('language', 'ko')
            
            if not original_text:
                return Response({'error': 'ë³€í™˜í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}, 
                               status=status.HTTP_400_BAD_REQUEST)
            
            # í…ìŠ¤íŠ¸ ë‹¨ìˆœí™” ìˆ˜í–‰
            simplifier = TextSimplifier(
                api_key=settings.OPENAI_API_KEY,
                model="gpt-4-turbo",  # ë˜ëŠ” ì„ í˜¸í•˜ëŠ” GPT ëª¨ë¸
                api_type="openai"
            )
            
            result = simplifier.simplify_text(
                original_text=original_text,
                target_audience=target_audience,
                language=language
            )
            
            return Response(result)
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë‹¨ìˆœí™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", exc_info=True)
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class TextSimplifier:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤
    ë‹¤ì–‘í•œ AI ëª¨ë¸ì„ í™œìš©í•˜ì—¬ ëŒ€ìƒìë³„ ë§ì¶¤í˜• ë‹¨ìˆœí™” ìˆ˜í–‰
    """
    def __init__(self, api_key, model, api_type):
        self.model = model
        self.api_type = api_type
        self.api_key = api_key
        
        if api_type == 'openai':
            openai.api_key = api_key
        elif api_type == 'anthropic':
            self.client = anthropic.Anthropic(api_key=api_key)
        elif api_type == 'groq':
            self.client = Groq(api_key=api_key)
    
    def simplify_text(self, original_text, target_audience, language='ko'):
        """
        í…ìŠ¤íŠ¸ë¥¼ ë‹¨ìˆœí™”í•˜ì—¬ ë°˜í™˜
        
        Args:
            original_text (str): ì›ë³¸ í…ìŠ¤íŠ¸
            target_audience (str): ëŒ€ìƒì ìœ í˜• (general, child, elderly, foreigner)
            language (str): ì–¸ì–´ (ê¸°ë³¸ê°’: í•œêµ­ì–´)
            
        Returns:
            dict: ë‹¨ìˆœí™” ê²°ê³¼
        """
        try:
            logger.info(f"í…ìŠ¤íŠ¸ ë‹¨ìˆœí™” ì‹œì‘: ëŒ€ìƒ={target_audience}, ì–¸ì–´={language}")
            
            # ëŒ€ìƒìì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = self._get_simplification_prompt(original_text, target_audience, language)
            
            # AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë‹¨ìˆœí™”
            simplified_text = self._generate_simplified_text(prompt)
            
            # ê²°ê³¼ ë°˜í™˜
            result = {
                'original_text': original_text,
                'simplified_text': simplified_text,
                'target_audience': target_audience,
                'language': language,
                'timestamp': time.time()
            }
            
            logger.info("í…ìŠ¤íŠ¸ ë‹¨ìˆœí™” ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ë‹¨ìˆœí™” ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise
    
    def _get_simplification_prompt(self, original_text, target_audience, language):
        """ëŒ€ìƒì ë§ì¶¤í˜• ë‹¨ìˆœí™” í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        base_prompt = f"""
ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë” ì‰¬ìš´ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”:

{original_text}

ëŒ€ìƒì: {target_audience}
ì–¸ì–´: {language}
"""
        
        if target_audience == 'child':
            base_prompt += """
[ì–´ë¦°ì´ìš© ë³€í™˜ ì§€ì¹¨]
1. 7-12ì„¸ ì–´ë¦°ì´ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ì–´ì™€ í‘œí˜„ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.
2. ì§§ê³  ê°„ë‹¨í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.
3. ì¶”ìƒì ì¸ ê°œë…ì€ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•˜ì„¸ìš”.
4. ì¬ë¯¸ìˆê³  í¥ë¯¸ë¡œìš´ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
5. ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ê°„ë‹¨í•œ ë™ì˜ì–´ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
6. í•„ìš”í•œ ê²½ìš° ë¹„ìœ ì™€ ì˜ˆì‹œë¥¼ í™œìš©í•˜ì„¸ìš”.
7. ë¬¸ì¥ ì‚¬ì´ì— ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì„¸ìš”.
"""
        elif target_audience == 'elderly':
            base_prompt += """
[ê³ ë ¹ììš© ë³€í™˜ ì§€ì¹¨]
1. ëª…í™•í•˜ê³  ì§ì ‘ì ì¸ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
2. ì™¸ë˜ì–´ë‚˜ ì˜ì–´ í‘œí˜„ì€ ê°€ëŠ¥í•œ í•œêµ­ì–´ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
3. ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°ë¥¼ í”¼í•˜ê³  ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
4. ì „ë¬¸ ìš©ì–´ëŠ” ì¼ìƒì ì¸ ìš©ì–´ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
5. ì¹œìˆ™í•œ ë¹„ìœ ì™€ ì˜ˆì‹œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
6. ì¤‘ìš”í•œ ì •ë³´ëŠ” ë°˜ë³µí•´ì„œ ê°•ì¡°í•˜ì„¸ìš”.
7. ë¬¸ì¥ ì‚¬ì´ì— ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì„¸ìš”.
"""
        elif target_audience == 'foreigner':
            base_prompt += """
[ì™¸êµ­ì¸ í•™ìŠµììš© ë³€í™˜ ì§€ì¹¨]
1. í•œêµ­ì–´ í•™ìŠµì(ì´ˆê¸‰~ì¤‘ê¸‰)ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ê¸°ë³¸ ì–´íœ˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
2. ê´€ìš©ì–´, ì†ë‹´, ì€ìœ ì  í‘œí˜„ì„ í”¼í•˜ì„¸ìš”.
3. í•œìì–´ëŠ” ê°€ëŠ¥í•œ ìˆœìš°ë¦¬ë§ë¡œ ëŒ€ì²´í•˜ì„¸ìš”.
4. ë¬¸ë²•ì ìœ¼ë¡œ ë‹¨ìˆœí•œ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
5. ë³µì¡í•œ ì—°ê²°ì–´ë¯¸ë‚˜ ì¡°ì‚¬ ì‚¬ìš©ì„ ìµœì†Œí™”í•˜ì„¸ìš”.
6. ì¤‘ìš”í•œ ê°œë…ì€ ê´„í˜¸ ì•ˆì— ì˜ì–´ë¡œ ë³‘ê¸°í•˜ì„¸ìš”.
7. ë¬¸ì¥ ì‚¬ì´ì— ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì„¸ìš”.
"""
        else:  # general
            base_prompt += """
[ì¼ë°˜ì¸ìš© ë³€í™˜ ì§€ì¹¨]
1. ë³´í¸ì ì¸ êµì–‘ ìˆ˜ì¤€ì˜ ì–´íœ˜ì™€ í‘œí˜„ì„ ì‚¬ìš©í•˜ì„¸ìš”.
2. ë¶ˆí•„ìš”í•˜ê²Œ ë³µì¡í•œ ë¬¸ì¥ êµ¬ì¡°ë¥¼ ë‹¨ìˆœí™”í•˜ì„¸ìš”.
3. ì „ë¬¸ ìš©ì–´ëŠ” ê°„ë‹¨í•œ ì„¤ëª…ê³¼ í•¨ê»˜ ì‚¬ìš©í•˜ì„¸ìš”.
4. ë…¼ë¦¬ì  íë¦„ì„ ìœ ì§€í•˜ë©° ëª…í™•í•˜ê²Œ í‘œí˜„í•˜ì„¸ìš”.
5. ë¹„ìœ ì™€ ì˜ˆì‹œë¥¼ ì ì ˆíˆ í™œìš©í•˜ì„¸ìš”.
6. ì¤‘ìš”í•œ ë‚´ìš©ì„ ê°•ì¡°í•˜ê³  í•µì‹¬ì„ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.
7. ë¬¸ì¥ ì‚¬ì´ì— ì ì ˆí•œ ì¤„ë°”ê¿ˆì„ ì¶”ê°€í•˜ì„¸ìš”.
"""
            
        return base_prompt
    
    def _generate_simplified_text(self, prompt):
        """AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‹¨ìˆœí™”ëœ í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            # API ìœ í˜•ì— ë”°ë¥¸ ë¶„ê¸°
            if self.api_type == 'openai':
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ë³µì¡í•œ í…ìŠ¤íŠ¸ë¥¼ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=2000
                )
                simplified_text = response['choices'][0]['message']['content']
                
            elif self.api_type == 'anthropic':
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.5,
                    system="ë‹¹ì‹ ì€ ë³µì¡í•œ í…ìŠ¤íŠ¸ë¥¼ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.",
                    messages=[{
                        "role": "user", 
                        "content": prompt
                    }]
                )
                simplified_text = message.content[0].text
                
            elif self.api_type == 'groq':
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ë³µì¡í•œ í…ìŠ¤íŠ¸ë¥¼ ë” ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ë³€í™˜í•´ì£¼ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=2000
                )
                simplified_text = response.choices[0].message.content
            
            return simplified_text
            
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {str(e)}", exc_info=True)
            raise




    
import logging
import json
import os
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
from PIL import Image, ImageFilter, ImageEnhance
import pytesseract
from .models import OCRResult
from .serializers import OCRResultSerializer

import PyPDF2
import tempfile
from pdf2image import convert_from_path
import re

logger = logging.getLogger(__name__)

# OllamaClientì™€ GPTTranslator í´ë˜ìŠ¤ ê°€ì ¸ì˜¤ê¸°
from .ollama_client import OllamaClient
from .gpt_translator import GPTTranslator 

@method_decorator(csrf_exempt, name='dispatch')
class ProcessFileView(APIView):
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            logger.info("ProcessFileView ìš”ì²­ ìˆ˜ì‹ : %s %s", request.method, request.path)
            
            # ìš”ì²­ ë°ì´í„° í™•ì¸
            if 'file' not in request.FILES:
                logger.error("íŒŒì¼ì´ ì œê³µë˜ì§€ ì•ŠìŒ")
                return Response({'error': 'íŒŒì¼ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤'}, status=status.HTTP_400_BAD_REQUEST)
            
            file_obj = request.FILES['file']
            file_name = file_obj.name.lower()
            logger.info("íŒŒì¼ ì—…ë¡œë“œ: %s, í¬ê¸°: %s bytes", file_name, file_obj.size)
            
            # Ollama í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            ollama_base_url = os.environ.get('OLLAMA_API_URL', 'http://localhost:11434')
            ollama_client = OllamaClient(base_url=ollama_base_url)
            
            # GPT ë²ˆì—­ê¸° ì´ˆê¸°í™”
            gpt_translator = GPTTranslator()
            
            # ë²ˆì—­ ì˜µì…˜ í™•ì¸ (ê¸°ë³¸ê°’: True)
            enable_translation = request.data.get('enable_translation', 'true').lower() == 'true'
            
            # íŒŒì¼ ìœ í˜• í™•ì¸
            if file_name.endswith(('.pdf')):
                file_type = 'pdf'
                
                # PDF í˜ì´ì§€ ë²”ìœ„ í™•ì¸
                start_page = int(request.data.get('start_page', 1))
                end_page = int(request.data.get('end_page', 0))  # 0ì€ ì „ì²´ í˜ì´ì§€ë¥¼ ì˜ë¯¸
                
                logger.info("PDF ì²˜ë¦¬ ë²”ìœ„: %s ~ %s í˜ì´ì§€", start_page, end_page if end_page > 0 else "ë")
                
            elif file_name.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')):
                file_type = 'image'
            else:
                logger.error("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: %s", file_name)
                return Response({'error': 'ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ë‚˜ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.'},
                              status=status.HTTP_400_BAD_REQUEST)
            
            # OCR ê²°ê³¼ ê°ì²´ ìƒì„±
            ocr_result = OCRResult.objects.create(file=file_obj, file_type=file_type)
            logger.info("OCRResult ê°ì²´ ìƒì„±: %s", ocr_result.id)
            
            # OCR ì²˜ë¦¬
            try:
                ocr_text = ""
                page_texts = []  # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì €ì¥
                
                if file_type == 'image':
                    # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬ - ê°œì„ ëœ OCR ì ìš©
                    img = Image.open(ocr_result.file.path)
                    # ì´ë¯¸ì§€ ì •ë³´ ë¡œê¹…
                    logger.info(f"ì´ë¯¸ì§€ ì •ë³´: í¬ê¸°={img.size}, ëª¨ë“œ={img.mode}, í¬ë§·={img.format}")
                    
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° OCR ìˆ˜í–‰ - OllamaClient ë©”ì„œë“œ ì‚¬ìš©
                    preprocessed_img = ollama_client.preprocess_image_for_ocr(img)
                    ocr_text = ollama_client.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    page_texts.append({"page": 1, "text": ocr_text})
                    logger.info("ì´ë¯¸ì§€ OCR ì²˜ë¦¬ ì™„ë£Œ, ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´: %s", len(ocr_text))
                    logger.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: %s", ocr_text[:200] if ocr_text else "í…ìŠ¤íŠ¸ ì—†ìŒ")
                
                elif file_type == 'pdf':
                    # PDF ì²˜ë¦¬ - ì§ì ‘ ì¶”ì¶œ í›„ í•„ìš”ì‹œ OCR
                    logger.info("PDF ì²˜ë¦¬ ì‹œì‘: %s", ocr_result.file.path)
                    
                    # ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„ (í˜ì´ì§€ë³„)
                    direct_extract_success = False
                    try:
                        all_page_texts = self.extract_text_from_pdf_by_pages(ocr_result.file.path)
                        
                        # í˜ì´ì§€ ë²”ìœ„ ì²˜ë¦¬
                        if start_page > 1 or (end_page > 0 and end_page < len(all_page_texts)):
                            if start_page <= len(all_page_texts):
                                if end_page > 0 and end_page >= start_page:
                                    page_texts = all_page_texts[start_page-1:end_page]
                                else:
                                    page_texts = all_page_texts[start_page-1:]
                            else:
                                page_texts = []
                        else:
                            page_texts = all_page_texts
                        
                        combined_text = "\n".join([page["text"] for page in page_texts])
                        
                        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ ì¶©ë¶„í•œì§€ í™•ì¸ (ë” ì—„ê²©í•œ ì¡°ê±´)
                        if combined_text.strip() and len(combined_text.strip()) >= 50:
                            meaningful_chars = sum(1 for c in combined_text if c.isalnum())
                            if meaningful_chars > 30:  # ì˜ë¯¸ìˆëŠ” ê¸€ìê°€ 30ì ì´ìƒì´ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                                ocr_text = combined_text
                                direct_extract_success = True
                                logger.info("PDF ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ, ì´ %s í˜ì´ì§€, í…ìŠ¤íŠ¸ ê¸¸ì´: %s", 
                                          len(page_texts), len(ocr_text))
                                logger.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: %s", ocr_text[:200] if ocr_text else "í…ìŠ¤íŠ¸ ì—†ìŒ")
                    except Exception as e:
                        logger.error(f"PDF ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
                    
                    # ì§ì ‘ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ì‹¤íŒ¨í•œ ê²½ìš°, OCR ì‹œë„
                    if not direct_extract_success:
                        logger.info("PDF OCR ì²˜ë¦¬ ì‹œì‘ (ì§ì ‘ ì¶”ì¶œ ì‹¤íŒ¨ ë˜ëŠ” í…ìŠ¤íŠ¸ ë¶ˆì¶©ë¶„)")
                        
                        # í˜ì´ì§€ ë²”ìœ„ ì„¤ì •ìœ¼ë¡œ OCR
                        all_page_texts = self.ocr_pdf_by_pages(ocr_result.file.path, ollama_client, start_page, end_page)
                        
                        # í˜ì´ì§€ ë²”ìœ„ ì²˜ë¦¬ - ocr_pdf_by_pagesì—ì„œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ì „ì²´ ì‚¬ìš©
                        page_texts = all_page_texts
                        
                        ocr_text = "\n".join([page["text"] for page in page_texts])
                        logger.info("PDF OCR ì²˜ë¦¬ ì™„ë£Œ, ì´ %s í˜ì´ì§€, í…ìŠ¤íŠ¸ ê¸¸ì´: %s", 
                                  len(page_texts), len(ocr_text))
                        logger.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ: %s", ocr_text[:200] if ocr_text else "í…ìŠ¤íŠ¸ ì—†ìŒ")
                
                # í…ìŠ¤íŠ¸ ì •í™” - ê°œì„ ëœ í•¨ìˆ˜ ì‚¬ìš©
                ocr_result.ocr_text = self.clean_text(ocr_text)
                
                # PDF íŒŒì¼ì€ í•­ìƒ í…ìŠ¤íŠ¸ ê´€ë ¨ ìˆìŒìœ¼ë¡œ ì„¤ì •
                if file_type == 'pdf':
                    text_relevant = True
                
                # ë¶„ì„ ìœ í˜• í™•ì¸ (ê¸°ë³¸ê°’: both)
                analysis_type = request.data.get('analysis_type', 'both')
                logger.info("ë¶„ì„ ìœ í˜•: %s", analysis_type)
                
                # ê²°ê³¼ ë³€ìˆ˜ ì´ˆê¸°í™”
                image_analysis = ""
                text_analysis = ""
                combined_analysis = ""
                
                # ë²ˆì—­ ê²°ê³¼ ë³€ìˆ˜ ì´ˆê¸°í™”
                translated_analysis = ""
                translation_success = False
                translation_error = ""
                
                # í˜ì´ì§€ ë¶„í•  ë¶„ì„ ì—¬ë¶€ í™•ì¸
                analyze_by_page = request.data.get('analyze_by_page', 'true').lower() == 'true'
                
                # ì„ íƒëœ ë¶„ì„ ìœ í˜•ì— ë”°ë¼ ì²˜ë¦¬
                if analysis_type in ['ollama', 'both']:
                    # ì´ë¯¸ì§€ íŒŒì¼ì¸ ê²½ìš°
                    if file_type == 'image':
                        # ì‚¬ìš©ì ì •ì˜ í”„ë¡¬í”„íŠ¸ ì„¤ì • (ìš”ì•½ëœ ê°„ê²°í•œ ì„¤ëª…ì„ ìœ„í•´)
                        custom_prompt = f"""ì´ë¯¸ì§€ë¥¼ ê°ê´€ì ìœ¼ë¡œ ê´€ì°°í•˜ê³  ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì‘ë‹µí•˜ì„¸ìš”:

í•„ìˆ˜ í¬í•¨ ì‚¬í•­:
- ì´ë¯¸ì§€ì— ì‹¤ì œë¡œ ë³´ì´ëŠ” ì‚¬ëŒ, ë™ë¬¼, ë¬¼ì²´ë§Œ ì–¸ê¸‰ (ì—†ìœ¼ë©´ ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ)
- ë§Œì•½ ë™ë¬¼ì´ë¼ë©´, ì–´ë–¤ ì¢…ì˜ ë™ë¬¼ì¸ì§€ë„ ì¶œë ¥
- í™•ì‹¤íˆ ë³´ì´ëŠ” ìƒ‰ìƒë§Œ ì–¸ê¸‰ (ë°°ê²½ìƒ‰, ì˜· ìƒ‰ìƒ ë“±)
- ëª…í™•íˆ ë³´ì´ëŠ” ìì„¸ë‚˜ ìœ„ì¹˜ ê´€ê³„ (ì •ë©´, ì¸¡ë©´ ë“±)

ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ:
- ì¶”ì¸¡ì´ë‚˜ í•´ì„ ("~ë¡œ ë³´ì…ë‹ˆë‹¤", "~ê°™ìŠµë‹ˆë‹¤" í‘œí˜„ ê¸ˆì§€)
- ë³´ì´ì§€ ì•ŠëŠ” ë¶€ë¶„ì— ëŒ€í•œ ì–¸ê¸‰ ("ë³´ì´ì§€ ì•ŠëŠ”ë‹¤", "ì—†ë‹¤" ë“±ì˜ í‘œí˜„ ê¸ˆì§€)
- ë°˜ë³µì ì¸ ì„¤ëª…
- ê°ì •ì´ë‚˜ ë¶„ìœ„ê¸° ë¬˜ì‚¬

í˜•ì‹:
- 1-2ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ê°„ê²°í•˜ê²Œ ì‘ì„±
- ë‹¨ìˆœ ì‚¬ì‹¤ ë‚˜ì—´ í˜•ì‹ (ì˜ˆ: "ì´ë¯¸ì§€ì—ëŠ” ê²€ì€ ë¨¸ë¦¬ ì—¬ì„±ì´ ìˆê³ , ë°°ê²½ì€ í°ìƒ‰ì´ë‹¤.")

OCR í…ìŠ¤íŠ¸ (ì°¸ê³ ìš©, ì‹¤ì œ ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ê²½ìš°ë§Œ ì–¸ê¸‰): {ocr_result.ocr_text}

ì˜ì–´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""

                        
                        # OCR í…ìŠ¤íŠ¸ë¥¼ ì „ë‹¬ (analyze_image ë‚´ë¶€ì—ì„œ ê´€ë ¨ì„± íŒë‹¨)
                        image_analysis = ollama_client.analyze_image(
                            ocr_result.file.path, 
                            custom_prompt,
                            ocr_text=ocr_result.ocr_text
                        )
                        
                        # OCR í…ìŠ¤íŠ¸ ë¶„ì„ (í…ìŠ¤íŠ¸ê°€ ìˆê³  both ëª¨ë“œì¸ ê²½ìš°)
                        if ocr_result.ocr_text and analysis_type == 'both':
                            # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì •ë¦¬ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
                            text_prompt = f"""ë‹¤ìŒ OCRë¡œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ ìì„¸íˆ ë¶„ì„í•˜ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

{ocr_result.ocr_text}

ë¶„ì„ ì§€ì¹¨:
1. í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ë‚´ìš©ê³¼ êµ¬ì¡°ë¥¼ íŒŒì•…í•˜ì—¬ ì •ë¦¬
2. ë‹¨ìˆœ ìš”ì•½ì´ ì•„ë‹Œ, í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶©ì‹¤í•˜ê²Œ ì •ë¦¬
3. ì¤‘ìš”í•œ ì„¸ë¶€ ì •ë³´ë¥¼ í¬í•¨
4. ë‚´ìš©ì´ ì´ë¯¸ì§€ì™€ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ì •ë¦¬

ë°˜ë“œì‹œ "ì˜ì–´(En)"ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
                            
                            try:
                                text_analysis = ollama_client.analyze_text(ocr_result.ocr_text, text_prompt)
                            except Exception as e:
                                logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                                text_analysis = f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                            
                            # ë‘ ë¶„ì„ ê²°ê³¼ ê²°í•©
                            combined_analysis = f"ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼:\n{image_analysis}\n\ní…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼:\n{text_analysis}"
                        else:
                            # OCR ì—†ì´ ì´ë¯¸ì§€ ë¶„ì„ë§Œ ìˆ˜í–‰
                            combined_analysis = image_analysis
                        
                    else:  # PDF íŒŒì¼ì¸ ê²½ìš°
                        if ocr_result.ocr_text:
                            if analyze_by_page and len(page_texts) > 1:
                                # ê°œì„ ëœ í˜ì´ì§€ë³„ ë¶„ì„ ìˆ˜í–‰ - OllamaClientì˜ ë¶„ì„ ê¸°ëŠ¥ í™œìš©
                                try:
                                    combined_analysis = ollama_client.analyze_text(ocr_result.ocr_text, None, page_texts)
                                    logger.info("í˜ì´ì§€ë³„ ë¶„ì„ ì™„ë£Œ")
                                except Exception as e:
                                    logger.error(f"í˜ì´ì§€ë³„ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                                    combined_analysis = f"í˜ì´ì§€ë³„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                            else:
                                # ë¬¸ì„œ ì „ì²´ ë¶„ì„ - í˜ì´ì§€ë³„ êµ¬ì¡°í™” ìš”ì²­
                                text_prompt = f"""ë‹¤ìŒ PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë³„ë¡œ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”:

{ocr_result.ocr_text}

ë¶„ì„ ì§€ì¹¨:
1. í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë‚˜ ì„¹ì…˜ ë‹¨ìœ„ë¡œ êµ¬ë¶„í•˜ì—¬ ì •ë¦¬í•´ì£¼ì„¸ìš”.
2. ë‚´ìš©ì„ ìš”ì•½í•˜ì§€ ë§ê³ , ê° ì„¹ì…˜ì˜ í•µì‹¬ ì •ë³´ë¥¼ ì¶©ì‹¤í•˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
3. ëª¨ë“  ì¤‘ìš”í•œ ì„¸ë¶€ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”.
4. ë‚´ìš©ì„ ë‹¨ìˆœ ìš”ì•½í•˜ì§€ ë§ê³ , êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:
===== í˜ì´ì§€ 1 (ë˜ëŠ” ì„¹ì…˜ 1) =====
- ì£¼ìš” ë‚´ìš© ì •ë¦¬
- ì¤‘ìš” ê°œë… ì„¤ëª…
- í•µì‹¬ ì •ë³´ ë‚˜ì—´

===== í˜ì´ì§€ 2 (ë˜ëŠ” ì„¹ì…˜ 2) =====
- ì£¼ìš” ë‚´ìš© ì •ë¦¬
...

ë°˜ë“œì‹œ "ì˜ì–´ë¡œ" ì‘ë‹µí•´ì£¼ì„¸ìš”."""
                                
                                try:
                                    text_analysis = ollama_client.analyze_text(ocr_result.ocr_text, text_prompt)
                                    combined_analysis = text_analysis
                                except Exception as e:
                                    logger.error(f"ë¬¸ì„œ ì „ì²´ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
                                    combined_analysis = f"ë¬¸ì„œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}\n\nOCR ê²°ê³¼: {ocr_result.ocr_text[:500]}..."
                    
                    logger.info("ì´ë¯¸ì§€/í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ")
                
                # GPT ë²ˆì—­ ìˆ˜í–‰ (ë²ˆì—­ì´ í™œì„±í™”ëœ ê²½ìš°)
                if enable_translation and combined_analysis and gpt_translator.is_available:
                    logger.info("GPT ë²ˆì—­ ì‹œì‘")
                    try:
                        # ë¶„ì„ ìœ í˜•ì— ë”°ë¥¸ ë²ˆì—­
                        if file_type == 'pdf' and analyze_by_page and len(page_texts) > 1:
                            # í˜ì´ì§€ë³„ ë¶„ì„ ê²°ê³¼ ë²ˆì—­
                            translation_result = gpt_translator.translate_paged_analysis(combined_analysis)
                        else:
                            # ì¼ë°˜ ë¶„ì„ ê²°ê³¼ ë²ˆì—­
                            translation_result = gpt_translator.translate_analysis_result(combined_analysis, file_type)
                        
                        if translation_result and translation_result.get("success"):
                            translated_analysis = translation_result["translated_analysis"]
                            translation_success = True
                            logger.info("GPT ë²ˆì—­ ì„±ê³µ")
                        else:
                            error_msg = translation_result.get('error', 'Unknown error') if translation_result else 'No translation result'
                            logger.error(f"GPT ë²ˆì—­ ì‹¤íŒ¨: {error_msg}")
                            translated_analysis = f"ë²ˆì—­ ì‹¤íŒ¨: {error_msg}"
                            translation_error = error_msg
                            
                    except Exception as e:
                        logger.error(f"GPT ë²ˆì—­ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(e)}")
                        translated_analysis = f"ë²ˆì—­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                        translation_error = str(e)
                
                # ë²ˆì—­ ê´€ë ¨ ë©”íƒ€ë°ì´í„° ì €ì¥
                ocr_result.translation_enabled = enable_translation
                ocr_result.translation_success = translation_success
                ocr_result.analysis_type = analysis_type
                ocr_result.analyze_by_page = analyze_by_page
                
                # MySQL ì €ì¥ì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì •í™”
                ocr_result.llm_response = self.clean_text(combined_analysis)
                
                # ë²ˆì—­ ê²°ê³¼ë„ ì €ì¥
                if enable_translation and translated_analysis:
                    if translation_success:
                        # ì„±ê³µí•œ ë²ˆì—­ ê²°ê³¼ ì €ì¥
                        ocr_result.llm_response_korean = self.clean_text(translated_analysis)
                        ocr_result.translation_model = gpt_translator.model if gpt_translator else "unknown"
                    else:
                        # ì‹¤íŒ¨í•œ ê²½ìš° ì˜¤ë¥˜ ë©”ì‹œì§€ ì €ì¥ (ë””ë²„ê¹…ìš©)
                        ocr_result.llm_response_korean = f"ë²ˆì—­ ì‹¤íŒ¨: {translation_error}"
                
                # í…ìŠ¤íŠ¸ ê´€ë ¨ì„± ì •ë³´ ì €ì¥ - PDFëŠ” í•­ìƒ True, ì´ë¯¸ì§€ëŠ” ë¶„ì„ ê³¼ì •ì—ì„œ ê²°ì •
                if file_type == 'pdf':
                    ocr_result.text_relevant = True
                
            except Exception as e:
                logger.error("ì²˜ë¦¬ ì‹¤íŒ¨: %s", str(e), exc_info=True)
                return Response({'error': f'ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}'}, 
                               status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ê²°ê³¼ ì €ì¥
            try:
                ocr_result.save()
                logger.info("OCRResult ì €ì¥ ì™„ë£Œ (ID: %s)", ocr_result.id)
            except Exception as e:
                logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                return Response({'error': f'ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}'}, 
                            status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„± - ëª…ì‹œì ìœ¼ë¡œ í•„ë“œ ì§€ì •
            try:
                # ê¸°ë³¸ ì‹œë¦¬ì–¼ë¼ì´ì € ë°ì´í„°
                response_data = OCRResultSerializer(ocr_result).data
                
                # ë²ˆì—­ ê´€ë ¨ ì •ë³´ ëª…ì‹œì  ì¶”ê°€
                response_data['translation_enabled'] = enable_translation
                response_data['translation_success'] = translation_success
                
                # ì˜ì–´ ì›ë¬¸ê³¼ í•œêµ­ì–´ ë²ˆì—­ì„ ëª…í™•íˆ êµ¬ë¶„
                response_data['llm_response'] = ocr_result.llm_response  # ì˜ì–´ ì›ë¬¸
                
                if enable_translation and translation_success:
                    # ë²ˆì—­ ì„±ê³µ ì‹œ í•œêµ­ì–´ ë²ˆì—­ ì¶”ê°€
                    response_data['llm_response_korean'] = ocr_result.llm_response_korean
                    logger.info("ì‘ë‹µì— í•œêµ­ì–´ ë²ˆì—­ í¬í•¨")
                elif enable_translation and not translation_success:
                    # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì˜¤ë¥˜ ì •ë³´ ì¶”ê°€
                    response_data['llm_response_korean'] = None
                    response_data['translation_error'] = translation_error if translation_error else "ë²ˆì—­ ì‹¤íŒ¨"
                    logger.info("ë²ˆì—­ ì‹¤íŒ¨ - ì˜ì–´ ì›ë¬¸ë§Œ í¬í•¨")
                else:
                    # ë²ˆì—­ ë¹„í™œì„±í™” ì‹œ
                    response_data['llm_response_korean'] = None
                    logger.info("ë²ˆì—­ ë¹„í™œì„±í™” - ì˜ì–´ ì›ë¬¸ë§Œ í¬í•¨")
                
                # ë””ë²„ê¹…ìš© ë¡œê·¸
                logger.info(f"ì‘ë‹µ ë°ì´í„° êµ¬ì„± ì™„ë£Œ:")
                logger.info(f"  - ì˜ì–´ ì›ë¬¸ ê¸¸ì´: {len(response_data.get('llm_response', ''))}")
                logger.info(f"  - í•œêµ­ì–´ ë²ˆì—­ ê¸¸ì´: {len(response_data.get('llm_response_korean', '') or '')}")
                logger.info(f"  - ë²ˆì—­ ì„±ê³µ: {response_data.get('translation_success', False)}")
                
            except Exception as e:
                logger.error(f"ì‘ë‹µ ë°ì´í„° êµ¬ì„± ì‹¤íŒ¨: {str(e)}")
                return Response({'error': f'ì‘ë‹µ êµ¬ì„± ì‹¤íŒ¨: {str(e)}'}, 
                            status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ì‘ë‹µ ë°˜í™˜
            return Response(response_data, status=status.HTTP_201_CREATED)
                
        except Exception as e:
            logger.error("ì²˜ë¦¬ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜: %s", str(e), exc_info=True)
            return Response({'error': f'ì„œë²„ ì˜¤ë¥˜: {str(e)}'}, 
                           status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def extract_text_from_pdf_by_pages(self, pdf_path):
        """PDFì—ì„œ ì§ì ‘ í…ìŠ¤íŠ¸ë¥¼ í˜ì´ì§€ë³„ë¡œ ì¶”ì¶œ"""
        pages = []
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                total_pages = len(reader.pages)
                
                for i in range(total_pages):
                    page = reader.pages[i]
                    text = page.extract_text()
                    pages.append({"page": i + 1, "text": text})
                    
            return pages
        except Exception as e:
            logger.error(f"PDF í…ìŠ¤íŠ¸ ì§ì ‘ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def ocr_pdf_by_pages(self, pdf_path, ollama_client, start_page=1, end_page=0):
        """PDFë¥¼ OCRë¡œ ì²˜ë¦¬í•˜ì—¬ í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        pages = []
        
        try:
            # PDF2Imageë¡œ ì´ë¯¸ì§€ ë³€í™˜
            with tempfile.TemporaryDirectory() as path:
                # í˜ì´ì§€ ë²ˆí˜¸ëŠ” 1ë¶€í„° ì‹œì‘í•˜ì§€ë§Œ, convert_from_pathëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ ì¡°ì •
                first_page = start_page
                last_page = None if end_page <= 0 else end_page
                
                images = convert_from_path(
                    pdf_path, 
                    dpi=300, 
                    output_folder=path, 
                    first_page=first_page,
                    last_page=last_page
                )
                
                # ê° í˜ì´ì§€ ì´ë¯¸ì§€ OCR ì²˜ë¦¬
                for i, image in enumerate(images):
                    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    preprocessed_img = ollama_client.preprocess_image_for_ocr(image)
                    # OCR ìˆ˜í–‰
                    text = ollama_client.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    
                    # í˜ì´ì§€ ë²ˆí˜¸ ê³„ì‚° (ì‹œì‘ í˜ì´ì§€ ê³ ë ¤)
                    page_num = start_page + i
                    pages.append({"page": page_num, "text": text})
                    
            return pages
        except Exception as e:
            logger.error(f"PDF OCR ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            raise
    
    def clean_text(self, text):
        """í…ìŠ¤íŠ¸ ì •í™” í•¨ìˆ˜"""
        if not text:
            return ""
            
        # ì—°ì†ëœ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        # ì—°ì†ëœ ì¤„ë°”ê¿ˆ ì œê±°
        text = re.sub(r'\n\s*\n', '\n\n', text)
        # ì•ë’¤ ê³µë°± ì œê±°
        text = text.strip()
        
        return text
    
# chat/views.pyì— ì¶”ê°€í•  ë·°ë“¤

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from django.shortcuts import get_object_or_404
from datetime import datetime, timedelta
import json
import re
from .models import Schedule, ScheduleRequest, ConflictResolution
from .serializers import (
    ScheduleSerializer, ScheduleRequestSerializer, 
    ConflictResolutionSerializer, ScheduleRequestInputSerializer
)

# ê¸°ì¡´ ChatBot í´ë˜ìŠ¤ì™€ ChatViewëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€...
# chat/views.py ìˆ˜ì • ë²„ì „

# from rest_framework.views import APIView
# from rest_framework.response import Response
# from rest_framework import status
# from rest_framework.decorators import api_view, permission_classes
# from rest_framework.permissions import IsAuthenticated, AllowAny
# from django.shortcuts import get_object_or_404
# from datetime import datetime, timedelta
# import json
# import re
# from .models import Schedule, ScheduleRequest, ConflictResolution
# from .serializers import (
#     ScheduleSerializer, ScheduleRequestSerializer, 
#     ConflictResolutionSerializer, ScheduleRequestInputSerializer
# )

# # ê¸°ì¡´ ChatBot í´ë˜ìŠ¤ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€...
# OPENAI_API_KEY = "***REMOVED***"
# ANTHROPIC_API_KEY = "***REMOVED***"
# GROQ_API_KEY = "***REMOVED***"


# chatbots = {
#     'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
#     'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
#     'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
# }

# # ë°±ì—”ë“œ views.pyì— ì¶”ê°€í•  í•¨ìˆ˜ë“¤

# def parse_date_from_request(request_text):
#     """ìì—°ì–´ ë‚ ì§œë¥¼ ì‹¤ì œ ë‚ ì§œë¡œ ë³€í™˜"""
#     today = datetime.now().date()
    
#     # ì˜¤ëŠ˜/ë‚´ì¼/ëª¨ë ˆ ë“± í•œêµ­ì–´ ë‚ ì§œ í‘œí˜„ ì²˜ë¦¬
#     if 'ì˜¤ëŠ˜' in request_text:
#         return today
#     elif 'ë‚´ì¼' in request_text:
#         return today + timedelta(days=1)
#     elif 'ëª¨ë ˆ' in request_text or 'ëª¨ë˜' in request_text:
#         return today + timedelta(days=2)
#     elif 'ì´ë²ˆ ì£¼' in request_text:
#         # ì´ë²ˆ ì£¼ ê¸ˆìš”ì¼ë¡œ ì„¤ì •
#         days_until_friday = (4 - today.weekday()) % 7
#         if days_until_friday == 0:  # ì˜¤ëŠ˜ì´ ê¸ˆìš”ì¼ì´ë©´ ë‹¤ìŒ ì£¼ ê¸ˆìš”ì¼
#             days_until_friday = 7
#         return today + timedelta(days=days_until_friday)
#     elif 'ë‹¤ìŒ ì£¼' in request_text:
#         return today + timedelta(days=7)
#     else:
#         # ê¸°ë³¸ê°’: ë‚´ì¼
#         return today + timedelta(days=1)

# def parse_multiple_schedules_backend(request_text):
#     """ë°±ì—”ë“œì—ì„œ ì—¬ëŸ¬ ì¼ì • íŒŒì‹±"""
#     # ì‰¼í‘œ, "ê·¸ë¦¬ê³ ", "ë°" ë“±ìœ¼ë¡œ ë¶„ë¦¬
#     separators = [',', 'ï¼Œ', 'ê·¸ë¦¬ê³ ', 'ë°', 'ì™€', 'ê³¼']
    
#     parts = [request_text]
#     for sep in separators:
#         new_parts = []
#         for part in parts:
#             new_parts.extend(part.split(sep))
#         parts = new_parts
    
#     # ì •ë¦¬ëœ ìš”ì²­ë“¤ ë°˜í™˜
#     cleaned_requests = []
#     for part in parts:
#         cleaned = part.strip()
#         if cleaned and len(cleaned) > 2:  # ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸
#             cleaned_requests.append(cleaned)
    
#     return cleaned_requests if len(cleaned_requests) > 1 else [request_text]
# class ScheduleOptimizerBot:
#     """ì¼ì • ìµœì í™”ë¥¼ ìœ„í•œ AI ë´‡ í´ë˜ìŠ¤ - ì—¬ëŸ¬ AI ëª¨ë¸ ì—°ë™"""
    
#     def __init__(self):
#         self.chatbots = {
#                 'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
#                 'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
#                 'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
#             }
        
#     def create_schedule_prompt(self, request_text, user_context=None, existing_schedules=None):
#         """ì¼ì • ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„± - ë¹ˆ ì‹œê°„ ë¶„ì„ í¬í•¨"""
#         base_prompt = f"""
#         ì‚¬ìš©ìì˜ ì¼ì • ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ìµœì ì˜ ë¹ˆ ì‹œê°„ì„ ì°¾ì•„ ì œì•ˆí•´ì£¼ì„¸ìš”.

#         ìš”ì²­ ë‚´ìš©: {request_text}
        
#         ê¸°ì¡´ ì¼ì •ë“¤: {existing_schedules or []}
        
#         ë¶„ì„ ë°©ë²•:
#         1. ê¸°ì¡´ ì¼ì •ë“¤ì˜ ì‹œê°„ëŒ€ë¥¼ í™•ì¸í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë‚ ì˜ ë¹ˆ ì‹œê°„ì„ ì°¾ì•„ì£¼ì„¸ìš”
#         2. ìš”ì²­ëœ ì¼ì •ì˜ ì„±ê²©ì— ë§ëŠ” ìµœì ì˜ ì‹œê°„ëŒ€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”
#         3. ì¼ì • ê°„ ì—¬ìœ  ì‹œê°„ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”
        
#         ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
#         {{
#             "title": "ì¼ì • ì œëª©",
#             "description": "ìƒì„¸ ì„¤ëª…",
#             "suggested_date": "YYYY-MM-DD",
#             "suggested_start_time": "HH:MM",
#             "suggested_end_time": "HH:MM",
#             "location": "ì¥ì†Œ (ì„ íƒì‚¬í•­)",
#             "priority": "HIGH/MEDIUM/LOW/URGENT",
#             "attendees": ["ì°¸ì„ì1", "ì°¸ì„ì2"],
#             "reasoning": "ì´ ì‹œê°„ì„ ì œì•ˆí•˜ëŠ” ì´ìœ  (ë¹ˆ ì‹œê°„ ë¶„ì„ ê²°ê³¼ í¬í•¨)"
#         }}
        
#         ì‚¬ìš©ìì˜ ë§¥ë½ ì •ë³´: {user_context or "ì—†ìŒ"}
#         """
#         return base_prompt

#     def create_conflict_resolution_prompt(self, conflicting_schedules, new_request):
#         """ì¼ì • ì¶©ëŒ í•´ê²°ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
#         prompt = f"""
#         ê¸°ì¡´ ì¼ì •ê³¼ ìƒˆë¡œìš´ ì¼ì • ìš”ì²­ ì‚¬ì´ì— ì¶©ëŒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. 
#         ì—¬ëŸ¬ AIì˜ ê´€ì ì—ì„œ ìµœì ì˜ í•´ê²° ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

#         ê¸°ì¡´ ì¶©ëŒ ì¼ì •ë“¤:
#         {json.dumps(conflicting_schedules, ensure_ascii=False, indent=2)}

#         ìƒˆë¡œìš´ ì¼ì • ìš”ì²­: {new_request}

#         ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ í•´ê²° ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”:
#         {{
#             "resolution_options": [
#                 {{
#                     "option": "ë°©ì•ˆ 1",
#                     "description": "ìƒì„¸ ì„¤ëª…",
#                     "impact": "ì˜í–¥ë„ ë¶„ì„",
#                     "recommended": true/false
#                 }},
#                 {{
#                     "option": "ë°©ì•ˆ 2", 
#                     "description": "ìƒì„¸ ì„¤ëª…",
#                     "impact": "ì˜í–¥ë„ ë¶„ì„",
#                     "recommended": true/false
#                 }}
#             ],
#             "best_recommendation": "ê°€ì¥ ì¶”ì²œí•˜ëŠ” ë°©ì•ˆê³¼ ì´ìœ "
#         }}
#         """
#         return prompt
    
#     def get_ai_suggestions(self, prompt, suggestion_type="schedule"):
#         """ì—¬ëŸ¬ AI ëª¨ë¸ë¡œë¶€í„° ì œì•ˆë°›ê¸°"""
#         suggestions = {}
        
#         for model_name, chatbot in self.chatbots.items():
#             try:
#                 response = chatbot.chat(prompt)
#                 suggestions[f"{model_name}_suggestion"] = response
#             except Exception as e:
#                 suggestions[f"{model_name}_suggestion"] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
#         return suggestions
    
#     def analyze_and_optimize_suggestions(self, suggestions, query, selected_models=['GPT', 'Claude', 'Mixtral']):
#         """ì—¬ëŸ¬ AI ì œì•ˆì„ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ê²°ê³¼ ìƒì„± - ê¸°ì¡´ analyze_responses í™œìš©"""
#         try:
#             # ChatBotì˜ analyze_responses ê¸°ëŠ¥ í™œìš©
#             analyzer = self.chatbots['claude']  # Claudeë¥¼ ë¶„ì„ìš©ìœ¼ë¡œ ì‚¬ìš©
            
#             # ì œì•ˆì„ ë¶„ì„ìš© í˜•íƒœë¡œ ë³€í™˜
#             responses_for_analysis = {}
#             for key, suggestion in suggestions.items():
#                 model_name = key.replace('_suggestion', '')
#                 responses_for_analysis[model_name] = suggestion
            
#             # ê¸°ì¡´ analyze_responses ë©”ì„œë“œ í™œìš©
#             analysis_result = analyzer.analyze_responses(
#                 responses_for_analysis, 
#                 query, 
#                 'Korean',  # ê¸°ë³¸ ì–¸ì–´
#                 selected_models
#             )
            
#             # JSON ì‘ë‹µì—ì„œ ìµœì í™”ëœ ì¼ì • ì •ë³´ ì¶”ì¶œ
#             try:
#                 # best_responseì—ì„œ JSON ë¶€ë¶„ ì¶”ì¶œ
#                 json_match = re.search(r'\{.*\}', analysis_result.get('best_response', ''), re.DOTALL)
#                 if json_match:
#                     optimized = json.loads(json_match.group())
#                 else:
#                     # fallback: ì²« ë²ˆì§¸ ìœ íš¨í•œ ì œì•ˆ ì‚¬ìš©
#                     optimized = self._extract_first_valid_suggestion(suggestions)
#             except:
#                 optimized = self._extract_first_valid_suggestion(suggestions)
            
#             confidence = self._calculate_confidence_from_analysis(analysis_result)
            
#             return {
#                 "optimized_suggestion": optimized,
#                 "confidence_score": confidence,
#                 "ai_analysis": analysis_result,
#                 "individual_suggestions": self._parse_individual_suggestions(suggestions)
#             }
            
#         except Exception as e:
#             print(f"Analysis error: {str(e)}")
#             return {"error": f"ìµœì í™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
#     def _extract_first_valid_suggestion(self, suggestions):
#         """ì²« ë²ˆì§¸ ìœ íš¨í•œ ì œì•ˆ ì¶”ì¶œ"""
#         for key, suggestion in suggestions.items():
#             try:
#                 json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group())
#             except:
#                 continue
        
#         # ê¸°ë³¸ ì œì•ˆ ë°˜í™˜
#         return {
#             "title": "ìƒˆ ì¼ì •",
#             "description": "AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤",
#             "suggested_date": datetime.now().strftime('%Y-%m-%d'),
#             "suggested_start_time": "09:00",
#             "suggested_end_time": "10:00",
#             "location": "",
#             "priority": "MEDIUM",
#             "attendees": [],
#             "reasoning": "ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ì œì•ˆì„ ì¢…í•©í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
#         }
    
#     def _calculate_confidence_from_analysis(self, analysis_result):
#         """ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹ ë¢°ë„ ê³„ì‚°"""
#         reasoning = analysis_result.get('reasoning', '')
        
#         # í‚¤ì›Œë“œ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
#         confidence_keywords = ['ì¼ì¹˜', 'ê³µí†µ', 'ì •í™•', 'ìµœì ', 'ì¶”ì²œ']
#         uncertainty_keywords = ['ë¶ˆí™•ì‹¤', 'ì¶”ì •', 'ê°€ëŠ¥ì„±', 'ì–´ë ¤ì›€']
        
#         confidence_score = 0.5  # ê¸°ë³¸ê°’
        
#         for keyword in confidence_keywords:
#             if keyword in reasoning:
#                 confidence_score += 0.1
        
#         for keyword in uncertainty_keywords:
#             if keyword in reasoning:
#                 confidence_score -= 0.1
        
#         return max(0.1, min(1.0, confidence_score))
    
#     def _parse_individual_suggestions(self, suggestions):
#         """ê°œë³„ ì œì•ˆë“¤ì„ íŒŒì‹±"""
#         parsed = []
#         for key, suggestion in suggestions.items():
#             try:
#                 json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
#                 if json_match:
#                     parsed_suggestion = json.loads(json_match.group())
#                     parsed_suggestion['source'] = key.replace('_suggestion', '')
#                     parsed.append(parsed_suggestion)
#             except:
#                 continue
#         return parsed

# class ScheduleManagementView(APIView):
#     """ì¼ì • ê´€ë¦¬ ë©”ì¸ ë·° - ê¶Œí•œ ìˆ˜ì •"""
#     # ì„ì‹œë¡œ AllowAnyë¡œ ë³€ê²½ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
#     permission_classes = [IsAuthenticated]
    
#     def __init__(self):
#         super().__init__()
#         self.optimizer = ScheduleOptimizerBot()
    
#     def get(self, request):
#         """ì‚¬ìš©ìì˜ ì¼ì • ëª©ë¡ ì¡°íšŒ"""
#         # ğŸš« ê¸°ì¡´ ë”ë¯¸ ì‚¬ìš©ì ë¡œì§ ì œê±°
#         if not request.user.is_authenticated:
#             return Response({'error': 'ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=status.HTTP_401_UNAUTHORIZED)
        
#         schedules = Schedule.objects.filter(user=request.user).order_by('start_time')
        
#         # ë‚ ì§œ í•„í„°ë§ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
#         start_date = request.query_params.get('start_date')
#         end_date = request.query_params.get('end_date')
        
#         if start_date:
#             schedules = schedules.filter(start_time__date__gte=start_date)
#         if end_date:
#             schedules = schedules.filter(end_time__date__lte=end_date)
        
#         serializer = ScheduleSerializer(schedules, many=True)
#         return Response(serializer.data)
#     def post(self, request):
#         """ìƒˆë¡œìš´ ì¼ì • ìƒì„± ìš”ì²­ - ì—¬ëŸ¬ ì¼ì • ì§€ì› ê°œì„ """
#         try:
#             request_text = request.data.get('request_text', '')
#             existing_schedules = request.data.get('existing_schedules', [])
            
#             if not request_text:
#                 return Response({'error': 'ìš”ì²­ í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, 
#                             status=status.HTTP_400_BAD_REQUEST)
#             if not request.user.is_authenticated:
#                 return Response({'error': 'ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=status.HTTP_401_UNAUTHORIZED)
        
#             user = request.user

         
            
#             # ì—¬ëŸ¬ ì¼ì • ìš”ì²­ì¸ì§€ í™•ì¸
#             schedule_requests = parse_multiple_schedules_backend(request_text)
#             target_date = parse_date_from_request(request_text)
            
#             if len(schedule_requests) > 1:
#                 # ì—¬ëŸ¬ ì¼ì • ì²˜ë¦¬
#                 multiple_schedules = []
#                 all_individual_suggestions = []
                
#                 for i, single_request in enumerate(schedule_requests):
#                     # ê° ì¼ì •ì˜ ì‹œì‘ ì‹œê°„ì„ ë‹¤ë¥´ê²Œ ì„¤ì •
#                     schedule_date = target_date
#                     if i > 0:  # ë‘ ë²ˆì§¸ ì¼ì •ë¶€í„°ëŠ” 2ì‹œê°„ì”© ë’¤ë¡œ
#                         base_hour = 9 + (i * 2)
#                     else:
#                         base_hour = 9
                    
#                     # ê°œë³„ ì¼ì • ìƒì„±
#                     optimized_schedule = {
#                         "title": self._extract_schedule_title(single_request),
#                         "description": f"AIê°€ ë¶„ì„í•œ {self._extract_schedule_title(single_request)} ì¼ì •ì…ë‹ˆë‹¤.",
#                         "suggested_date": schedule_date.strftime('%Y-%m-%d'),
#                         "suggested_start_time": f"{base_hour:02d}:00",
#                         "suggested_end_time": f"{base_hour + 2:02d}:00",
#                         "location": self._extract_schedule_location(single_request),
#                         "priority": "HIGH",
#                         "attendees": [],
#                         "reasoning": f"{i + 1}ë²ˆì§¸ ì¼ì •: {single_request}. ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ì‹œê°„ìœ¼ë¡œ ë°°ì •í–ˆìŠµë‹ˆë‹¤."
#                     }
#                     multiple_schedules.append(optimized_schedule)
                    
#                     # ê° AIë³„ ê°œë³„ ì œì•ˆ ìƒì„±
#                     for ai_type in ['gpt', 'claude', 'mixtral']:
#                         individual_suggestion = optimized_schedule.copy()
#                         individual_suggestion['source'] = ai_type
#                         individual_suggestion['reasoning'] = f"{ai_type.upper()}ê°€ ë¶„ì„í•œ {self._extract_schedule_title(single_request)} ìµœì  ì‹œê°„ì…ë‹ˆë‹¤."
#                         all_individual_suggestions.append(individual_suggestion)
                
#                 # ì—¬ëŸ¬ ì¼ì • ì‘ë‹µ ìƒì„±
#                 response_data = {
#                     'request_id': int(datetime.now().timestamp()),
#                     'multiple_schedules': multiple_schedules,
#                     'optimized_suggestion': multiple_schedules[0],
#                     'confidence_score': 0.92,
#                     'individual_suggestions': all_individual_suggestions,
#                     'ai_analysis': {
#                         'analysis_summary': f"ì´ {len(schedule_requests)}ê°œì˜ ì¼ì •ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì‹œê°„ëŒ€ë¡œ ë°°ì •í–ˆìŠµë‹ˆë‹¤.",
#                         'reasoning': f"ì—¬ëŸ¬ ì¼ì •ì„ {target_date.strftime('%Yë…„ %mì›” %dì¼')}ì— ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í–ˆìŠµë‹ˆë‹¤.",
#                         'models_used': ["gpt", "claude", "mixtral"]
#                     },
#                     'has_conflicts': False,
#                     'conflicts': [],
#                     'analysis_summary': f"{len(schedule_requests)}ê°œ ì¼ì •ì— ëŒ€í•´ 3ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
#                     'is_multiple_schedule': True
#                 }
                
#             else:
#                 # ë‹¨ì¼ ì¼ì • ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì‚¬ìš©í•˜ë˜ ë‚ ì§œ ë°˜ì˜)
#                 user_context = self._get_user_context(user)
                
#                 # ë‚ ì§œê°€ ë°˜ì˜ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±
#                 enhanced_prompt = f"""
#                 ì‚¬ìš©ìì˜ ì¼ì • ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ìµœì ì˜ ë¹ˆ ì‹œê°„ì„ ì°¾ì•„ ì œì•ˆí•´ì£¼ì„¸ìš”.
                
#                 ìš”ì²­ ë‚´ìš©: {request_text}
#                 ëª©í‘œ ë‚ ì§œ: {target_date.strftime('%Yë…„ %mì›” %dì¼')} ({self._get_weekday_korean(target_date)})
#                 ê¸°ì¡´ ì¼ì •ë“¤: {existing_schedules or []}
                
#                 ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
#                 {{
#                     "title": "ì¼ì • ì œëª©",
#                     "description": "ìƒì„¸ ì„¤ëª…",
#                     "suggested_date": "{target_date.strftime('%Y-%m-%d')}",
#                     "suggested_start_time": "HH:MM",
#                     "suggested_end_time": "HH:MM",
#                     "location": "ì¥ì†Œ",
#                     "priority": "HIGH/MEDIUM/LOW/URGENT",
#                     "attendees": [],
#                     "reasoning": "ì´ ì‹œê°„ì„ ì œì•ˆí•˜ëŠ” ì´ìœ "
#                 }}
#                 """
                
#                 # ê¸°ì¡´ ë‹¨ì¼ ì¼ì • ë¡œì§ ê³„ì†...
#                 suggestions = self.optimizer.get_ai_suggestions(enhanced_prompt)
#                 optimized_result = self.optimizer.analyze_and_optimize_suggestions(
#                     suggestions, f"ì¼ì • ìš”ì²­: {request_text}"
#                 )
                
#                 response_data = {
#                     'request_id': int(datetime.now().timestamp()),
#                     'optimized_suggestion': optimized_result.get('optimized_suggestion', {}),
#                     'confidence_score': optimized_result.get('confidence_score', 0.0),
#                     'ai_analysis': optimized_result.get('ai_analysis', {}),
#                     'individual_suggestions': optimized_result.get('individual_suggestions', []),
#                     'has_conflicts': False,
#                     'conflicts': [],
#                     'analysis_summary': "3ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
#                     'is_multiple_schedule': False
#                 }
            
#             return Response(response_data, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#                     return Response({
#                         'error': f'ì¼ì • ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
#                     }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

#     def _extract_schedule_title(self, request):
#             """ìš”ì²­ì—ì„œ ì¼ì • ì œëª© ì¶”ì¶œ"""
#             if 'ìš´ë™' in request:
#                 return 'ìš´ë™'
#             elif 'ë¯¸íŒ…' in request or 'íšŒì˜' in request:
#                 return 'íŒ€ ë¯¸íŒ…'
#             elif 'ê³µë¶€' in request or 'í•™ìŠµ' in request:
#                 return 'í•™ìŠµ ì‹œê°„'
#             elif 'ì‘ì—…' in request or 'ì—…ë¬´' in request:
#                 return 'ì§‘ì¤‘ ì‘ì—…'
#             elif 'ì•½ì†' in request:
#                 return 'ì•½ì†'
#             else:
#                 return 'ìƒˆ ì¼ì •'

#     def _extract_schedule_location(self, request):
#             """ìš”ì²­ì—ì„œ ì¥ì†Œ ì¶”ì¶œ"""
#             if 'ìš´ë™' in request:
#                 return 'í—¬ìŠ¤ì¥'
#             elif 'ë¯¸íŒ…' in request or 'íšŒì˜' in request:
#                 return 'íšŒì˜ì‹¤'
#             elif 'ê³µë¶€' in request or 'í•™ìŠµ' in request:
#                 return 'ë„ì„œê´€'
#             elif 'ì»¤í”¼' in request:
#                 return 'ì¹´í˜'
#             else:
#                 return 'ì‚¬ë¬´ì‹¤'

#     def _get_weekday_korean(self, date):
#             """ìš”ì¼ì„ í•œêµ­ì–´ë¡œ ë°˜í™˜"""
#             weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
#             return weekdays[date.weekday()]
            
   
#     def _check_schedule_conflicts(self, user, suggestion):
#         """ì¼ì • ì¶©ëŒ ê²€ì‚¬"""
#         if not suggestion or 'suggested_date' not in suggestion:
#             return []
        
#         try:
#             suggested_date = datetime.strptime(suggestion['suggested_date'], '%Y-%m-%d').date()
#             start_time = datetime.strptime(suggestion.get('suggested_start_time', '09:00'), '%H:%M').time()
#             end_time = datetime.strptime(suggestion.get('suggested_end_time', '10:00'), '%H:%M').time()
            
#             suggested_start = datetime.combine(suggested_date, start_time)
#             suggested_end = datetime.combine(suggested_date, end_time)
            
#             conflicts = Schedule.objects.filter(
#                 user=user,
#                 start_time__date=suggested_date,
#                 start_time__lt=suggested_end,
#                 end_time__gt=suggested_start
#             )
            
#             return [ScheduleSerializer(conflict).data for conflict in conflicts]
            
#         except Exception as e:
#             return []

# # ê¶Œí•œ ìˆ˜ì •ëœ í•¨ìˆ˜ë“¤
# @api_view(['POST'])
# @permission_classes([IsAuthenticated])  # ğŸ”§ ê¶Œí•œ ë³€ê²½
# def confirm_schedule(request, request_id):
#     """AI ì œì•ˆëœ ì¼ì •ì„ í™•ì •í•˜ì—¬ ì‹¤ì œ ì¼ì •ìœ¼ë¡œ ìƒì„±"""
#     try:
#         user = request.user
        
#         # ğŸš« ScheduleRequest.DoesNotExistì—ì„œ ë”ë¯¸ ë°ì´í„° ìƒì„± ì œê±°
#         try:
#             schedule_request = ScheduleRequest.objects.get(id=request_id, user=user)
#             optimized_suggestion = json.loads(schedule_request.optimized_suggestion)
#         except ScheduleRequest.DoesNotExist:
#             return Response({
#                 'error': f'ìš”ì²­ ID {request_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
#             }, status=status.HTTP_404_NOT_FOUND)
#                 # ë‚ ì§œ/ì‹œê°„ íŒŒì‹± ê°œì„ 
#         try:
#             suggested_date = optimized_suggestion.get('suggested_date')
#             suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
#             suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
            
#             # ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
#             if isinstance(suggested_date, str):
#                 if 'T' in suggested_date:  # ISO í˜•ì‹ì¸ ê²½ìš°
#                     suggested_date = suggested_date.split('T')[0]
                
#                 start_datetime = datetime.strptime(
#                     f"{suggested_date} {suggested_start_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#                 end_datetime = datetime.strptime(
#                     f"{suggested_date} {suggested_end_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#             else:
#                 # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ë¡œ ì„¤ì •
#                 today = datetime.now().date()
#                 start_datetime = datetime.strptime(
#                     f"{today} {suggested_start_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#                 end_datetime = datetime.strptime(
#                     f"{today} {suggested_end_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
                
#         except (ValueError, TypeError) as e:
#             print(f"DateTime parsing error: {e}")
#             # ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±
#             now = datetime.now()
#             start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
#             end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
        
#         # Schedule ê°ì²´ ìƒì„±
#         schedule_data = {
#             'user': user,
#             'title': optimized_suggestion.get('title', 'ìƒˆ ì¼ì •'),
#             'description': optimized_suggestion.get('description', 'AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤.'),
#             'start_time': start_datetime,
#             'end_time': end_datetime,
#             'location': optimized_suggestion.get('location', ''),
#             'priority': optimized_suggestion.get('priority', 'MEDIUM'),
#             'attendees': json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
#         }
        
#         schedule = Schedule.objects.create(**schedule_data)
#         serializer = ScheduleSerializer(schedule)
        
#         print(f"Schedule created successfully: {schedule.id}")
        
#         return Response({
#             'message': 'ì—¬ëŸ¬ AIì˜ ë¶„ì„ì„ í†µí•´ ìµœì í™”ëœ ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
#             'schedule': serializer.data
#         }, status=status.HTTP_201_CREATED)
        
#     except Exception as e:
#         print(f"Confirm schedule error: {str(e)}")
#         import traceback
#         traceback.print_exc()
        
#         return Response({
#             'error': f'ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
#         }, status=status.HTTP_400_BAD_REQUEST)


# # Alternative solution: Convert to Class-Based View
# class ConfirmScheduleView(APIView):
#     """AI ì œì•ˆëœ ì¼ì •ì„ í™•ì •í•˜ì—¬ ì‹¤ì œ ì¼ì •ìœ¼ë¡œ ìƒì„±"""
#     permission_classes = [AllowAny]  # ì„ì‹œë¡œ AllowAny
    
#     def post(self, request, request_id):
#         try:
#             # ì‚¬ìš©ì ì²˜ë¦¬
#             if not request.user.is_authenticated:
#                 return Response({'error': 'ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.'}, status=status.HTTP_401_UNAUTHORIZED)

#             user = request.user
            
#             # request_idë¡œ ScheduleRequestë¥¼ ì°¾ê±°ë‚˜ ë”ë¯¸ ë°ì´í„° ì²˜ë¦¬
#             try:
#                 schedule_request = ScheduleRequest.objects.get(id=request_id, user=user)
#                 optimized_suggestion = json.loads(schedule_request.optimized_suggestion)
#             except ScheduleRequest.DoesNotExist:
#                 # ë”ë¯¸ ëª¨ë“œ: request_idë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ì¼ì • ìƒì„±
#                 print(f"ScheduleRequest {request_id} not found, creating dummy schedule")
#                 optimized_suggestion = {
#                     'title': 'AI ì œì•ˆ ì¼ì •',
#                     'description': 'AIê°€ ì œì•ˆí•œ ìµœì ì˜ ì¼ì •ì…ë‹ˆë‹¤.',
#                     'suggested_date': datetime.now().strftime('%Y-%m-%d'),
#                     'suggested_start_time': '09:00',
#                     'suggested_end_time': '10:00',
#                     'location': 'ì‚¬ë¬´ì‹¤',
#                     'priority': 'MEDIUM',
#                     'attendees': []
#                 }
#             except json.JSONDecodeError as e:
#                 print(f"JSON decode error: {e}")
#                 return Response({
#                     'error': f'ì¼ì • ë°ì´í„° íŒŒì‹± ì˜¤ë¥˜: {str(e)}'
#                 }, status=status.HTTP_400_BAD_REQUEST)
            
#             # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
#             try:
#                 suggested_date = optimized_suggestion.get('suggested_date')
#                 suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
#                 suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
                
#                 # ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜
#                 if isinstance(suggested_date, str):
#                     if 'T' in suggested_date:  # ISO í˜•ì‹ì¸ ê²½ìš°
#                         suggested_date = suggested_date.split('T')[0]
                    
#                     start_datetime = datetime.strptime(
#                         f"{suggested_date} {suggested_start_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                     end_datetime = datetime.strptime(
#                         f"{suggested_date} {suggested_end_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                 else:
#                     # ë‚ ì§œê°€ ì—†ìœ¼ë©´ ì˜¤ëŠ˜ë¡œ ì„¤ì •
#                     today = datetime.now().date()
#                     start_datetime = datetime.strptime(
#                         f"{today} {suggested_start_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                     end_datetime = datetime.strptime(
#                         f"{today} {suggested_end_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
                    
#             except (ValueError, TypeError) as e:
#                 print(f"DateTime parsing error: {e}")
#                 # ê¸°ë³¸ê°’ìœ¼ë¡œ í´ë°±
#                 now = datetime.now()
#                 start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
#                 end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
            
#             # Schedule ê°ì²´ ìƒì„±
#             schedule_data = {
#                 'user': user,
#                 'title': optimized_suggestion.get('title', 'ìƒˆ ì¼ì •'),
#                 'description': optimized_suggestion.get('description', 'AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤.'),
#                 'start_time': start_datetime,
#                 'end_time': end_datetime,
#                 'location': optimized_suggestion.get('location', ''),
#                 'priority': optimized_suggestion.get('priority', 'MEDIUM'),
#                 'attendees': json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
#             }
            
#             schedule = Schedule.objects.create(**schedule_data)
#             serializer = ScheduleSerializer(schedule)
            
#             print(f"Schedule created successfully: {schedule.id}")
            
#             return Response({
#                 'message': 'ì—¬ëŸ¬ AIì˜ ë¶„ì„ì„ í†µí•´ ìµœì í™”ëœ ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
#                 'schedule': serializer.data
#             }, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#             print(f"Confirm schedule error: {str(e)}")
#             import traceback
#             traceback.print_exc()
            
#             return Response({
#                 'error': f'ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
#             }, status=status.HTTP_400_BAD_REQUEST)


# # Fix for resolve_schedule_conflict function
# @api_view(['POST'])
# @permission_classes([IsAuthenticated])  # ğŸ”§ ê¶Œí•œ ë³€ê²½
# def resolve_schedule_conflict(request):
#     """ì¼ì • ì¶©ëŒ í•´ê²° ë°©ì•ˆ ì œê³µ"""
#     # ğŸš« ë”ë¯¸ ì‚¬ìš©ì ë¡œì§ ì œê±°
#     user = request.user
    
#     conflicting_schedule_ids = request.data.get('conflicting_schedule_ids', [])
#     new_request = request.data.get('new_request', '')
    
#     # ë‚˜ë¨¸ì§€ ë¡œì§ì€ ê·¸ëŒ€ë¡œ...
    
#     if not conflicting_schedule_ids or not new_request:
#         return Response({
#             'error': 'ì¶©ëŒ ì¼ì • IDì™€ ìƒˆë¡œìš´ ìš”ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤.'
#         }, status=status.HTTP_400_BAD_REQUEST)
    
#     try:
#         # ì‚¬ìš©ì ì²˜ë¦¬
#         if request.user.is_authenticated:
#             user = request.user
#         else:
#             from django.contrib.auth.models import User
#             user, created = User.objects.get_or_create(
#                 username='dummy_user',
#                 defaults={'email': 'dummy@example.com'}
#             )
        
#         # ì¶©ëŒ ì¼ì •ë“¤ ì¡°íšŒ
#         conflicting_schedules = Schedule.objects.filter(
#             id__in=conflicting_schedule_ids,
#             user=user
#         )
        
#         conflicting_data = [ScheduleSerializer(schedule).data for schedule in conflicting_schedules]
        
#         # ë‹¤ì¤‘ AI ëª¨ë¸ë“¤ë¡œë¶€í„° í•´ê²° ë°©ì•ˆ ë°›ê¸°
#         optimizer = ScheduleOptimizerBot()
#         prompt = optimizer.create_conflict_resolution_prompt(conflicting_data, new_request)
#         suggestions = optimizer.get_ai_suggestions(prompt, "conflict_resolution")
        
#         # AI ë¶„ì„ì„ í†µí•œ ìµœì  í•´ê²°ë°©ì•ˆ ë„ì¶œ
#         analysis_result = optimizer.analyze_and_optimize_suggestions(
#             suggestions,
#             f"ì¶©ëŒ í•´ê²°: {new_request}"
#         )
        
#         # í•´ê²° ë°©ì•ˆ ì €ì¥
#         conflict_resolution = ConflictResolution.objects.create(
#             user=user,
#             conflicting_schedules=json.dumps(conflicting_data, ensure_ascii=False),
#             resolution_options=json.dumps(suggestions, ensure_ascii=False),
#             ai_recommendations=json.dumps(analysis_result, ensure_ascii=False)
#         )
        
#         return Response({
#             'resolution_id': conflict_resolution.id,
#             'conflicting_schedules': conflicting_data,
#             'ai_suggestions': suggestions,
#             'optimized_resolution': analysis_result,
#             'message': f'{len(suggestions)}ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ì¶©ëŒ í•´ê²° ë°©ì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
#         }, status=status.HTTP_201_CREATED)
        
#     except Exception as e:
#         return Response({
#             'error': f'ì¶©ëŒ í•´ê²° ë°©ì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
#         }, status=status.HTTP_400_BAD_REQUEST)


# # Alternative Class-Based View for conflict resolution
# class ResolveScheduleConflictView(APIView):
#     """ì¼ì • ì¶©ëŒ í•´ê²° ë°©ì•ˆ ì œê³µ - ë‹¤ì¤‘ AI ë¶„ì„"""
#     permission_classes = [IsAuthenticated]
    
#     def post(self, request):
#         conflicting_schedule_ids = request.data.get('conflicting_schedule_ids', [])
#         new_request = request.data.get('new_request', '')
        
#         if not conflicting_schedule_ids or not new_request:
#             return Response({
#                 'error': 'ì¶©ëŒ ì¼ì • IDì™€ ìƒˆë¡œìš´ ìš”ì²­ì´ í•„ìš”í•©ë‹ˆë‹¤.'
#             }, status=status.HTTP_400_BAD_REQUEST)
        
#         try:
#             # ì‚¬ìš©ì ì²˜ë¦¬
#             if request.user.is_authenticated:
#                 user = request.user
#             else:
#                 from django.contrib.auth.models import User
#                 user, created = User.objects.get_or_create(
#                     username='dummy_user',
#                     defaults={'email': 'dummy@example.com'}
#                 )
            
#             # ì¶©ëŒ ì¼ì •ë“¤ ì¡°íšŒ
#             conflicting_schedules = Schedule.objects.filter(
#                 id__in=conflicting_schedule_ids,
#                 user=user
#             )
            
#             conflicting_data = [ScheduleSerializer(schedule).data for schedule in conflicting_schedules]
            
#             # ë‹¤ì¤‘ AI ëª¨ë¸ë“¤ë¡œë¶€í„° í•´ê²° ë°©ì•ˆ ë°›ê¸°
#             optimizer = ScheduleOptimizerBot()
#             prompt = optimizer.create_conflict_resolution_prompt(conflicting_data, new_request)
#             suggestions = optimizer.get_ai_suggestions(prompt, "conflict_resolution")
            
#             # AI ë¶„ì„ì„ í†µí•œ ìµœì  í•´ê²°ë°©ì•ˆ ë„ì¶œ
#             analysis_result = optimizer.analyze_and_optimize_suggestions(
#                 suggestions,
#                 f"ì¶©ëŒ í•´ê²°: {new_request}"
#             )
            
#             # í•´ê²° ë°©ì•ˆ ì €ì¥
#             conflict_resolution = ConflictResolution.objects.create(
#                 user=user,
#                 conflicting_schedules=json.dumps(conflicting_data, ensure_ascii=False),
#                 resolution_options=json.dumps(suggestions, ensure_ascii=False),
#                 ai_recommendations=json.dumps(analysis_result, ensure_ascii=False)
#             )
            
#             return Response({
#                 'resolution_id': conflict_resolution.id,
#                 'conflicting_schedules': conflicting_data,
#                 'ai_suggestions': suggestions,
#                 'optimized_resolution': analysis_result,
#                 'message': f'{len(suggestions)}ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ì¶©ëŒ í•´ê²° ë°©ì•ˆì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.'
#             }, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#             return Response({
#                 'error': f'ì¶©ëŒ í•´ê²° ë°©ì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
#             }, status=status.HTTP_400_BAD_REQUEST)

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes, authentication_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.authentication import TokenAuthentication, SessionAuthentication
from django.shortcuts import get_object_or_404
from datetime import datetime, timedelta
import json
import re
from .models import Schedule, ScheduleRequest, ConflictResolution
from .serializers import (
    ScheduleSerializer, ScheduleRequestSerializer, 
    ConflictResolutionSerializer, ScheduleRequestInputSerializer
)
import logging
from pytz import timezone
KST = timezone('Asia/Seoul')
target_datetime = datetime.now(KST)
logger = logging.getLogger(__name__)

# ê¸°ì¡´ ChatBot í´ë˜ìŠ¤ì™€ API í‚¤ë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€...
OPENAI_API_KEY = "***REMOVED***"
ANTHROPIC_API_KEY = "***REMOVED***"
GROQ_API_KEY = "***REMOVED***"


# ğŸ”§ í† í° ë””ë²„ê¹…ì„ ìœ„í•œ ì»¤ìŠ¤í…€ ì¸ì¦ í´ë˜ìŠ¤
class DebugTokenAuthentication(TokenAuthentication):
    """ë””ë²„ê¹…ì´ í¬í•¨ëœ í† í° ì¸ì¦ í´ë˜ìŠ¤"""
    
    def authenticate(self, request):
        logger.info("=== ê°œì„ ëœ í† í° ì¸ì¦ ë””ë²„ê¹… ì‹œì‘ ===")
        
        # Authorization í—¤ë” í™•ì¸
        auth_header = request.META.get('HTTP_AUTHORIZATION', '')
        logger.info(f"Authorization í—¤ë”: '{auth_header}'")
        
        if not auth_header:
            logger.warning("âŒ Authorization í—¤ë”ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
            
        if not auth_header.startswith('Bearer '):
            logger.warning(f"âŒ Bearer í† í° í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {auth_header}")
            return None
            
        token = auth_header.split(' ')[1]
        logger.info(f"ğŸ“± ì¶”ì¶œëœ í† í°: {token[:10]}...{token[-10:]}")
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í† í° í™•ì¸
        try:
            token_obj = Token.objects.select_related('user').get(key=token)
            logger.info(f"âœ… DBì—ì„œ í† í° ë°œê²¬: {token_obj.key[:10]}...{token_obj.key[-10:]}")
            logger.info(f"ğŸ‘¤ í† í° ì†Œìœ ì: {token_obj.user.username} (ID: {token_obj.user.id})")
            logger.info(f"ğŸ”„ ì‚¬ìš©ì í™œì„± ìƒíƒœ: {token_obj.user.is_active}")
            
            if not token_obj.user.is_active:
                logger.warning(f"âŒ ì‚¬ìš©ìê°€ ë¹„í™œì„±í™”ë¨: {token_obj.user.username}")
                raise exceptions.AuthenticationFailed('User inactive or deleted.')
            
            logger.info("âœ… í† í° ì¸ì¦ ì„±ê³µ!")
            logger.info("=== ê°œì„ ëœ í† í° ì¸ì¦ ë””ë²„ê¹… ì¢…ë£Œ ===")
            return (token_obj.user, token_obj)
            
        except Token.DoesNotExist:
            logger.error(f"âŒ DBì— í•´ë‹¹ í† í°ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {token[:10]}...{token[-10:]}")
            
            # ëª¨ë“  í† í° ëª©ë¡ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            all_tokens = Token.objects.all()[:5]  # ì²˜ìŒ 5ê°œë§Œ
            logger.info(f"ğŸ—ƒï¸ DBì˜ ê¸°ì¡´ í† í°ë“¤:")
            for i, t in enumerate(all_tokens):
                logger.info(f"  {i+1}. {t.key[:10]}...{t.key[-10:]} (ì‚¬ìš©ì: {t.user.username})")
            
            logger.info("=== ê°œì„ ëœ í† í° ì¸ì¦ ë””ë²„ê¹… ì¢…ë£Œ ===")
            raise exceptions.AuthenticationFailed('Invalid token.')
        
        except Exception as e:
            logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            logger.info("=== ê°œì„ ëœ í† í° ì¸ì¦ ë””ë²„ê¹… ì¢…ë£Œ ===")
            raise exceptions.AuthenticationFailed('Authentication error.')


# ğŸ”§ ì¼ì • ê´€ë¦¬ ë·° - ì¸ì¦ ë¬¸ì œ í•´ê²°
class ScheduleManagementView(APIView):
    """ì¼ì • ê´€ë¦¬ ë©”ì¸ ë·° - í† í° ì¸ì¦ ì ìš©"""
    authentication_classes = [DebugTokenAuthentication, SessionAuthentication]
    permission_classes = [IsAuthenticated]
    
    def __init__(self):
        super().__init__()
        # ScheduleOptimizerBot ì´ˆê¸°í™”ëŠ” ë©”ì„œë“œ ë‚´ì—ì„œ ìˆ˜í–‰
    
    def get_optimizer(self):
        """í•„ìš”í•  ë•Œë§Œ optimizer ì¸ìŠ¤í„´ìŠ¤ ìƒì„±"""
        if not hasattr(self, '_optimizer'):
            self._optimizer = ScheduleOptimizerBot()
        return self._optimizer
    
    def get(self, request):
        """ì‚¬ìš©ìì˜ ì¼ì • ëª©ë¡ ì¡°íšŒ"""
        logger.info(f"ì¼ì • ì¡°íšŒ ìš”ì²­ - ì‚¬ìš©ì: {request.user.username if request.user.is_authenticated else 'Anonymous'}")
        
        try:
            schedules = Schedule.objects.filter(user=request.user).order_by('start_time')
            
            # ë‚ ì§œ í•„í„°ë§
            start_date = request.query_params.get('start_date')
            end_date = request.query_params.get('end_date')
            
            if start_date:
                schedules = schedules.filter(start_time__date__gte=start_date)
            if end_date:
                schedules = schedules.filter(end_time__date__lte=end_date)
            
            serializer = ScheduleSerializer(schedules, many=True)
            logger.info(f"ì¼ì • ì¡°íšŒ ì„±ê³µ: {len(serializer.data)}ê°œ ì¼ì • ë°˜í™˜")
            return Response(serializer.data)
            
        except Exception as e:
            logger.error(f"ì¼ì • ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return Response(
                {'error': f'ì¼ì • ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}, 
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    def _get_ai_generated_title(self, prompt):
        """AIë¥¼ í†µí•´ ì¼ì • ì œëª© ìƒì„±"""
        try:
            optimizer = self.get_optimizer()
            suggestions = optimizer.get_ai_suggestions(prompt, "title")
            
            # ì²« ë²ˆì§¸ ì‘ë‹µì—ì„œ ì œëª© ì¶”ì¶œ
            for key, response in suggestions.items():
                if response and len(response.strip()) > 0:
                    # ê°„ë‹¨í•œ ì œëª©ë§Œ ì¶”ì¶œ (ì²« ì¤„ë§Œ)
                    title = response.strip().split('\n')[0]
                    # ë”°ì˜´í‘œ ì œê±°
                    title = title.strip('"\'')
                    if len(title) > 0 and len(title) < 50:  # ì ì ˆí•œ ê¸¸ì´ í™•ì¸
                        return title
            
            return None
        except Exception as e:
            logger.warning(f"AI ì œëª© ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return None
    
    def post(self, request):
        """ìƒˆë¡œìš´ ì¼ì • ìƒì„± ìš”ì²­"""
        logger.info(f"ì¼ì • ìƒì„± ìš”ì²­ - ì‚¬ìš©ì: {request.user.username}")
        
        try:
            request_text = request.data.get('request_text', '')
            existing_schedules = request.data.get('existing_schedules', [])
            
            if not request_text:
                return Response({'error': 'ìš”ì²­ í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}, 
                            status=status.HTTP_400_BAD_REQUEST)
            
            user = request.user
            
            # ì—¬ëŸ¬ ì¼ì • ìš”ì²­ì¸ì§€ í™•ì¸
            schedule_requests = parse_multiple_schedules_backend(request_text)
            target_date = parse_date_from_request(request_text)
            
            logger.info(f"íŒŒì‹±ëœ ì¼ì • ìš”ì²­: {len(schedule_requests)}ê°œ")
            logger.info(f"ğŸ“Œ KST ê¸°ì¤€ ëª©í‘œ ë‚ ì§œ: {target_date} (ìš”ì²­ í…ìŠ¤íŠ¸: '{request_text}')")

            
            if len(schedule_requests) > 1:
                # ì—¬ëŸ¬ ì¼ì • ì²˜ë¦¬
                multiple_schedules = []
                all_individual_suggestions = []
                
                def extract_time_info(text):
                    import re
                    start_hour = None
                    duration_hours = 1

                    is_pm = 'ì˜¤í›„' in text
                    is_am = 'ì˜¤ì „' in text

                    # ğŸ” "ì˜¤í›„ 3-5ì‹œ"ì™€ ê°™ì€ ê²½ìš° ì²˜ë¦¬
                    time_range = re.search(r'(\d{1,2})\s*[-~]\s*(\d{1,2})\s*ì‹œ', text)
                    if time_range:
                        start = int(time_range.group(1))
                        end = int(time_range.group(2))

                        if is_pm:
                            if start < 12:
                                start += 12
                            if end < 12:
                                end += 12
                        elif is_am:
                            if start == 12:
                                start = 0
                            if end == 12:
                                end = 0

                        start_hour = start
                        duration_hours = end - start
                        return start_hour, duration_hours

                    # ğŸ” "2ì‹œê°„"ë§Œ ìˆëŠ” ê²½ìš°
                    dur_match = re.search(r'(\d{1,2})\s*ì‹œê°„', text)
                    if dur_match:
                        duration_hours = int(dur_match.group(1))

                    # ğŸ” ë‹¨ì¼ ì‹œê°: "ì˜¤í›„ 3ì‹œ"
                    single_time_match = re.search(r'(ì˜¤ì „|ì˜¤í›„)?\s*(\d{1,2})\s*ì‹œ', text)
                    if single_time_match:
                        hour = int(single_time_match.group(2))
                        if single_time_match.group(1) == 'ì˜¤í›„' and hour < 12:
                            hour += 12
                        elif single_time_match.group(1) == 'ì˜¤ì „' and hour == 12:
                            hour = 0
                        start_hour = hour

                    return start_hour, duration_hours

                def find_non_conflicting_time(existing_schedules, start_hour, duration_hours, date):
                    """
                    ê¸°ì¡´ ì¼ì •ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” ì‹œê°„ëŒ€ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
                    """
                    from datetime import datetime, timedelta, time

                    def is_conflicting(new_start, new_end, schedules):
                        for s in schedules:
                            s_start = datetime.strptime(s['start_time'], '%Y-%m-%dT%H:%M:%S')
                            s_end = datetime.strptime(s['end_time'], '%Y-%m-%dT%H:%M:%S')
                            if not (new_end <= s_start or new_start >= s_end):
                                return True
                        return False

                    attempt = 0
                    max_attempts = 10
                    while attempt < max_attempts:
                        candidate_start = datetime.combine(date, time(start_hour))
                        candidate_end = candidate_start + timedelta(hours=duration_hours)
                        if not is_conflicting(candidate_start, candidate_end, existing_schedules):
                            return candidate_start, candidate_end
                        start_hour += 1
                        attempt += 1

                    # fallback
                    return datetime.combine(date, time(start_hour)), datetime.combine(date, time(start_hour + duration_hours))



                # ì¼ì • ë£¨í”„ ìˆ˜ì •
                for i, single_request in enumerate(schedule_requests):
                    title_prompt = f"""ë‹¤ìŒ ì¼ì • ìš”ì²­ì—ì„œ ì ì ˆí•œ ì¼ì • ì œëª©ì„ í•œ ì¤„ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”: {single_request}
                    ë¶„ì„ ë°©ë²•:
                    1. ê¸°ì¡´ ì¼ì •ë“¤ì˜ ì‹œê°„ëŒ€ë¥¼ í™•ì¸í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì‹œê°„ì— ì¼ì •ì´ ì—†ë‹¤ë©´, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¼ì •ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.
                    2. ìš”ì²­ëœ ì¼ì •ì˜ ì„±ê²©ì— ë§ëŠ” ìµœì ì˜ ì‹œê°„ëŒ€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”
                    3. ì¼ì • ê°„ ì—¬ìœ  ì‹œê°„ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”
                    4. ë˜ë„ë¡ì´ë©´ ìƒˆë²½ì‹œê°„ì€ í”¼í•´ì£¼ì„¸ìš”.
                    5. ì‚¬ìš©ìê°€ ì§€ì •í•œ ì‹œê°„ì´ ìˆë‹¤ë©´, ê·¸ ì‹œê°„ìœ¼ë¡œ ë°°ì •í•´ì£¼ì„¸ìš”. ë‹¨, ê·¸ ì‹œê°„ì— ì´ë¯¸ ì¼ì •ì´ ìˆë‹¤ë©´ ë‹¤ë¥¸ ì‹œê°„ì„ ë°°ì •í•˜ê³  ì¼ì •ì´ ìˆìŒì„ ì•Œë ¤ì£¼ì„¸ìš”
                    """
                    ai_title = self._get_ai_generated_title(title_prompt) or "ìƒˆ ì¼ì •"

                    # ì‹œê°„ ì •ë³´ ì¶”ì¶œ
                    parsed_start, parsed_duration = extract_time_info(single_request)

                    if parsed_start is not None:
                        start_hour = parsed_start
                    else:
                        start_hour = 9 + i * 2  # ê¸°ë³¸ê°’ fallback

                    duration_hours = parsed_duration or 1

                    existing = request.data.get("existing_schedules", [])
                    schedule_start_dt, schedule_end_dt = find_non_conflicting_time(existing, start_hour, duration_hours, target_date)

                    optimized_schedule = {
                        "title": ai_title,
                        "description": f"AIê°€ ë¶„ì„í•œ {self._extract_schedule_title(single_request)} ì¼ì •ì…ë‹ˆë‹¤.",
                        "suggested_date": target_datetime.strftime('%Y-%m-%d'),
                        "suggested_start_time": schedule_start_dt.strftime('%H:%M'),
                        "suggested_end_time": schedule_end_dt.strftime('%H:%M'),
                        "location": self._extract_schedule_location(single_request),
                        "priority": "HIGH",
                        "attendees": [],
                        "reasoning": f"{i + 1}ë²ˆì§¸ ì¼ì •: {single_request}. ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ì‹œê°„ìœ¼ë¡œ ë°°ì •í–ˆìŠµë‹ˆë‹¤."
                    }

                
                # for i, single_request in enumerate(schedule_requests):
                #     # ê° ì¼ì •ì˜ ì‹œì‘ ì‹œê°„ì„ ë‹¤ë¥´ê²Œ ì„¤ì •
                #     base_hour = 9 + (i * 2)

                #     title_prompt = f"ë‹¤ìŒ ì¼ì • ìš”ì²­ì—ì„œ ì ì ˆí•œ ì¼ì • ì œëª©ì„ í•œ ì¤„ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”: {single_request}"
                #     ai_title = self._get_ai_generated_title(title_prompt) or "ìƒˆ ì¼ì •"
                    
                #     optimized_schedule = {
                #         "title": ai_title,  # âœ… AIê°€ ìƒì„±í•œ ì œëª© ì‚¬ìš©
                #         "description": f"AIê°€ ë¶„ì„í•œ {self._extract_schedule_title(single_request)} ì¼ì •ì…ë‹ˆë‹¤.",
                #         "suggested_date": target_date.strftime('%Y-%m-%d'),
                #         "suggested_start_time": f"{base_hour:02d}:00",
                #         "suggested_end_time": f"{base_hour + 2:02d}:00",
                #         "location": self._extract_schedule_location(single_request),
                #         "priority": "HIGH",
                #         "attendees": [],
                #         "reasoning": f"{i + 1}ë²ˆì§¸ ì¼ì •: {single_request}. ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ì‹œê°„ìœ¼ë¡œ ë°°ì •í–ˆìŠµë‹ˆë‹¤."
                #     }
                    multiple_schedules.append(optimized_schedule)
                    existing_schedules.append({
    'start_time': schedule_start_dt.isoformat(),
    'end_time': schedule_end_dt.isoformat()
})
                    
                    # ê° AIë³„ ê°œë³„ ì œì•ˆ ìƒì„±
                    for ai_type in ['gpt', 'claude', 'mixtral']:
                        individual_suggestion = optimized_schedule.copy()
                        individual_suggestion['source'] = ai_type
                        individual_suggestion['reasoning'] = f"{ai_type.upper()}ê°€ ë¶„ì„í•œ {self._extract_schedule_title(single_request)} ìµœì  ì‹œê°„ì…ë‹ˆë‹¤."
                        all_individual_suggestions.append(individual_suggestion)
                
                response_data = {
                    'request_id': int(datetime.now().timestamp()),
                    'multiple_schedules': multiple_schedules,
                    'optimized_suggestion': multiple_schedules[0],
                    'confidence_score': 0.92,
                    'individual_suggestions': all_individual_suggestions,
                    'ai_analysis': {
                        'analysis_summary': f"ì´ {len(schedule_requests)}ê°œì˜ ì¼ì •ì„ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì‹œê°„ëŒ€ë¡œ ë°°ì •í–ˆìŠµë‹ˆë‹¤.",
                        'reasoning': f"ì—¬ëŸ¬ ì¼ì •ì„ {target_date.strftime('%Yë…„ %mì›” %dì¼')}ì— ì‹œê°„ ìˆœì„œëŒ€ë¡œ ë°°ì¹˜í•˜ì—¬ ì¶©ëŒì„ ë°©ì§€í–ˆìŠµë‹ˆë‹¤.",
                        'models_used': ["gpt", "claude", "mixtral"]
                    },
                    'has_conflicts': False,
                    'conflicts': [],
                    'analysis_summary': f"{len(schedule_requests)}ê°œ ì¼ì •ì— ëŒ€í•´ 3ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
                    'is_multiple_schedule': True
                }
                
            else:
                # ë‹¨ì¼ ì¼ì • ì²˜ë¦¬
                optimizer = self.get_optimizer()
                user_context = self._get_user_context(user)
                
                enhanced_prompt = f"""
                ì‚¬ìš©ìì˜ ì¼ì • ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê¸°ì¡´ ì¼ì •ê³¼ ì¶©ëŒí•˜ì§€ ì•ŠëŠ” ìµœì ì˜ ë¹ˆ ì‹œê°„ì„ ì°¾ì•„ ì œì•ˆí•´ì£¼ì„¸ìš”.
                ë§Œì•½ ì‚¬ìš©ìê°€ ì§€ì •í•œ ì‹œê°„ì´ ìˆë‹¤ë©´, ê·¸ ì‹œê°„ì— ì¼ì •ì„ ë„£ì–´ì£¼ì„¸ìš”.
                
                ìš”ì²­ ë‚´ìš©: {request_text}
                ëª©í‘œ ë‚ ì§œ: {target_date.strftime('%Yë…„ %mì›” %dì¼')} ({self._get_weekday_korean(target_date)})
                ê¸°ì¡´ ì¼ì •ë“¤: {existing_schedules or []}
                ë¶„ì„ ë°©ë²•:
                1. ê¸°ì¡´ ì¼ì •ë“¤ì˜ ì‹œê°„ëŒ€ë¥¼ í™•ì¸í•˜ì—¬ ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì‹œê°„ì— ì¼ì •ì´ ì—†ë‹¤ë©´, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¼ì •ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.
                2. ìš”ì²­ëœ ì¼ì •ì˜ ì„±ê²©ì— ë§ëŠ” ìµœì ì˜ ì‹œê°„ëŒ€ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”
                3. ì¼ì • ê°„ ì—¬ìœ  ì‹œê°„ë„ ê³ ë ¤í•´ì£¼ì„¸ìš”
                4. ìƒˆë²½ì‹œê°„ì€ í”¼í•´ì£¼ì„¸ìš”.
                5. ì‚¬ìš©ìê°€ ì§€ì •í•œ ì‹œê°„ì´ ìˆë‹¤ë©´, ê·¸ ì‹œê°„ìœ¼ë¡œ ë°°ì •í•´ì£¼ì„¸ìš”. ë‹¨, ê·¸ ì‹œê°„ì— ì´ë¯¸ ì¼ì •ì´ ìˆë‹¤ë©´ ë‹¤ë¥¸ ì‹œê°„ì„ ë°°ì •í•˜ê³  ì¼ì •ì´ ìˆìŒì„ ì•Œë ¤ì£¼ì„¸ìš”


                
                ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
                {{
                    "title": "ìš”ì²­ ë‚´ìš©ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ì˜ë¯¸ìˆëŠ” ì¼ì • ì œëª©ì„ ì‘ì„±í•˜ì„¸ìš”", 
                    "description": "ìƒì„¸ ì„¤ëª…",
                    "suggested_date": "%Y-%m-%d",
                    "suggested_start_time": "HH:MM",
                    "suggested_end_time": "HH:MM",
                    "location": "ì¥ì†Œ",
                    "priority": "HIGH/MEDIUM/LOW/URGENT",
                    "attendees": [],
                    "reasoning": "ì´ ì‹œê°„ì„ ì œì•ˆí•˜ëŠ” ì´ìœ "
                }}
                """
                
                suggestions = optimizer.get_ai_suggestions(enhanced_prompt)
                optimized_result = optimizer.analyze_and_optimize_suggestions(
                    suggestions, f"ì¼ì • ìš”ì²­: {request_text}"
                )
                
                response_data = {
                    'request_id': int(datetime.now().timestamp()),
                    'optimized_suggestion': optimized_result.get('optimized_suggestion', {}),
                    'confidence_score': optimized_result.get('confidence_score', 0.0),
                    'ai_analysis': optimized_result.get('ai_analysis', {}),
                    'individual_suggestions': optimized_result.get('individual_suggestions', []),
                    'has_conflicts': False,
                    'conflicts': [],
                    'analysis_summary': "3ê°œ AI ëª¨ë¸ì´ ë¶„ì„í•œ ê²°ê³¼ì…ë‹ˆë‹¤.",
                    'is_multiple_schedule': False
                }
            
            logger.info("ì¼ì • ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì™„ë£Œ")
            return Response(response_data, status=status.HTTP_201_CREATED)
            
        except Exception as e:
            logger.error(f"ì¼ì • ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
            return Response({
                'error': f'ì¼ì • ìƒì„± ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_user_context(self, user):
        """ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ìƒì„±"""
        return {
            'username': user.username,
            'timezone': 'Asia/Seoul',  # ê¸°ë³¸ íƒ€ì„ì¡´
            'preferences': {}
        }
    
    def _extract_schedule_title(self, request):
        """ìš”ì²­ì—ì„œ ì¼ì • ì œëª© ì¶”ì¶œ"""
        if 'ìš´ë™' in request:
            return 'ìš´ë™'
        elif 'ë¯¸íŒ…' in request or 'íšŒì˜' in request:
            return 'íŒ€ ë¯¸íŒ…'
        elif 'ê³µë¶€' in request or 'í•™ìŠµ' in request:
            return 'í•™ìŠµ ì‹œê°„'
        elif 'ì‘ì—…' in request or 'ì—…ë¬´' in request:
            return 'ì§‘ì¤‘ ì‘ì—…'
        elif 'ì•½ì†' in request:
            return 'ì•½ì†'
        else:
            return 'ìƒˆ ì¼ì •'

    def _extract_schedule_location(self, request):
        """ìš”ì²­ì—ì„œ ì¥ì†Œ ì¶”ì¶œ"""
        if 'ìš´ë™' in request:
            return 'í—¬ìŠ¤ì¥'
        elif 'ë¯¸íŒ…' in request or 'íšŒì˜' in request:
            return 'íšŒì˜ì‹¤'
        elif 'ê³µë¶€' in request or 'í•™ìŠµ' in request:
            return 'ë„ì„œê´€'
        elif 'ì»¤í”¼' in request:
            return 'ì¹´í˜'
        else:
            return 'ì‚¬ë¬´ì‹¤'

    def _get_weekday_korean(self, date):
        """ìš”ì¼ì„ í•œêµ­ì–´ë¡œ ë°˜í™˜"""
        weekdays = ['ì›”ìš”ì¼', 'í™”ìš”ì¼', 'ìˆ˜ìš”ì¼', 'ëª©ìš”ì¼', 'ê¸ˆìš”ì¼', 'í† ìš”ì¼', 'ì¼ìš”ì¼']
        return weekdays[date.weekday()]

@api_view(['POST'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def confirm_schedule(request, request_id):
    """AI ì œì•ˆëœ ì¼ì •ì„ í™•ì •í•˜ì—¬ ì‹¤ì œ ì¼ì •ìœ¼ë¡œ ìƒì„±"""
    logger.info(f"ì¼ì • í™•ì • ìš”ì²­ - ì‚¬ìš©ì: {request.user.username}, request_id: {request_id}")
    
    try:
        user = request.user
        
        # âœ… í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ì†¡ëœ ì‹¤ì œ AI ì œì•ˆ ë°ì´í„° ì‚¬ìš©
        ai_suggestion_data = request.data.get('ai_suggestion')
        if not ai_suggestion_data:
            return Response({
                'error': 'AI ì œì•ˆ ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # ì—¬ëŸ¬ ì¼ì •ì¸ì§€ ë‹¨ì¼ ì¼ì •ì¸ì§€ í™•ì¸
        is_multiple = ai_suggestion_data.get('is_multiple_schedule', False)
        
        if is_multiple and ai_suggestion_data.get('multiple_schedules'):
            # ì—¬ëŸ¬ ì¼ì • ì²˜ë¦¬
            created_schedules = []
            
            for schedule_data in ai_suggestion_data['multiple_schedules']:
                try:
                    # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
                    suggested_date = schedule_data.get('suggested_date')
                    suggested_start_time = schedule_data.get('suggested_start_time', '09:00')
                    suggested_end_time = schedule_data.get('suggested_end_time', '10:00')
                    
                    start_datetime = datetime.strptime(
                        f"{suggested_date} {suggested_start_time}",
                        '%Y-%m-%d %H:%M'
                    )
                    end_datetime = datetime.strptime(
                        f"{suggested_date} {suggested_end_time}",
                        '%Y-%m-%d %H:%M'
                    )
                    
                    # Schedule ê°ì²´ ìƒì„±
                    schedule = Schedule.objects.create(
                        user=user,
                        title=schedule_data.get('title', 'ìƒˆ ì¼ì •'),
                        description=schedule_data.get('description', 'AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤.'),
                        start_time=start_datetime,
                        end_time=end_datetime,
                        location=schedule_data.get('location', ''),
                        priority=schedule_data.get('priority', 'MEDIUM'),
                        attendees=json.dumps(schedule_data.get('attendees', []), ensure_ascii=False)
                    )
                    
                    created_schedules.append(schedule)
                    logger.info(f"ë‹¤ì¤‘ ì¼ì • ìƒì„± ì„±ê³µ: {schedule.id} - {schedule.title}")
                    
                except Exception as e:
                    logger.error(f"ê°œë³„ ì¼ì • ìƒì„± ì‹¤íŒ¨: {str(e)}")
                    continue
            
            if created_schedules:
                serializer = ScheduleSerializer(created_schedules, many=True)
                return Response({
                    'message': f'{len(created_schedules)}ê°œì˜ ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
                    'schedules': serializer.data
                }, status=status.HTTP_201_CREATED)
            else:
                return Response({
                    'error': 'ì¼ì • ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
        
        else:
            # ë‹¨ì¼ ì¼ì • ì²˜ë¦¬
            optimized_suggestion = ai_suggestion_data.get('optimized_suggestion')
            if not optimized_suggestion:
                return Response({
                    'error': 'ìµœì í™”ëœ ì œì•ˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ë‚ ì§œ/ì‹œê°„ íŒŒì‹±
            try:
                suggested_date = optimized_suggestion.get('suggested_date')
                suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
                suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
                
                if 'T' in suggested_date:
                    suggested_date = suggested_date.split('T')[0]
                
                start_datetime = datetime.strptime(
                    f"{suggested_date} {suggested_start_time}",
                    '%Y-%m-%d %H:%M'
                )
                end_datetime = datetime.strptime(
                    f"{suggested_date} {suggested_end_time}",
                    '%Y-%m-%d %H:%M'
                )
                
            except (ValueError, TypeError) as e:
                logger.error(f"DateTime parsing error: {e}")
                now = datetime.now()
                start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
                end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
            
            # Schedule ê°ì²´ ìƒì„±
            schedule = Schedule.objects.create(
                user=user,
                title=optimized_suggestion.get('title', 'ìƒˆ ì¼ì •'),
                description=optimized_suggestion.get('description', 'AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤.'),
                start_time=start_datetime,
                end_time=end_datetime,
                location=optimized_suggestion.get('location', ''),
                priority=optimized_suggestion.get('priority', 'MEDIUM'),
                attendees=json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
            )
            
            serializer = ScheduleSerializer(schedule)
            logger.info(f"ë‹¨ì¼ ì¼ì • ìƒì„± ì„±ê³µ: {schedule.id} - {schedule.title}")
            
            return Response({
                'message': 'AIì˜ ë¶„ì„ì„ í†µí•´ ìµœì í™”ëœ ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.',
                'schedule': serializer.data
            }, status=status.HTTP_201_CREATED)
            
    except Exception as e:
        logger.error(f"ì¼ì • í™•ì • ì‹¤íŒ¨: {str(e)}")
        return Response({
            'error': f'ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }, status=status.HTTP_400_BAD_REQUEST)
# ğŸ”§ ìˆ˜ë™ ì¼ì • ìƒì„± ë·°
@api_view(['POST'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def create_manual_schedule(request):
    """ìˆ˜ë™ìœ¼ë¡œ ì¼ì • ìƒì„±"""
    logger.info(f"ìˆ˜ë™ ì¼ì • ìƒì„± ìš”ì²­ - ì‚¬ìš©ì: {request.user.username}")
    
    try:
        data = request.data.copy()
        data['user'] = request.user.id
        
        serializer = ScheduleSerializer(data=data)
        if serializer.is_valid():
            schedule = serializer.save(user=request.user)
            logger.info(f"ìˆ˜ë™ ì¼ì • ìƒì„± ì„±ê³µ: {schedule.id}")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            logger.warning(f"ìˆ˜ë™ ì¼ì • ìƒì„± ì‹¤íŒ¨ - ìœ íš¨ì„± ê²€ì¦ ì˜¤ë¥˜: {serializer.errors}")
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
            
    except Exception as e:
        logger.error(f"ìˆ˜ë™ ì¼ì • ìƒì„± ì‹¤íŒ¨: {str(e)}")
        return Response({
            'error': f'ì¼ì • ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# ğŸ”§ ì¼ì • ìˆ˜ì •/ì‚­ì œ ë·°
@api_view(['PUT', 'DELETE'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def manage_schedule(request, schedule_id):
    """ì¼ì • ìˆ˜ì • ë˜ëŠ” ì‚­ì œ"""
    try:
        schedule = get_object_or_404(Schedule, id=schedule_id, user=request.user)
        
        if request.method == 'PUT':
            # ì¼ì • ìˆ˜ì •
            serializer = ScheduleSerializer(schedule, data=request.data, partial=True)
            if serializer.is_valid():
                serializer.save()
                logger.info(f"ì¼ì • ìˆ˜ì • ì„±ê³µ: {schedule_id}")
                return Response(serializer.data)
            else:
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        elif request.method == 'DELETE':
            # ì¼ì • ì‚­ì œ
            schedule.delete()
            logger.info(f"ì¼ì • ì‚­ì œ ì„±ê³µ: {schedule_id}")
            return Response({'message': 'ì¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'}, 
                          status=status.HTTP_204_NO_CONTENT)
            
    except Exception as e:
        logger.error(f"ì¼ì • ê´€ë¦¬ ì‹¤íŒ¨: {str(e)}")
        return Response({
            'error': f'ì¼ì • ê´€ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

from pytz import timezone

def parse_date_from_request(request_text):
    korea_now = datetime.now(timezone('Asia/Seoul')).date()

    if 'ì˜¤ëŠ˜' in request_text:
        return korea_now
    elif 'ë‚´ì¼' in request_text:
        return korea_now + timedelta(days=1)
    elif 'ëª¨ë ˆ' in request_text or 'ëª¨ë˜' in request_text:
        return korea_now + timedelta(days=2)
    elif 'ì´ë²ˆ ì£¼' in request_text:
        days_until_friday = (4 - korea_now.weekday()) % 7
        days_until_friday = 7 if days_until_friday == 0 else days_until_friday
        return korea_now + timedelta(days=days_until_friday)
    elif 'ë‹¤ìŒ ì£¼' in request_text:
        return korea_now + timedelta(days=7)
    else:
        return korea_now + timedelta(days=1)

def parse_multiple_schedules_backend(request_text):
    """ë°±ì—”ë“œì—ì„œ ì—¬ëŸ¬ ì¼ì • íŒŒì‹±"""
    separators = [',', 'ï¼Œ', 'ê·¸ë¦¬ê³ ', 'ë°', 'ì™€', 'ê³¼']
    
    parts = [request_text]
    for sep in separators:
        new_parts = []
        for part in parts:
            new_parts.extend(part.split(sep))
        parts = new_parts
    
    cleaned_requests = []
    for part in parts:
        cleaned = part.strip()
        if cleaned and len(cleaned) > 2:
            cleaned_requests.append(cleaned)
    
    return cleaned_requests if len(cleaned_requests) > 1 else [request_text]

# ğŸ”§ ScheduleOptimizerBot í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼í•˜ì§€ë§Œ import ì˜¤ë¥˜ ìˆ˜ì •)
class ScheduleOptimizerBot:
    """ì¼ì • ìµœì í™”ë¥¼ ìœ„í•œ AI ë´‡ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ChatBot í´ë˜ìŠ¤ê°€ ì •ì˜ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        try:
            self.chatbots = {
                'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
                'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
                'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
            }
        except NameError:
            # ChatBot í´ë˜ìŠ¤ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©
            logger.warning("ChatBot í´ë˜ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë”ë¯¸ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.chatbots = {
                'gpt': DummyChatBot(),
                'claude': DummyChatBot(),
                'mixtral': DummyChatBot(),
            }
    
    def get_ai_suggestions(self, prompt, suggestion_type="schedule"):
        """ì—¬ëŸ¬ AI ëª¨ë¸ë¡œë¶€í„° ì œì•ˆë°›ê¸°"""
        suggestions = {}
        
        for model_name, chatbot in self.chatbots.items():
            try:
                if hasattr(chatbot, 'chat'):
                    response = chatbot.chat(prompt)
                else:
                    response = f"ë”ë¯¸ ì‘ë‹µ: {model_name}ì—ì„œ {suggestion_type} ë¶„ì„ ì™„ë£Œ"
                suggestions[f"{model_name}_suggestion"] = response
            except Exception as e:
                suggestions[f"{model_name}_suggestion"] = f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        
        return suggestions
    
    def analyze_and_optimize_suggestions(self, suggestions, query, selected_models=['GPT', 'Claude', 'Mixtral']):
        """ì—¬ëŸ¬ AI ì œì•ˆì„ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ ê²°ê³¼ ìƒì„±"""
        try:
            # ê¸°ë³¸ ì œì•ˆ ìƒì„±
            optimized = self._extract_first_valid_suggestion(suggestions)
            confidence = 0.85
            
            return {
                "optimized_suggestion": optimized,
                "confidence_score": confidence,
                "ai_analysis": {
                    "analysis_summary": "AI ëª¨ë¸ë“¤ì˜ ì œì•ˆì„ ì¢…í•© ë¶„ì„í–ˆìŠµë‹ˆë‹¤.",
                    "reasoning": "ì—¬ëŸ¬ ëª¨ë¸ì˜ ê³µí†µì ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì í™”í–ˆìŠµë‹ˆë‹¤.",
                    "models_used": selected_models
                },
                "individual_suggestions": self._parse_individual_suggestions(suggestions)
            }
            
        except Exception as e:
            logger.error(f"Analysis error: {str(e)}")
            return {"error": f"ìµœì í™” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    
    def _extract_first_valid_suggestion(self, suggestions):
        """ì²« ë²ˆì§¸ ìœ íš¨í•œ ì œì•ˆ ì¶”ì¶œ"""
        for key, suggestion in suggestions.items():
            try:
                json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except:
                continue
        
        return {
            "title": "ìƒˆ ì¼ì •",
            "description": "AIê°€ ì œì•ˆí•œ ì¼ì •ì…ë‹ˆë‹¤",
            "suggested_date": "{target_datetime.strftime('%Y-%m-%d')}",
            "suggested_start_time": "09:00",
            "suggested_end_time": "10:00",
            "location": "",
            "priority": "MEDIUM",
            "attendees": [],
            "reasoning": "ì—¬ëŸ¬ AI ëª¨ë¸ì˜ ì œì•ˆì„ ì¢…í•©í•œ ê²°ê³¼ì…ë‹ˆë‹¤."
        }
    
    def _parse_individual_suggestions(self, suggestions):
        """ê°œë³„ ì œì•ˆë“¤ì„ íŒŒì‹±"""
        parsed = []
        for key, suggestion in suggestions.items():
            try:
                json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
                if json_match:
                    parsed_suggestion = json.loads(json_match.group())
                    parsed_suggestion['source'] = key.replace('_suggestion', '')
                    parsed.append(parsed_suggestion)
            except:
                continue
        return parsed
