from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
import logging
import json
import openai
import anthropic
from groq import Groq
from django.conf import settings
from bs4 import BeautifulSoup
logger = logging.getLogger(__name__)
import re
import json
import logging

def fetch_and_clean_url(url, timeout=10):
    """
    Ï£ºÏñ¥ÏßÑ URLÏùò HTMLÏùÑ ÏöîÏ≤≠Ìï¥, Ïä§ÌÅ¨Î¶ΩÌä∏¬∑Ïä§ÌÉÄÏùº Ï†úÍ±∞ ÌõÑ ÌÖçÏä§Ìä∏Îßå Î∞òÌôòÌï©ÎãàÎã§.
    """
    resp = requests.get(url, timeout=timeout)
    resp.raise_for_status()

    soup = BeautifulSoup(resp.text, "html.parser")
    # Ïä§ÌÅ¨Î¶ΩÌä∏¬∑Ïä§ÌÉÄÏùº¬∑ÎÑ§ÎπÑÍ≤åÏù¥ÏÖò ÌÉúÍ∑∏ Ï†úÍ±∞
    for tag in soup(["script", "style", "header", "footer", "nav"]):
        tag.decompose()

    text = soup.get_text(separator="\n")
    # Îπà Ï§Ñ Ï†úÍ±∞
    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return "\n".join(lines)

# Add this function to your ChatBot class or as a standalone function
def sanitize_and_parse_json(text, selected_models, responses):
    """
    Sanitize and parse the JSON response from AI models.
    Handles various edge cases and formatting issues.
    """
    import re
    import json
    import logging
    
    logger = logging.getLogger(__name__)
    
    try:
        # Step 1: Basic cleanup
        text = text.strip()
        
        # Step 2: Handle code blocks
        if text.startswith('```json') and '```' in text:
            text = re.sub(r'```json(.*?)```', r'\1', text, flags=re.DOTALL).strip()
        elif text.startswith('```') and text.endswith('```'):
            text = text[3:-3].strip()
            
        # Step 3: Extract JSON object if embedded in other text
        json_pattern = r'({[\s\S]*})'
        json_matches = re.findall(json_pattern, text)
        if json_matches:
            text = json_matches[0]
            
        # Step 4: Handle escaped backslashes in the text
        # First identify all occurrences of escaped backslashes followed by characters like "_"
        text = re.sub(r'\\([_"])', r'\1', text)
        
        # Step 5: Attempt to parse the JSON
        result = json.loads(text)
        
        # Ensure the required fields exist
        required_fields = ["preferredModel", "best_response", "analysis", "reasoning"]
        for field in required_fields:
            if field not in result:
                if field == "best_response" and "bestResponse" in result:
                    result["best_response"] = result["bestResponse"]
                else:
                    result[field] = "" if field != "analysis" else {}
        
        return result
        
    except Exception as e:
        logger.error(f"‚ùå JSON ÌååÏã± Ïã§Ìå®: {str(e)}")
        logger.error(f"ÏõêÎ≥∏ ÌÖçÏä§Ìä∏: {text[:200]}..." if len(text) > 200 else text)
        
        # Advanced recovery attempt for malformed JSON
        try:
            # Remove problematic escaped characters
            fixed_text = text.replace("\\_", "_").replace('\\"', '"')
            
            # Try to fix common issues with JSON (missing quotes, commas, etc.)
            fixed_text = re.sub(r'([{,])\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*:', r'\1"\2":', fixed_text)
            fixed_text = re.sub(r':\s*([a-zA-Z_][a-zA-Z0-9_]*)\s*([,}])', r':"\1"\2', fixed_text)
            
            # Handle unclosed strings
            for match in re.finditer(r':\s*"([^"\\]*(\\.[^"\\]*)*)', fixed_text):
                if not re.search(r':\s*"([^"\\]*(\\.[^"\\]*)*)"', match.group(0)):
                    pos = match.end()
                    fixed_text = fixed_text[:pos] + '"' + fixed_text[pos:]
            
            result = json.loads(fixed_text)
            logger.info("‚úÖ Recovered JSON after fixing format issues")
            return result
        except:
            # Last resort: construct a sensible fallback response
            error_analysis = {}
            for model in selected_models:
                model_lower = model.lower()
                error_analysis[model_lower] = {"Ïû•Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®", "Îã®Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®"}
            
            # Find the largest response to use as best_response
            best_response = ""
            if responses:
                best_response = max(responses.values(), key=len) 
            
            return {
                "preferredModel": "FALLBACK",
                "best_response": best_response,
                "analysis": error_analysis,
                "reasoning": "ÏùëÎãµ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌïòÏó¨ ÏµúÏ†ÅÏùò ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§."
            }

# src/chatbot_backend/chat/bot.py

# import logging
# import openai
# import anthropic
# import base64
# import imghdr
# from groq import Groq
# from io import BytesIO

# logger = logging.getLogger(__name__)

# class ChatBot:
#     def __init__(self, api_key, model, api_type):
#         self.conversation_history = []
#         self.api_type = api_type
#         self.api_key = api_key

#         # Anthropic Î©ÄÌã∞Î™®Îã¨ÏùÄ Opus Î™®Îç∏ Í∂åÏû•
#         if api_type == 'anthropic' and not model.startswith('claude-3-opus-20240229'):
#             logger.info(f"Overriding Anthropic model '{model}' to 'claude-3-opus-20240229' for image support")
#             self.model = 'claude-3-opus-20240229'
#         else:
#             self.model = model

#         if api_type == 'openai':
#             openai.api_key = api_key
#         elif api_type == 'anthropic':
#             # Anthropic Python SDK Ï¥àÍ∏∞Ìôî
#             self.client = anthropic.Client(api_key=api_key)
#         elif api_type == 'groq':
#             self.client = Groq(api_key=api_key)
#         else:
#             raise ValueError(f"Unsupported api_type: {api_type}")

#     def chat(self, prompt=None, user_input=None, image_file=None, analysis_mode=None, user_language=None):
#         """
#         prompt       : ÌÖçÏä§Ìä∏ ÌîÑÎ°¨ÌîÑÌä∏ (ÌÇ§ÏõåÎìú)
#         user_input   : ÌÖçÏä§Ìä∏ ÌîÑÎ°¨ÌîÑÌä∏ (ÏúÑÏπò Ïù∏Ïûê)
#         image_file   : ÌååÏùº Í∞ùÏ≤¥ (BytesIO, InMemoryUploadedFile Îì±)
#         analysis_mode: 'describe'|'ocr'|'objects'
#         user_language: 'ko','en'
#         """
#         text = prompt if prompt is not None else user_input
#         try:
#             logger.info(f"[{self.api_type}] Received input: {text}")

#             # Î™®Îç∏Î≥Ñ Ìò∏Ï∂ú
#             if self.api_type == 'openai':
#                 # GPT-4 Vision ÏßÄÏõê
#                 params = {
#                     'model': self.model,
#                     'messages': self.conversation_history + [{"role": "user", "content": text}],
#                     'temperature': 0.7,
#                     'max_tokens': 1024
#                 }
#                 if image_file:
#                     params['files'] = [("image", image_file)]
#                 resp = openai.ChatCompletion.create(**params)
#                 assistant_response = resp.choices[0].message.content

#             elif self.api_type == 'anthropic':
#                 # Claude 3 Opus: Ïù¥ÎØ∏ÏßÄ+ÌÖçÏä§Ìä∏ ÏßÄÏõê via Messages API
#                 messages = []
#                 # ÌÜ†ÌÅ∞ Ïàò ÏÑ§Ï†ï
#                 max_tokens = 1024 if image_file else 4096
#                 if image_file:
#                     # Ïù¥ÎØ∏ÏßÄ Î∞îÏù¥ÎÑàÎ¶¨ ÏùΩÍ∏∞ Î∞è ÎØ∏ÎîîÏñ¥ ÌÉÄÏûÖ ÏûêÎèô Í∞êÏßÄ
#                     image_file.seek(0)
#                     data_bytes = image_file.read()
#                     ext = imghdr.what(None, h=data_bytes) or 'jpeg'
#                     mime_map = {
#                         'jpeg': 'image/jpeg', 'jpg': 'image/jpeg',
#                         'png': 'image/png', 'gif': 'image/gif',
#                         'bmp': 'image/bmp', 'webp': 'image/webp'
#                     }
#                     media_type = mime_map.get(ext, 'image/jpeg')
#                     b64 = base64.b64encode(data_bytes).decode('utf-8')

#                     # Ïù¥ÎØ∏ÏßÄ Î∏îÎ°ùÍ≥º ÌÖçÏä§Ìä∏ Î∏îÎ°ùÏùÑ Î¶¨Ïä§Ìä∏Î°ú Íµ¨ÏÑ±
#                     image_block = {
#                         'type': 'image',
#                         'source': {'type': 'base64', 'media_type': media_type, 'data': b64}
#                     }
#                     text_block = {'type': 'text', 'text': text}
#                     content_blocks = [image_block, text_block]

#                     # Îã®Ïùº Î©îÏãúÏßÄÏóê Î∏îÎ°ù Î¶¨Ïä§Ìä∏ Ï†ÑÎã¨
#                     messages.append({'role': 'user', 'content': content_blocks})
#                 else:
#                     # ÌÖçÏä§Ìä∏ Ï†ÑÏö© Î©îÏãúÏßÄ
#                     messages.append({'role': 'user', 'content': [{'type': 'text', 'text': text}]})

#                 # Messages API Ìò∏Ï∂ú
#                 resp = self.client.messages.create(
#                     model=self.model,
#                     messages=messages,
#                     max_tokens=max_tokens
#                 )
#                 # ÏùëÎãµ Î∏îÎ°ùÏóêÏÑú ÌÖçÏä§Ìä∏Îßå Ìï©ÏπòÍ∏∞
#                 assistant_response = ' '.join(getattr(block, 'text', '') for block in resp.content)

#             elif self.api_type == 'groq':
#                 # Groq Chat API
#                 resp = self.client.chat.completions.create(
#                     model=self.model,
#                     messages=self.conversation_history + [{"role": "user", "content": text}],
#                     temperature=0.7,
#                     max_tokens=1024
#                 )
#                 assistant_response = resp.choices[0].message.content

#             else:
#                 raise ValueError(f"Unsupported api_type: {self.api_type}")

#             # ÏùëÎãµ Í∏∞Î°ù Î∞è Î∞òÌôò
#             self.conversation_history.append({"role": "assistant", "content": assistant_response})
#             logger.info(f"[{self.api_type}] Response: {assistant_response[:100]}...")
#             return assistant_response

#         except Exception as e:
#             logger.error(f"Error in chat method ({self.api_type}): {e}", exc_info=True)
#             raise


# paste-2.txt ÏàòÏ†ïÎêú ÎÇ¥Ïö©

# chatbot.py - OpenAI v1.0+ Ìò∏Ìôò Î≤ÑÏ†Ñ
import openai
import anthropic
from groq import Groq
import logging
import json
import asyncio
from typing import Dict, List, Any, Optional

logger = logging.getLogger(__name__)

# sanitize_and_parse_json Ìï®Ïàò (Í∏∞Ï°¥ Ìï®Ïàò Ìè¨Ìï®)
def sanitize_and_parse_json(text, selected_models=None, responses=None):
    """JSON ÏùëÎãµÏùÑ Ï†ïÎ¶¨ÌïòÍ≥† ÌååÏã±ÌïòÎäî Ìï®Ïàò"""
    import re
    try:
        text = text.strip()
        
        # ÏΩîÎìú Î∏îÎ°ù Ï†úÍ±∞
        if text.startswith('```json') and '```' in text:
            text = re.sub(r'```json(.*?)```', r'\1', text, flags=re.DOTALL).strip()
        elif text.startswith('```') and text.endswith('```'):
            text = text[3:-3].strip()
        
        # JSON Ìå®ÌÑ¥ Ï∂îÏ∂ú
        json_pattern = r'({[\s\S]*})'
        json_matches = re.findall(json_pattern, text)
        if json_matches:
            text = json_matches[0]
        
        # Ïù¥Ïä§ÏºÄÏù¥ÌîÑ Î¨∏Ïûê Ï≤òÎ¶¨
        text = re.sub(r'\\([_"])', r'\1', text)
        
        # JSON ÌååÏã±
        result = json.loads(text)
        
        # ÌïÑÏàò ÌïÑÎìú ÌôïÏù∏ Î∞è Î≥¥Ï†ï
        required_fields = ["preferredModel", "best_response", "analysis", "reasoning"]
        for field in required_fields:
            if field not in result:
                if field == "best_response" and "bestResponse" in result:
                    result["best_response"] = result["bestResponse"]
                else:
                    result[field] = "" if field != "analysis" else {}
        
        return result
        
    except Exception as e:
        logger.error(f"JSON ÌååÏã± Ïã§Ìå®: {e}")
        # Ìè¥Î∞± ÏùëÎãµ ÏÉùÏÑ±
        error_analysis = {}
        if selected_models:
            for model in selected_models:
                model_lower = model.lower()
                error_analysis[model_lower] = {"Ïû•Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®", "Îã®Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®"}
        
        return {
            "preferredModel": "ERROR",
            "best_response": max(responses.values(), key=len) if responses else "Î∂ÑÏÑù Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§.",
            "analysis": error_analysis,
            "reasoning": "ÏùëÎãµ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§."
        }
import openai

import anthropic
from groq import Groq
import logging
from .langchain_config import LangChainManager

logger = logging.getLogger(__name__)

class ChatBot:
    def __init__(self, api_key, model, api_type, langchain_manager=None):
        self.conversation_history = []
        self.model = model
        self.api_type = api_type
        self.api_key = api_key
        self.langchain_manager = langchain_manager
        
        # LangChain ÏÇ¨Ïö© Ïó¨Î∂Ä Í≤∞Ï†ï
        self.use_langchain = langchain_manager is not None
        
        if not self.use_langchain:
            # Í∏∞Ï°¥ Î∞©Ïãù Ï¥àÍ∏∞Ìôî
            if api_type == 'openai':
                openai.api_key = api_key
            elif api_type == 'anthropic':
                self.client = anthropic.Anthropic(api_key=api_key)
            elif api_type == 'groq':
                self.client = Groq(api_key=api_key)
        else:
            # LangChain Ï≤¥Ïù∏ ÏÉùÏÑ±
            try:
                if api_type in ['gpt', 'claude']:
                    self.chat_chain = langchain_manager.create_chat_chain(api_type)
                elif api_type == 'groq' or api_type == 'mixtral':
                    # GroqÎäî Î≥ÑÎèÑ Ï≤òÎ¶¨
                    self.groq_llm = langchain_manager.groq_llm if hasattr(langchain_manager, 'groq_llm') else None
                logger.info(f"LangChain Ï≤¥Ïù∏ ÏÉùÏÑ± ÏôÑÎ£å: {api_type}")
            except Exception as e:
                logger.warning(f"LangChain Ï≤¥Ïù∏ ÏÉùÏÑ± Ïã§Ìå®, Í∏∞Ï°¥ Î∞©Ïãù ÏÇ¨Ïö©: {e}")
                self.use_langchain = False
   
    async def chat_async(self, user_input, image_file=None, analysis_mode=None, user_language=None):
        """ÎπÑÎèôÍ∏∞ Ï±ÑÌåÖ Î©îÏÑúÎìú (LangChain Ïö©)"""
        if self.use_langchain:
            return await self._chat_with_langchain(user_input, user_language)
        else:
            return self.chat(user_input, image_file, analysis_mode, user_language)
    
    async def _chat_with_langchain(self, user_input, user_language='ko'):
        """LangChainÏùÑ ÏÇ¨Ïö©Ìïú Ï±ÑÌåÖ"""
        try:
            if self.api_type in ['gpt', 'claude']:
                result = await self.chat_chain.arun(
                    user_input=user_input,
                    user_language=user_language
                )
                return result
            elif self.api_type == 'groq' or self.api_type == 'mixtral':
                if self.groq_llm:
                    prompt = f"ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†ÌÉùÌïú Ïñ∏Ïñ¥Îäî '{user_language}'ÏûÖÎãàÎã§. Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏùëÎãµÌïòÏÑ∏Ïöî.\n\n{user_input}"
                    result = self.groq_llm(prompt)
                    return result
                else:
                    # Ìè¥Î∞±: Í∏∞Ï°¥ Î∞©Ïãù
                    return self.chat(user_input, user_language=user_language)
            else:
                raise ValueError(f"ÏßÄÏõêÌïòÏßÄ ÏïäÎäî API ÌÉÄÏûÖ: {self.api_type}")
                
        except Exception as e:
            logger.error(f"LangChain Ï±ÑÌåÖ ÏóêÎü¨: {e}")
            # Ìè¥Î∞±: Í∏∞Ï°¥ Î∞©Ïãù
            return self.chat(user_input, user_language=user_language)

    def chat(self, user_input, image_file=None, analysis_mode=None, user_language=None):
        """Í∏∞Ï°¥ ÎèôÍ∏∞ Ï±ÑÌåÖ Î©îÏÑúÎìú (Ìò∏ÌôòÏÑ± Ïú†ÏßÄ)"""
        try:
            logger.info(f"Processing chat request for {self.api_type}")
            logger.info(f"User input: {user_input}")
            
            # ÎåÄÌôî Í∏∞Î°ùÏóê ÏÇ¨Ïö©Ïûê ÏûÖÎ†• Ï∂îÍ∞Ä
            if image_file:
                self.conversation_history = [{
                    "role": "system",
                    "content": f"Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù Î™®Îìú: {analysis_mode}, ÏùëÎãµ Ïñ∏Ïñ¥: {user_language}"
                }]
                messages = [
                    {"role": "user", "content": user_input}
                ]
            else:
                self.conversation_history.append({"role": "user", "content": user_input})
                messages = self.conversation_history

            try:
                if self.api_type == 'openai':
                    response = openai.ChatCompletion.create(
                        model=self.model,
                        messages=self.conversation_history,
                        temperature=0.7,
                        max_tokens=1024
                    )
                    assistant_response = response['choices'][0]['message']['content']
                    
                elif self.api_type == 'anthropic':
                    try:
                        # ÏãúÏä§ÌÖú Î©îÏãúÏßÄ Ï∞æÍ∏∞
                        system_message = next((msg['content'] for msg in self.conversation_history 
                                            if msg['role'] == 'system'), '')
                        
                        # ÏÇ¨Ïö©Ïûê Î©îÏãúÏßÄ Ï∞æÍ∏∞
                        user_content = next((msg['content'] for msg in self.conversation_history 
                                        if msg['role'] == 'user'), '')

                        message = self.client.messages.create(
                            model=self.model,
                            max_tokens=4096,
                            temperature=0,
                            system=system_message,
                            messages=[{
                                "role": "user",
                                "content": user_content
                            }]
                        )
                        assistant_response = message.content[0].text
                        logger.info(f"Anthropic response with system message: {system_message[:100]}")
                        
                    except Exception as e:
                        logger.error(f"Anthropic API error: {str(e)}")
                        raise
               
                elif self.api_type == 'groq':
                    response = self.client.chat.completions.create(
                        model=self.model,
                        messages=self.conversation_history,
                        temperature=0.7,
                        max_tokens=1024
                    )
                    assistant_response = response.choices[0].message.content
               
                # ÏùëÎãµ Í∏∞Î°ù
                self.conversation_history.append({
                    "role": "assistant",
                    "content": assistant_response
                })
               
                logger.info(f"Generated response: {assistant_response[:100]}...")
                return assistant_response
               
            except Exception as e:
                logger.error(f"API error in {self.api_type}: {str(e)}", exc_info=True)
                raise
               
        except Exception as e:
            logger.error(f"Error in chat method: {str(e)}", exc_info=True)
            raise

    async def analyze_responses_async(self, responses, query, user_language, selected_models):
        """ÎπÑÎèôÍ∏∞ ÏùëÎãµ Î∂ÑÏÑù (LangChain Ïö©)"""
        if self.use_langchain and self.langchain_manager:
            return await self._analyze_with_langchain(responses, query, user_language, selected_models)
        else:
            return self.analyze_responses(responses, query, user_language, selected_models)
    
    async def _analyze_with_langchain(self, responses, query, user_language, selected_models):
        """LangChainÏùÑ ÏÇ¨Ïö©Ìïú ÏùëÎãµ Î∂ÑÏÑù"""
        try:
            logger.info("\n" + "="*100)
            logger.info("üìä LangChain Î∂ÑÏÑù ÏãúÏûë")
            logger.info(f"ü§ñ Î∂ÑÏÑù ÏàòÌñâ AI: {self.api_type.upper()}")
            logger.info(f"üîç ÏÑ†ÌÉùÎêú Î™®Îç∏Îì§: {', '.join(selected_models)}")
            logger.info("="*100)
            
            # Î∂ÑÏÑù Ï≤¥Ïù∏ ÏÉùÏÑ±
            analysis_chain = self.langchain_manager.create_analysis_chain(self.api_type)
            
            # ÏùëÎãµ Ìè¨Îß∑ÌåÖ
            formatted = self.langchain_manager.format_responses_for_analysis(
                responses, selected_models
            )
            
            # Î∂ÑÏÑù Ïã§Ìñâ
            analysis_result = await analysis_chain.arun(
                query=query,
                user_language=user_language,
                selected_models=selected_models,
                **formatted
            )
            
            # preferredModel ÏÑ§Ï†ï
            analysis_result['preferredModel'] = self.api_type.upper()
            
            logger.info("‚úÖ LangChain Î∂ÑÏÑù ÏôÑÎ£å\n")
            return analysis_result
            
        except Exception as e:
            logger.error(f"‚ùå LangChain Î∂ÑÏÑù ÏóêÎü¨: {str(e)}")
            # Ìè¥Î∞±: Í∏∞Ï°¥ Î∞©Ïãù
            return self.analyze_responses(responses, query, user_language, selected_models)

    def analyze_responses(self, responses, query, user_language, selected_models):
        """Í∏∞Ï°¥ ÎèôÍ∏∞ ÏùëÎãµ Î∂ÑÏÑù Î©îÏÑúÎìú (Ìò∏ÌôòÏÑ± Ïú†ÏßÄ)"""
        try:
            logger.info("\n" + "="*100)
            logger.info("üìä Î∂ÑÏÑù ÏãúÏûë")
            logger.info(f"ü§ñ Î∂ÑÏÑù ÏàòÌñâ AI: {self.api_type.upper()}")
            logger.info(f"üîç ÏÑ†ÌÉùÎêú Î™®Îç∏Îì§: {', '.join(selected_models)}")
            logger.info("="*100)

            # ÏÑ†ÌÉùÎêú Î™®Îç∏Îì§Îßå Î∂ÑÏÑùÏóê Ìè¨Ìï®
            responses_section = ""
            analysis_section = ""
            
            for model in selected_models:
                model_lower = model.lower()
                responses_section += f"\n{model.upper()} ÏùëÎãµ: Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏûëÏÑ± {responses.get(model_lower, 'ÏùëÎãµ ÏóÜÏùå')}"
                
                analysis_section += f"""
                        "{model_lower}": {{
                            "Ïû•Ï†ê": "Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏûëÏÑ± {model.upper()} ÎãµÎ≥ÄÏùò Ïû•Ï†ê",
                            "Îã®Ï†ê": "Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏûëÏÑ± {model.upper()} ÎãµÎ≥ÄÏùò Îã®Ï†ê"
                        }}{"," if model_lower != selected_models[-1].lower() else ""}"""

            # Í∏∞Ï°¥ Î∂ÑÏÑù ÌîÑÎ°¨ÌîÑÌä∏ (Î≥ÄÍ≤Ω ÏóÜÏùå)
            analysis_prompt = f"""Îã§ÏùåÏùÄ ÎèôÏùºÌïú ÏßàÎ¨∏Ïóê ÎåÄÌïú {len(selected_models)}Í∞ÄÏßÄ AIÏùò ÏùëÎãµÏùÑ Î∂ÑÏÑùÌïòÎäî Í≤ÉÏûÖÎãàÎã§.
                    ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†ÌÉùÌïú Ïñ∏Ïñ¥Îäî '{user_language}'ÏûÖÎãàÎã§.
                    Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏµúÏ†ÅÏùò ÎãµÏùÑ ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
                    Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú Ïû•Ï†êÏùÑ ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
                    Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú Îã®Ï†êÏùÑ ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.
                    Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú Î∂ÑÏÑù Í∑ºÍ±∞Î•º ÏûëÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî.

                    ÏßàÎ¨∏: {query}
                    {responses_section}

                     [ÏµúÏ†ÅÏùò ÏùëÎãµÏùÑ ÎßåÎì§ Îïå Í≥†Î†§Ìï† ÏÇ¨Ìï≠]
                    - Î™®Îì† AIÏùò ÎãµÎ≥ÄÎì§ÏùÑ Ï¢ÖÌï©ÌïòÏó¨ ÏµúÏ†ÅÏùò ÎãµÎ≥ÄÏúºÎ°ú Î∞òÎìúÏãú Ïû¨Íµ¨ÏÑ±Ìï©ÎãàÎã§
                    - Í∏∞Ï°¥ AIÏùò ÎãµÎ≥ÄÏùÑ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©ÌïòÎ©¥ ÏïàÎê©ÎãàÎã§
                    - Ï¶â, Í∏∞Ï°¥ AIÏùò ÎãµÎ≥ÄÍ≥º ÏµúÏ†ÅÏùò ÎãµÎ≥ÄÏù¥ ÎèôÏùºÌïòÎ©¥ ÏïàÎê©ÎãàÎã§.
                    - Îã§ÏàòÏùò AIÍ∞Ä Í≥µÌÜµÏúºÎ°ú Ï†úÍ≥µÌïú Ï†ïÎ≥¥Îäî Í∞ÄÏû• Ïã†Î¢∞Ìï† Ïàò ÏûàÎäî Ïò¨Î∞îÎ•∏ Ï†ïÎ≥¥Î°ú Í∞ÑÏ£ºÌï©ÎãàÎã§
                    - ÏΩîÎìúÎ•º Î¨ªÎäî ÏßàÎ¨∏ÏùºÎïåÎäî, AIÏùò ÎãµÎ≥Ä Ï§ë Ï†úÏùº Ï¢ãÏùÄ ÎãµÎ≥ÄÏùÑ ÏÑ†ÌÉùÌï¥ÏÑú Ïû¨Íµ¨ÏÑ±Ìï¥Ï§ò
                    - Î∞òÎìúÏãú JSON ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî
                    [Ï∂úÎ†• ÌòïÏãù]
                    {{
                        "preferredModel": "{self.api_type.upper()}",
                        "best_response": "ÏµúÏ†ÅÏùò ÎãµÎ≥Ä ({user_language}Î°ú ÏûëÏÑ±)",
                        "analysis": {{
                            {analysis_section}
                        }},
                        "reasoning": "Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏûëÏÑ± ÏµúÏ†ÅÏùò ÏùëÎãµÏùÑ ÏÑ†ÌÉùÌïú Ïù¥Ïú†"
                    }}"""

            # Í∏∞Ï°¥ API Ìò∏Ï∂ú Î°úÏßÅ (Î≥ÄÍ≤Ω ÏóÜÏùå)
            if self.api_type == 'openai':
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant. Always respond with valid JSON ONLY, no additional text or explanations."},
                        {"role": "user", "content": analysis_prompt}
                    ],
                    temperature=0,
                    max_tokens=4096
                )
                analysis_text = response['choices'][0]['message']['content']
                
            elif self.api_type == 'anthropic':
                system_message = next((msg['content'] for msg in self.conversation_history 
                                    if msg['role'] == 'system'), '')
                
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=4096,
                    temperature=0,
                    system=f"{system_message}\nYou must respond with valid JSON only in the specified language. No other text or formatting.",
                    messages=[{
                        "role": "user", 
                        "content": analysis_prompt
                    }]
                )
                analysis_text = message.content[0].text.strip()
            
            elif self.api_type == 'groq':
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "You are a helpful assistant. Always respond with valid JSON ONLY, no additional text or explanations."},
                        {"role": "user", "content": analysis_prompt}
                    ],
                    temperature=0,
                    max_tokens=4096
                )
                analysis_text = response.choices[0].message.content

            logger.info("‚úÖ Î∂ÑÏÑù ÏôÑÎ£å\n")
            
            # JSON ÌååÏã± (Í∏∞Ï°¥ Ìï®Ïàò ÏÇ¨Ïö©)
            from paste_3 import sanitize_and_parse_json  # Í∏∞Ï°¥ Ìï®Ïàò import
            analysis_result = sanitize_and_parse_json(analysis_text, selected_models, responses)
            analysis_result['preferredModel'] = self.api_type.upper()
            
            return analysis_result
        
        except Exception as e:
            logger.error(f"‚ùå Analysis error: {str(e)}")
            # Í∏∞Ï°¥ Ìè¥Î∞± Î°úÏßÅ
            error_analysis = {}
            for model in selected_models:
                model_lower = model.lower()
                error_analysis[model_lower] = {"Ïû•Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®", "Îã®Ï†ê": "Î∂ÑÏÑù Ïã§Ìå®"}
            
            return {
                "preferredModel": self.api_type.upper(),
                "best_response": max(responses.values(), key=len) if responses else "",
                "analysis": error_analysis,
                "reasoning": "ÏùëÎãµ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌïòÏó¨ ÏµúÏ†ÅÏùò ÎãµÎ≥ÄÏùÑ ÏÉùÏÑ±ÌïòÏßÄ Î™ªÌñàÏäµÎãàÎã§."
            }
# class ChatView(APIView):
#     permission_classes = [AllowAny]

#     def post(self, request, preferredModel):
#         try:
#             logger.info(f"Received chat request for {preferredModel}")
            
#             data = request.data
#             user_message = data.get('message')
#             compare_responses = data.get('compare', True)
            
#             # ÏÉàÎ°úÏö¥ ÌååÎùºÎØ∏ÌÑ∞: ÏÑ†ÌÉùÎêú Î™®Îç∏Îì§
#             selected_models = data.get('selectedModels', ['gpt', 'claude', 'mixtral'])
            
#             # ÏÑ†ÌÉùÎêú Î™®Îç∏ Î°úÍ∑∏
#             logger.info(f"Selected models: {selected_models}")
            
#             # ÌÜ†ÌÅ∞ Ïú†Î¨¥Ïóê Îî∞Î•∏ Ïñ∏Ïñ¥ Î∞è ÏÑ†Ìò∏ Î™®Îç∏ Ï≤òÎ¶¨
#             token = request.headers.get('Authorization')
#             if not token:
#                 # ÎπÑÎ°úÍ∑∏Ïù∏: Í∏∞Î≥∏ Ïñ∏Ïñ¥Îäî ko, ÏÑ†Ìò∏ Î™®Îç∏ÏùÄ GPTÎ°ú Í≥†Ï†ï
#                 user_language = 'ko'
#                 preferredModel = 'gpt'
#             else:
#                 # Î°úÍ∑∏Ïù∏: ÏöîÏ≤≠ Îç∞Ïù¥ÌÑ∞Ïùò Ïñ∏Ïñ¥ ÏÇ¨Ïö© (ÌòπÏùÄ ÏÇ¨Ïö©ÏûêÏùò ÏÑ§Ï†ïÏùÑ Îî∞Î¶Ñ)
#                 user_language = data.get('language', 'ko')
#                 # URLÏóê Ï†ÑÎã¨Îêú preferredModelÏùÑ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö© (ÌîÑÎ°†Ìä∏ÏóîÎìúÏóêÏÑú ÏÇ¨Ïö©Ïûê ÏÑ§Ï†ï Î∞òÏòÅ)

#             logger.info(f"Received language setting: {user_language}")

#             if not user_message:
#                 return Response({'error': 'No message provided'}, 
#                                 status=status.HTTP_400_BAD_REQUEST)

#             # ÎπÑÎèôÍ∏∞ ÏùëÎãµÏùÑ ÏúÑÌïú StreamingHttpResponse ÏÇ¨Ïö©
#             from django.http import StreamingHttpResponse
#             import json
#             import time

#             def stream_responses():
#                 try:
#                     system_message = {
#                         "role": "system",
#                         "content": f"ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†ÌÉùÌïú Ïñ∏Ïñ¥Îäî '{user_language}'ÏûÖÎãàÎã§. Î∞òÎìúÏãú Î™®Îì† ÏùëÎãµÏùÑ Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú Ï†úÍ≥µÌï¥Ï£ºÏÑ∏Ïöî."
#                     }
                    
#                     responses = {}
                    
#                     # ÌòÑÏû¨ ÏöîÏ≤≠Ïóê ÎåÄÌïú Í≥†Ïú† ÏãùÎ≥ÑÏûê ÏÉùÏÑ± (ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ ÌôúÏö©)
#                     request_id = str(time.time())
                    
#                     # ÏÑ†ÌÉùÎêú Î™®Îç∏Îì§Îßå ÎåÄÌôîÏóê Ï∞∏Ïó¨ÏãúÌÇ¥
#                     selected_chatbots = {model: chatbots.get(model) for model in selected_models if model in chatbots}
                    
#                     # Í∞Å Î¥áÏùò ÏùëÎãµÏùÑ Í∞úÎ≥ÑÏ†ÅÏúºÎ°ú Ï≤òÎ¶¨ÌïòÍ≥† Ï¶âÏãú ÏùëÎãµ
#                     for bot_id, bot in selected_chatbots.items():
#                         if bot is None:
#                             logger.warning(f"Selected model {bot_id} not available in chatbots")
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': f"Model {bot_id} is not available"
#                             }) + '\n'
#                             continue
                            
#                         try:
#                             # Îß§Î≤à ÏÉàÎ°úÏö¥ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏ ÏÉùÏÑ± (Ïù¥Ï†Ñ ÎÇ¥Ïö© Ï¥àÍ∏∞Ìôî)
#                             bot.conversation_history = [system_message]
#                             response = bot.chat(user_message)
#                             responses[bot_id] = response
                            
#                             # Í∞Å Î¥á ÏùëÎãµÏùÑ Ï¶âÏãú Ï†ÑÏÜ°
#                             yield json.dumps({
#                                 'type': 'bot_response',
#                                 'botId': bot_id,
#                                 'response': response,
#                                 'requestId': request_id  # ÏöîÏ≤≠ ID Ï∂îÍ∞Ä
#                             }) + '\n'
                            
#                         except Exception as e:
#                             logger.error(f"Error from {bot_id}: {str(e)}")
#                             responses[bot_id] = f"Error: {str(e)}"
                            
#                             # ÏóêÎü¨ÎèÑ Ï¶âÏãú Ï†ÑÏÜ°
#                             yield json.dumps({
#                                 'type': 'bot_error',
#                                 'botId': bot_id,
#                                 'error': str(e),
#                                 'requestId': request_id  # ÏöîÏ≤≠ ID Ï∂îÍ∞Ä
#                             }) + '\n'
                    
#                     # ÏÑ†ÌÉùÎêú Î™®Îç∏Ïù¥ ÏûàÍ≥† ÏùëÎãµÏù¥ ÏûàÏùÑ ÎïåÎßå Î∂ÑÏÑù ÏàòÌñâ
#                     if selected_models and responses:
#                         # Î∂ÑÏÑù(ÎπÑÍµê)ÏùÄ Î°úÍ∑∏Ïù∏ Ïãú ÏÇ¨Ïö©ÏûêÏùò ÏÑ†Ìò∏ Î™®Îç∏ÏùÑ, ÎπÑÎ°úÍ∑∏Ïù∏ Ïãú GPTÎ•º ÏÇ¨Ïö©
#                         if token:
#                             analyzer_bot = chatbots.get(preferredModel) or chatbots.get('gpt')
#                         else:
#                             analyzer_bot = chatbots.get('gpt')
                        
#                         # Î∂ÑÏÑùÏö© Î¥áÎèÑ ÏÉàÎ°úÏö¥ ÎåÄÌôî Ïª®ÌÖçÏä§Ìä∏Î°ú Ï¥àÍ∏∞Ìôî
#                         analyzer_bot.conversation_history = [system_message]
                        
#                         # Î∂ÑÏÑù Ïã§Ìñâ (Ìï≠ÏÉÅ ÏÉàÎ°≠Í≤å Ïã§Ìñâ)
#                         analysis = analyzer_bot.analyze_responses(responses, user_message, user_language, selected_models)
                        
#                         # Î∂ÑÏÑù Í≤∞Í≥º Ï†ÑÏÜ°
#                         yield json.dumps({
#                             'type': 'analysis',
#                             'preferredModel': analyzer_bot and analyzer_bot.api_type.upper(),
#                             'best_response': analysis.get('best_response', ''),
#                             'analysis': analysis.get('analysis', {}),
#                             'reasoning': analysis.get('reasoning', ''),
#                             'language': user_language,
#                             'requestId': request_id,  # ÏöîÏ≤≠ ID Ï∂îÍ∞Ä
#                             'timestamp': time.time()  # ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Ï∂îÍ∞Ä
#                         }) + '\n'
#                     else:
#                         logger.warning("No selected models or responses to analyze")
                    
#                 except Exception as e:
#                     logger.error(f"Stream processing error: {str(e)}", exc_info=True)
#                     yield json.dumps({
#                         'type': 'error',
#                         'error': f"Stream processing error: {str(e)}"
#                     }) + '\n'

#             # StreamingHttpResponse Î∞òÌôò
#             response = StreamingHttpResponse(
#                 streaming_content=stream_responses(),
#                 content_type='text/event-stream'
#             )
#             response['Cache-Control'] = 'no-cache'
#             response['X-Accel-Buffering'] = 'no'
#             return response
                
#         except Exception as e:
#             logger.error(f"Unexpected error: {str(e)}", exc_info=True)
#             return Response({
#                 'error': str(e)
#             }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
from django.http import StreamingHttpResponse
import logging
import json
import openai
import anthropic
from groq import Groq
from django.conf import settings
from bs4 import BeautifulSoup
import re
import time
import asyncio
from asgiref.sync import sync_to_async

# ÏÉàÎ°ú Ï∂îÍ∞ÄÎêú import
from .langchain_config import LangChainManager
from .langgraph_workflow import AIComparisonWorkflow

logger = logging.getLogger(__name__)

def convert_to_serializable(obj):
    """Í∞ùÏ≤¥Î•º ÏßÅÎ†¨Ìôî Í∞ÄÎä•Ìïú ÌòïÌÉúÎ°ú Î≥ÄÌôò"""
    if hasattr(obj, '__dict__'):
        return {k: convert_to_serializable(v) for k, v in obj.__dict__.items()}
    elif isinstance(obj, dict):
        return {k: convert_to_serializable(v) for k, v in obj.items()}
    elif isinstance(obj, list):
        return [convert_to_serializable(item) for item in obj]
    else:
        return obj

class ChatView(APIView):
    permission_classes = [AllowAny]

    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        
        # Í∏∞Ï°¥ Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑùÍ∏∞
        from .similarity_analyzer import SimilarityAnalyzer  # Ïã§Ï†ú import Í≤ΩÎ°úÎ°ú Î≥ÄÍ≤Ω ÌïÑÏöî
        self.similarity_analyzer = SimilarityAnalyzer(threshold=0.85)
        
        # LangChain Í¥ÄÎ¶¨Ïûê Ï¥àÍ∏∞Ìôî
        self.langchain_manager = LangChainManager(
            openai_key=OPENAI_API_KEY,
            anthropic_key=ANTHROPIC_API_KEY,
            groq_key=GROQ_API_KEY
        )
        
        # LangGraph ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ï¥àÍ∏∞Ìôî
        self.workflow = AIComparisonWorkflow(
            langchain_manager=self.langchain_manager,
            similarity_analyzer=self.similarity_analyzer
        )
        
        # Í∏∞Ï°¥ ChatBot Ïù∏Ïä§ÌÑ¥Ïä§Îì§ÎèÑ LangChain ÏÇ¨Ïö©ÌïòÎèÑÎ°ù ÏóÖÎç∞Ïù¥Ìä∏
        self.update_chatbots_with_langchain()

    def update_chatbots_with_langchain(self):
        """Í∏∞Ï°¥ ChatBotÎì§ÏùÑ LangChainÏùÑ ÏÇ¨Ïö©ÌïòÎèÑÎ°ù ÏóÖÎç∞Ïù¥Ìä∏"""
        global chatbots
        
        # Í∏∞Ï°¥ ChatBotÎì§Ïóê LangChain Îß§ÎãàÏ†Ä Ï∂îÍ∞Ä
        for bot_id, bot in chatbots.items():
            bot.langchain_manager = self.langchain_manager
            bot.use_langchain = True
            
            # LangChain Ï≤¥Ïù∏ ÏÉùÏÑ± ÏãúÎèÑ
            try:
                if bot_id == 'gpt':
                    bot.chat_chain = self.langchain_manager.create_chat_chain('gpt')
                elif bot_id == 'claude':
                    bot.chat_chain = self.langchain_manager.create_chat_chain('claude')
                elif bot_id == 'mixtral':
                    bot.groq_llm = self.langchain_manager.groq_llm if hasattr(self.langchain_manager, 'groq_llm') else None
                logger.info(f"LangChain Ï≤¥Ïù∏ ÏÉùÏÑ± ÏôÑÎ£å: {bot_id}")
            except Exception as e:
                logger.warning(f"LangChain Ï≤¥Ïù∏ ÏÉùÏÑ± Ïã§Ìå® ({bot_id}), Í∏∞Ï°¥ Î∞©Ïãù ÏÇ¨Ïö©: {e}")
                bot.use_langchain = False

    def post(self, request, preferredModel):
        try:
            logger.info(f"Received chat request for {preferredModel}")
            data = request.data
            user_message = data.get('message')
            selected_models = data.get('selectedModels', ['gpt', 'claude', 'mixtral'])
            token = request.headers.get('Authorization')
            user_language = 'ko' if not token else data.get('language', 'ko')
            use_workflow = data.get('useWorkflow', True)  # ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÏÇ¨Ïö© Ïó¨Î∂Ä
            
            if not user_message:
                return Response({'error': 'No message provided'}, status=status.HTTP_400_BAD_REQUEST)

            # URL Ï≤òÎ¶¨ Î°úÏßÅ (Í∏∞Ï°¥Í≥º ÎèôÏùº)
            url_pattern = r'^(https?://\S+)$'
            match = re.match(url_pattern, user_message.strip())
            if match:
                url = match.group(1)
                try:
                    page_text = fetch_and_clean_url(url)
                    if len(page_text) > 10000:
                        page_text = page_text[:5000] + "\n\n‚Ä¶(Ï§ëÎûµ)‚Ä¶\n\n" + page_text[-5000:]
                    user_message = (
                        f"Îã§Ïùå ÏõπÌéòÏù¥ÏßÄÏùò ÎÇ¥Ïö©ÏùÑ Î∂ÑÏÑùÌï¥ Ï£ºÏÑ∏Ïöî:\n"
                        f"URL: {url}\n\n"
                        f"{page_text}"
                    )
                except Exception as e:
                    logger.error(f"URL fetch error: {e}")
                    return Response({'error': f"URLÏùÑ Í∞ÄÏ†∏Ïò§ÏßÄ Î™ªÌñàÏäµÎãàÎã§: {e}"}, status=status.HTTP_400_BAD_REQUEST)

            # ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÏÇ¨Ïö© Ïó¨Î∂ÄÏóê Îî∞Î•∏ Î∂ÑÍ∏∞
            if use_workflow:
                return self.handle_with_workflow(user_message, selected_models, user_language, preferredModel)
            else:
                return self.handle_with_legacy(user_message, selected_models, user_language, preferredModel)

        except Exception as e:
            logger.error(f"Unexpected error: {e}", exc_info=True)
            return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    def handle_with_workflow(self, user_message, selected_models, user_language, preferred_model):
        """LangGraph ÏõåÌÅ¨ÌîåÎ°úÏö∞Î•º ÏÇ¨Ïö©Ìïú Ï≤òÎ¶¨"""
        def stream_workflow_responses():
            try:
                request_id = str(time.time())
                
                # ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ïã§ÌñâÏùÑ ÏúÑÌïú async ÎûòÌçº
                async def run_workflow_async():
                    return await self.workflow.run_workflow(
                        user_message=user_message,
                        selected_models=selected_models,
                        user_language=user_language,
                        request_id=request_id
                    )
                
                # asyncio Ïù¥Î≤§Ìä∏ Î£®ÌîÑÏóêÏÑú Ïã§Ìñâ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                try:
                    workflow_result = loop.run_until_complete(run_workflow_async())
                finally:
                    loop.close()
                
                # Í∞úÎ≥Ñ ÏùëÎãµ Ïä§Ìä∏Î¶¨Î∞ç
                for bot_id, response in workflow_result["individual_responses"].items():
                    yield json.dumps({
                        'type': 'bot_response',
                        'botId': bot_id,
                        'response': response,
                        'requestId': request_id
                    }) + '\n'
                
                # Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑù Í≤∞Í≥º
                if workflow_result["similarity_analysis"]:
                    yield json.dumps({
                        'type': 'similarity_analysis',
                        'result': workflow_result["similarity_analysis"],
                        'requestId': request_id,
                        'timestamp': time.time(),
                        'userMessage': user_message
                    }) + '\n'
                
                # ÏµúÏ¢Ö Î∂ÑÏÑù Í≤∞Í≥º
                final_analysis = workflow_result["final_analysis"]
                yield json.dumps({
                    'type': 'analysis',
                    'preferredModel': final_analysis.get('preferredModel', preferred_model.upper()),
                    'best_response': final_analysis.get('best_response', ''),
                    'analysis': final_analysis.get('analysis', {}),
                    'reasoning': final_analysis.get('reasoning', ''),
                    'language': user_language,
                    'requestId': request_id,
                    'timestamp': time.time(),
                    'userMessage': user_message,
                    'workflowUsed': True,
                    'errors': workflow_result.get("errors", [])
                }) + '\n'
                
            except Exception as e:
                logger.error(f"ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ïä§Ìä∏Î¶¨Î∞ç ÏóêÎü¨: {e}")
                yield json.dumps({
                    'type': 'error',
                    'error': f"Workflow error: {e}",
                    'fallbackToLegacy': True
                }) + '\n'

        return StreamingHttpResponse(stream_workflow_responses(), content_type='text/event-stream')

    def handle_with_legacy(self, user_message, selected_models, user_language, preferred_model):
        """Í∏∞Ï°¥ Î∞©ÏãùÏúºÎ°ú Ï≤òÎ¶¨ (Ìò∏ÌôòÏÑ± Ïú†ÏßÄ)"""
        def stream_responses():
            try:
                system_message = {
                    'role': 'system',
                    'content': f"ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†ÌÉùÌïú Ïñ∏Ïñ¥Îäî '{user_language}'ÏûÖÎãàÎã§. Î∞òÎìúÏãú Ïù¥ Ïñ∏Ïñ¥({user_language})Î°ú ÏùëÎãµÌïòÏÑ∏Ïöî."
                }
                responses = {}
                request_id = str(time.time())
                
                # Í∞Å Î™®Îç∏Î≥Ñ Ï±óÎ¥á Ïù∏Ïä§ÌÑ¥Ïä§ Í∞ÄÏ†∏Ïò§Í∏∞
                selected_chatbots = {m: chatbots.get(m) for m in selected_models if chatbots.get(m)}

                # Î™®Îç∏ ÏùëÎãµ ÏàòÏßë (ÎπÑÎèôÍ∏∞ Ï≤òÎ¶¨ ÏãúÎèÑ)
                async def collect_responses_async():
                    responses = {}
                    tasks = []
                    
                    for bot_id, bot in selected_chatbots.items():
                        if hasattr(bot, 'chat_async') and bot.use_langchain:
                            # LangChain ÎπÑÎèôÍ∏∞ ÏÇ¨Ïö©
                            task = bot.chat_async(user_message, user_language=user_language)
                        else:
                            # Í∏∞Ï°¥ ÎèôÍ∏∞ Î∞©ÏãùÏùÑ ÎπÑÎèôÍ∏∞Î°ú ÎûòÌïë
                            task = sync_to_async(self.sync_chat)(bot, user_message, system_message)
                        tasks.append((bot_id, task))
                    
                    for bot_id, task in tasks:
                        try:
                            response = await task
                            responses[bot_id] = response
                            logger.info(f"‚úÖ {bot_id} ÏùëÎãµ ÏôÑÎ£å")
                        except Exception as e:
                            logger.error(f"‚ùå {bot_id} ÏùëÎãµ Ïã§Ìå®: {e}")
                    
                    return responses

                # ÎπÑÎèôÍ∏∞ ÏùëÎãµ ÏàòÏßë
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                
                try:
                    responses = loop.run_until_complete(collect_responses_async())
                finally:
                    loop.close()

                # Í∞úÎ≥Ñ ÏùëÎãµ Ïä§Ìä∏Î¶¨Î∞ç
                for bot_id, resp_text in responses.items():
                    yield json.dumps({
                        'type': 'bot_response',
                        'botId': bot_id,
                        'response': resp_text,
                        'requestId': request_id
                    }) + '\n'

                # Ïú†ÏÇ¨ÎèÑ Î∂ÑÏÑù
                if len(responses) >= 2:
                    sim_res = self.similarity_analyzer.cluster_responses(responses)
                    serial = convert_to_serializable(sim_res)
                    yield json.dumps({
                        'type': 'similarity_analysis',
                        'result': serial,
                        'requestId': request_id,
                        'timestamp': time.time(),
                        'userMessage': user_message
                    }) + '\n'

                # ÏµúÏ¢Ö ÎπÑÍµê Î∞è Î∂ÑÏÑù
                analyzer_bot = chatbots.get(preferred_model) or chatbots.get('gpt')
                analyzer_bot.conversation_history = [system_message]
                
                # LangChain ÎπÑÎèôÍ∏∞ Î∂ÑÏÑù ÏãúÎèÑ
                if hasattr(analyzer_bot, 'analyze_responses_async') and analyzer_bot.use_langchain:
                    async def analyze_async():
                        return await analyzer_bot.analyze_responses_async(
                            responses, user_message, user_language, list(responses.keys())
                        )
                    
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    
                    try:
                        analysis = loop.run_until_complete(analyze_async())
                    finally:
                        loop.close()
                else:
                    # Í∏∞Ï°¥ ÎèôÍ∏∞ Î∞©Ïãù
                    analysis = analyzer_bot.analyze_responses(
                        responses, user_message, user_language, list(responses.keys())
                    )
                
                yield json.dumps({
                    'type': 'analysis',
                    'preferredModel': analyzer_bot.api_type.upper(),
                    'best_response': analysis.get('best_response', ''),
                    'analysis': analysis.get('analysis', {}),
                    'reasoning': analysis.get('reasoning', ''),
                    'language': user_language,
                    'requestId': request_id,
                    'timestamp': time.time(),
                    'userMessage': user_message,
                    'workflowUsed': False
                }) + '\n'
                
            except Exception as e:
                yield json.dumps({
                    'type': 'error',
                    'error': f"Stream error: {e}"
                }) + '\n'

        return StreamingHttpResponse(stream_responses(), content_type='text/event-stream')

    def sync_chat(self, bot, user_message, system_message):
        """ÎèôÍ∏∞ Ï±ÑÌåÖÏùÑ ÏúÑÌïú Ìó¨Ìçº Î©îÏÑúÎìú"""
        bot.conversation_history = [system_message]
        return bot.chat(user_message)

# API ÌÇ§ ÏÑ§Ï†ï (Í∏∞Ï°¥Í≥º ÎèôÏùº)
OPENAI_API_KEY = "***REMOVED***"
ANTHROPIC_API_KEY = "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"
GROQ_API_KEY = "***REMOVED***"

# ChatBot import (ÏàòÏ†ïÎêú Î≤ÑÏ†Ñ)

chatbots = {
    'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
    'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
    'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
}
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import IsAuthenticated
from .models import UserProfile, UserSettings
from .serializers import UserSerializer

class UserSettingsView(APIView):
    permission_classes = [IsAuthenticated]

    def get(self, request):
        try:
            user_settings, created = UserSettings.objects.get_or_create(
                user=request.user,
                defaults={
                    'language': 'ko',
                    'analyzer_bot': 'claude'
                }
            )
            serializer = UserSerializer(user_settings)
            return Response(serializer.data)
        except Exception as e:
            return Response({
                'language': 'ko', 
                'analyzer_bot': 'claude'
            }, status=status.HTTP_200_OK)

    def post(self, request):
        try:
            user_settings, created = UserSettings.objects.get_or_create(
                user=request.user,
                defaults={
                    'language': request.data.get('language', 'ko'),
                    'analyzer_bot': request.data.get('analyzer_bot', 'claude')
                }
            )

            # Ïù¥ÎØ∏ Ï°¥Ïû¨ÌïòÎäî Í≤ΩÏö∞ ÏóÖÎç∞Ïù¥Ìä∏
            if not created:
                user_settings.language = request.data.get('language', user_settings.language)
                user_settings.analyzer_bot = request.data.get('analyzer_bot', user_settings.analyzer_bot)
                user_settings.save()

            serializer = UserSettingsSerializer(user_settings)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_400_BAD_REQUEST)
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import AllowAny
from rest_framework.response import Response
import requests
import logging
from django.contrib.auth import get_user_model
from .models import SocialAccount

import uuid

logger = logging.getLogger(__name__)
User = get_user_model()

# def generate_unique_username(email, name=None):
#     """Í≥†Ïú†Ìïú username ÏÉùÏÑ±"""
#     base = name or email.split('@')[0]
#     username = base
#     suffix = 1
    
#     # usernameÏù¥ Í≥†Ïú†Ìï† ÎïåÍπåÏßÄ Ïà´Ïûê Ï∂îÍ∞Ä
#     while User.objects.filter(username=username).exists():
#         username = f"{base}_{suffix}"
#         suffix += 1
    
#     return username

def generate_unique_username(email, name=None):
    """username ÏÉùÏÑ± - Ïù¥Î©îÏùº ÏïûÎ∂ÄÎ∂Ñ ÎòêÎäî Ïù¥Î¶Ñ ÏÇ¨Ïö©"""
    if name:
        return name  # Ïù¥Î¶ÑÏù¥ ÏûàÏúºÎ©¥ Í∑∏ÎåÄÎ°ú ÏÇ¨Ïö©
    return email.split('@')[0]  # Ïù¥Î¶ÑÏù¥ ÏóÜÏúºÎ©¥ Ïù¥Î©îÏùº ÏïûÎ∂ÄÎ∂Ñ ÏÇ¨Ïö©
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import AllowAny
from rest_framework.authtoken.models import Token
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
# views.py
from django.db import transaction, IntegrityError

# @api_view(['GET'])
# @authentication_classes([TokenAuthentication])
# @permission_classes([AllowAny])
# @api_view(['GET'])
# @permission_classes([AllowAny])
# def google_callback(request):
#     logger.info("Starting Google callback process")  # Î°úÍπÖ Ï∂îÍ∞Ä
#     try:
#         with transaction.atomic():
#             # 1. ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Í∞ÄÏ†∏Ïò§Í∏∞
#             auth_header = request.headers.get('Authorization', '')
#             access_token = auth_header.split(' ')[1]
            
#             user_info_response = requests.get(
#                 'https://www.googleapis.com/oauth2/v3/userinfo',
#                 headers={'Authorization': f'Bearer {access_token}'}
#             )
            
#             user_info = user_info_response.json()
#             email = user_info.get('email')
#             name = user_info.get('name')

#             logger.info(f"Processing user: {email}")  # Î°úÍπÖ Ï∂îÍ∞Ä

#             # 2. User Í∞ùÏ≤¥ Í∞ÄÏ†∏Ïò§Í∏∞ ÎòêÎäî ÏÉùÏÑ±
#             user = User.objects.filter(email=email).first()
#             if not user:
#                 user = User.objects.create(
#                     username=email,
#                     email=email,
#                     first_name=name or '',
#                     is_active=True
#                 )
#                 logger.info(f"Created new user: {user.id}")
#             else:
#                 logger.info(f"Found existing user: {user.id}")

#             # 3. Í∏∞Ï°¥ UserSettings ÏÇ≠Ï†ú (ÏûàÎã§Î©¥)
#             UserSettings.objects.filter(user=user).delete()
#             logger.info("Deleted any existing settings")

#             # 4. ÏÉàÎ°úÏö¥ UserSettings ÏÉùÏÑ±
#             settings = UserSettings.objects.create(
#                 user=user,
#                 language='ko',
#                 preferred_model='default'
#             )
#             logger.info(f"Created new settings for user: {user.id}")

#             # 5. ÌÜ†ÌÅ∞ ÏÉùÏÑ±
#             token, _ = Token.objects.get_or_create(user=user)
            
#             return Response({
#                 'user': {
#                     'id': user.id,
#                     'email': user.email,
#                     'username': user.username,
#                     'first_name': user.first_name,
#                     'settings': {
#                         'language': settings.language,
#                         'preferred_model': settings.preferred_model
#                     }
#                 },
#                 'access_token': token.key
#             })
#     except Exception as e:
#         logger.error(f"Error in google_callback: {str(e)}")
#         return Response(
#             {'error': str(e)},
#             status=status.HTTP_400_BAD_REQUEST
        # )
@api_view(['GET'])
@authentication_classes([TokenAuthentication])
@permission_classes([AllowAny])
def google_callback(request):
    try:
        # Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞ Ï∂îÏ∂ú
        auth_header = request.headers.get('Authorization', '')
        if not auth_header.startswith('Bearer '):
            return Response(
                {'error': 'ÏûòÎ™ªÎêú Ïù∏Ï¶ù Ìó§Îçî'}, 
                status=status.HTTP_401_UNAUTHORIZED
            )
        
        access_token = auth_header.split(' ')[1]

        # Google APIÎ°ú ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ ÏöîÏ≤≠
        user_info_response = requests.get(
            'https://www.googleapis.com/oauth2/v3/userinfo',
            headers={'Authorization': f'Bearer {access_token}'}
        )

        if user_info_response.status_code != 200:
            return Response(
                {'error': 'GoogleÏóêÏÑú ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥Î•º Í∞ÄÏ†∏Ïò§ÎäîÎç∞ Ïã§Ìå®ÌñàÏäµÎãàÎã§'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        user_info = user_info_response.json()
        email = user_info.get('email')
        name = user_info.get('name')
        
        if not email:
            return Response(
                {'error': 'Ïù¥Î©îÏùºÏù¥ Ï†úÍ≥µÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§'}, 
                status=status.HTTP_400_BAD_REQUEST
            )

        try:
            # Í∏∞Ï°¥ ÏÇ¨Ïö©Ïûê Í≤ÄÏÉâ
            user = User.objects.get(email=email)
        except User.DoesNotExist:
            # ÏÉàÎ°úÏö¥ ÏÇ¨Ïö©Ïûê ÏÉùÏÑ±
            username = generate_unique_username(email, name)
            user = User.objects.create(
                username=username,
                email=email,
                is_active=True
            )
            
            # Í∏∞Î≥∏ ÎπÑÎ∞ÄÎ≤àÌò∏ ÏÑ§Ï†ï (ÏÑ†ÌÉùÏ†Å)
            random_password = uuid.uuid4().hex
            user.set_password(random_password)
            user.save()

        # ÏÜåÏÖú Í≥ÑÏ†ï Ï†ïÎ≥¥ ÏÉùÏÑ± ÎòêÎäî ÏóÖÎç∞Ïù¥Ìä∏
        social_account, created = SocialAccount.objects.get_or_create(
            email=email,
            provider='google',
            defaults={'user': user}
        )

        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()

        # ÌÜ†ÌÅ∞ ÏÉùÏÑ± ÎòêÎäî Í∞ÄÏ†∏Ïò§Í∏∞
        token, created = Token.objects.get_or_create(user=user)
        logger.info(f"GOOGLE Token created: {created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")


        # ÏÇ¨Ïö©Ïûê Îç∞Ïù¥ÌÑ∞ Î∞òÌôò
        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token Î∞òÌôò
            'token_created': created,
            'google_access_token': access_token,  # Google OAuth Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞

        })

    except Exception as e:
        logger.error(f"Error in google_callback: {str(e)}")
        return Response(
            {'error': str(e)}, 
            status=status.HTTP_500_INTERNAL_SERVER_ERROR
        )
import requests
import json
import requests
from django.conf import settings
from django.http import JsonResponse
from django.shortcuts import redirect
from .models import User  # User Î™®Îç∏ÏùÑ ÏûÑÌè¨Ìä∏


@api_view(['GET'])
@permission_classes([AllowAny])
def kakao_callback(request):
    try:
        auth_code = request.GET.get('code')
        logger.info(f"Received Kakao auth code: {auth_code}")
        
        # Ïπ¥Ïπ¥Ïò§ ÌÜ†ÌÅ∞ Î∞õÍ∏∞
        token_url = "https://kauth.kakao.com/oauth/token"
        data = {
            "grant_type": "authorization_code",
            "client_id": settings.KAKAO_CLIENT_ID,
            "redirect_uri": settings.KAKAO_REDIRECT_URI,
            "code": auth_code,
        }
        
        token_response = requests.post(token_url, data=data)
        
        if not token_response.ok:
            return Response({
                'error': 'Ïπ¥Ïπ¥Ïò§ ÌÜ†ÌÅ∞ Î∞õÍ∏∞ Ïã§Ìå®',
                'details': token_response.text
            }, status=status.HTTP_400_BAD_REQUEST)
        
        token_data = token_response.json()
        access_token = token_data.get('access_token')
        
        if not access_token:
            return Response({
                'error': 'Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞ ÏóÜÏùå',
                'details': token_data
            }, status=status.HTTP_400_BAD_REQUEST)

        # Ïπ¥Ïπ¥Ïò§ ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Î∞õÍ∏∞
        user_info_url = "https://kapi.kakao.com/v2/user/me"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-type": "application/x-www-form-urlencoded;charset=utf-8"
        }
        
        user_info_response = requests.get(
            user_info_url,
            headers=headers,
            params={
                'property_keys': json.dumps([
                    "kakao_account.email",
                    "kakao_account.profile",
                    "kakao_account.name"
                ])
            }
        )
        
        if not user_info_response.ok:
            return Response({
                'error': 'ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Î∞õÍ∏∞ Ïã§Ìå®',
                'details': user_info_response.text
            }, status=status.HTTP_400_BAD_REQUEST)
        
        user_info = user_info_response.json()
        kakao_account = user_info.get('kakao_account', {})
        email = kakao_account.get('email')
        profile = kakao_account.get('profile', {})
        nickname = profile.get('nickname')
        
        logger.info(f"Kakao user info - email: {email}, nickname: {nickname}")
        
        if not email:
            return Response({
                'error': 'Ïù¥Î©îÏùº Ï†ïÎ≥¥ ÏóÜÏùå',
                'details': 'Ïπ¥Ïπ¥Ïò§ Í≥ÑÏ†ïÏùò Ïù¥Î©îÏùº Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.'
            }, status=status.HTTP_400_BAD_REQUEST)

        # ÏÇ¨Ïö©Ïûê ÏÉùÏÑ± ÎòêÎäî ÏóÖÎç∞Ïù¥Ìä∏
        try:
            user = User.objects.get(email=email)
            logger.info(f"Updated existing user with nickname: {nickname}")
        except User.DoesNotExist:
            unique_username = generate_unique_username(email, nickname)
            user = User.objects.create(
                email=email,
                username=unique_username,
                is_active=True
            )            
            logger.info(f"Created new user with nickname: {nickname}")

        # ÏÜåÏÖú Í≥ÑÏ†ï ÏÉùÏÑ± ÎòêÎäî ÏóÖÎç∞Ïù¥Ìä∏
        social_account, created = SocialAccount.objects.update_or_create(
            email=email,
            provider='kakao',
            defaults={
                'user': user,
                'nickname': nickname
            }
        )
        logger.info(f"Social account updated - email: {email}, nickname: {nickname}")

        if not created and social_account.user != user:
            social_account.user = user
            social_account.save()

        # ÌÜ†ÌÅ∞ ÏÉùÏÑ± ÎòêÎäî Í∞ÄÏ†∏Ïò§Í∏∞
        token, token_created = Token.objects.get_or_create(user=user)
        logger.info(f"KAKAO Token created: {token_created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")

        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token Î∞òÌôò
            'token_created': created,
            'kakao_access_token': access_token,  # Google OAuth Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞

        })


        
    except Exception as e:
        logger.exception("Unexpected error in kakao_callback")
        return Response({
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


from rest_framework.authtoken.models import Token  # Token Î™®Îç∏ Ï∂îÍ∞Ä

@api_view(['GET'])
@permission_classes([AllowAny])
def naver_callback(request):
    try:
        code = request.GET.get('code')
        state = request.GET.get('state')
        logger.info(f"Received Naver auth code: {code}")

        # ÎÑ§Ïù¥Î≤Ñ ÌÜ†ÌÅ∞ Î∞õÍ∏∞
        token_url = "https://nid.naver.com/oauth2.0/token"
        token_params = {
            "grant_type": "authorization_code",
            "client_id": settings.NAVER_CLIENT_ID,
            "client_secret": settings.NAVER_CLIENT_SECRET,
            "code": code,
            "state": state
        }

        token_response = requests.get(token_url, params=token_params)

        if not token_response.ok:
            return Response({
                'error': 'ÎÑ§Ïù¥Î≤Ñ ÌÜ†ÌÅ∞ Î∞õÍ∏∞ Ïã§Ìå®',
                'details': token_response.text
            }, status=status.HTTP_400_BAD_REQUEST)

        token_data = token_response.json()
        access_token = token_data.get('access_token')

        if not access_token:
            return Response({
                'error': 'Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞ ÏóÜÏùå',
                'details': token_data
            }, status=status.HTTP_400_BAD_REQUEST)

        # ÎÑ§Ïù¥Î≤Ñ ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Î∞õÍ∏∞
        user_info_url = "https://openapi.naver.com/v1/nid/me"
        headers = {
            "Authorization": f"Bearer {access_token}",
            "Content-type": "application/x-www-form-urlencoded;charset=utf-8"
        }

        user_info_response = requests.get(user_info_url, headers=headers)

        if not user_info_response.ok:
            return Response({
                'error': 'ÏÇ¨Ïö©Ïûê Ï†ïÎ≥¥ Î∞õÍ∏∞ Ïã§Ìå®',
                'details': user_info_response.text
            }, status=status.HTTP_400_BAD_REQUEST)

        user_info = user_info_response.json()
        response = user_info.get('response', {})
        email = response.get('email')
        nickname = response.get('nickname')
        username = email.split('@')[0]

        if not email:
            return Response({
                'error': 'Ïù¥Î©îÏùº Ï†ïÎ≥¥ ÏóÜÏùå',
                'details': 'ÎÑ§Ïù¥Î≤Ñ Í≥ÑÏ†ïÏùò Ïù¥Î©îÏùº Ï†ïÎ≥¥Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.'
            }, status=status.HTTP_400_BAD_REQUEST)

        # ÏÇ¨Ïö©Ïûê ÏÉùÏÑ± ÎòêÎäî Ï°∞Ìöå
        user, created = User.objects.get_or_create(
            email=email,
            defaults={'username': generate_unique_username(email, username), 'is_active': True}
        )

        # ÏÜåÏÖú Í≥ÑÏ†ï Ï°∞Ìöå Î∞è ÏóÖÎç∞Ïù¥Ìä∏
        social_account, social_created = SocialAccount.objects.update_or_create(
            provider='naver',
            email=email,
            defaults={'user': user, 'nickname': nickname}
        )

        logger.info(f"Social account updated - email: {email}, nickname: {nickname}")

        # ‚úÖ Django REST Framework Token ÏÉùÏÑ±
        token, token_created = Token.objects.get_or_create(user=user)
        logger.info(f"Naver Token created: {token_created}")
        logger.info(f"Token key: {token.key}")
        logger.info(f"Token user: {token.user.username}")

        serializer = UserSerializer(user)
        return Response({
            'user': serializer.data,
            'access_token': token.key,  # Django REST Framework Token Î∞òÌôò
            'token_created': created,
            'naver_access_token': access_token,  # ÎÑ§Ïù¥Î≤Ñ Ïï°ÏÑ∏Ïä§ ÌÜ†ÌÅ∞
        })

    except Exception as e:
        logger.exception("Unexpected error in naver_callback")
        return Response({
            'error': str(e)
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# views.py
import logging
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.contrib.auth import get_user_model

# logger = logging.getLogger(__name__)

# @api_view(['PUT'])
# @permission_classes([IsAuthenticated])
# def update_user_settings(request):
#     # Ï∂îÍ∞Ä Î°úÍπÖ Î∞è ÎîîÎ≤ÑÍπÖ
#     logger.info(f"User authentication status: {request.user.is_authenticated}")
#     logger.info(f"User: {request.user}")
#     logger.info(f"Request headers: {request.headers}")
    
#     try:
#         # Ïù∏Ï¶ù ÏÉÅÌÉú Î™ÖÏãúÏ†Å ÌôïÏù∏
#         if not request.user.is_authenticated:
#             logger.error("Unauthenticated user attempt")
#             return Response({
#                 'status': 'error',
#                 'message': 'Ïù∏Ï¶ùÎêòÏßÄ ÏïäÏùÄ ÏÇ¨Ïö©ÏûêÏûÖÎãàÎã§.'
#             }, status=401)
        
#         # UserProfile Î™®Îç∏Ïù¥ ÏûàÎã§Í≥† Í∞ÄÏ†ï
#         user = request.user
#         user_profile = user.userprofile
        
#         # ÏÑ§Ï†ï ÏóÖÎç∞Ïù¥Ìä∏
#         settings_data = request.data
#         user_profile.language = settings_data.get('language', user_profile.language)
#         user_profile.preferred_model = settings_data.get('preferredModel', user_profile.preferred_model)
#         user_profile.save()
        
#         return Response({
#             'status': 'success',
#             'message': 'ÏÑ§Ï†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏóÖÎç∞Ïù¥Ìä∏ÎêòÏóàÏäµÎãàÎã§.',
#             'settings': {
#                 'language': user_profile.language,
#                 'preferredModel': user_profile.preferred_model
#             }
#         })
    
#     except Exception as e:
#         print("Error:", str(e))  # ÏóêÎü¨ Î°úÍπÖ
#         logger.error(f"Settings update error: {str(e)}")
#         return Response({
#             'status': 'error',
#             'message': f'Ïò§Î•ò Î∞úÏÉù: {str(e)}'
#         }, status=400)
# views.py
# Î∞±ÏóîÎìúÏóêÏÑú ÌÜ†ÌÅ∞ ÌòïÏãù ÌôïÏù∏
@api_view(['PUT'])
@authentication_classes([TokenAuthentication])
@permission_classes([IsAuthenticated])
def update_user_settings(request):
    try:
        # ÌÜ†ÌÅ∞ Î°úÍπÖ Ï∂îÍ∞Ä
        token_header = request.headers.get('Authorization')
        if not token_header or not token_header.startswith('Token '):
            return Response({'error': 'ÏûòÎ™ªÎêú ÌÜ†ÌÅ∞ ÌòïÏãù'}, status=status.HTTP_401_UNAUTHORIZED)
        
        user = request.user
        if not user.is_authenticated:
            return Response({'error': 'Ïù∏Ï¶ùÎêòÏßÄ ÏïäÏùÄ ÏÇ¨Ïö©Ïûê'}, status=status.HTTP_401_UNAUTHORIZED)
        
        settings_data = request.data
        print(f"Received settings data: {settings_data}")  # Îç∞Ïù¥ÌÑ∞ Î°úÍπÖ Ï∂îÍ∞Ä
        
        # UserSettings ÏóÖÎç∞Ïù¥Ìä∏ ÎòêÎäî ÏÉùÏÑ±
        settings, created = UserSettings.objects.get_or_create(user=user)
        
        # ÌïÑÎìú ÏóÖÎç∞Ïù¥Ìä∏
        if 'language' in settings_data:
            settings.language = settings_data['language']
        if 'preferredModel' in settings_data:
            settings.preferred_model = settings_data['preferredModel']
        
        settings.save()
        
        return Response({
            'message': 'Settings updated successfully',
            'settings': {
                'language': settings.language,
                'preferredModel': settings.preferred_model
            }
        })
        
    except Exception as e:
        logger.error(f"Settings update error: {str(e)}")
        return Response(
            {'error': str(e)},
            status=status.HTTP_400_BAD_REQUEST
        )
from rest_framework import status
from rest_framework.decorators import api_view, authentication_classes, permission_classes
from rest_framework.authentication import TokenAuthentication
from rest_framework.permissions import IsAuthenticated
from rest_framework.response import Response
from django.core.exceptions import ObjectDoesNotExist

@api_view(['PUT'])
@authentication_classes([TokenAuthentication])
@permission_classes([IsAuthenticated])
def update_user_settings(request):
    try:
        user = request.user
        settings_data = request.data
        
        # UserProfile ÌôïÏù∏ Î∞è ÏÉùÏÑ±
        try:
            profile = user.userprofile
        except ObjectDoesNotExist:
            profile = UserProfile.objects.create(user=user)
            
        # UserSettings ÌôïÏù∏ Î∞è ÏÉùÏÑ±/ÏóÖÎç∞Ïù¥Ìä∏
        settings, created = UserSettings.objects.get_or_create(
            user=user,
            defaults={
                'language': settings_data.get('language', 'en'),
                'preferred_model': settings_data.get('preferredModel', 'default')
            }
        )
        
        if not created:
            settings.language = settings_data.get('language', settings.language)
            settings.preferred_model = settings_data.get('preferredModel', settings.preferred_model)
            settings.save()
            
        return Response({
            'message': 'Settings updated successfully',
            'settings': {
                'language': settings.language,
                'preferredModel': settings.preferred_model
            }
        })
            
    except Exception as e:
        print(f"Settings update error: {str(e)}")
        return Response(
            {'error': str(e)},
            status=status.HTTP_400_BAD_REQUEST
        )

import logging
import re
import math
import numpy as np
from collections import Counter
from typing import Dict, List, Union, Any
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer
logger = logging.getLogger(__name__)

class SimilarityAnalyzer:
    """
    AI Î™®Îç∏ ÏùëÎãµ Í∞ÑÏùò Ïú†ÏÇ¨ÎèÑÎ•º Î∂ÑÏÑùÌïòÍ≥† ÏùëÎãµ ÌäπÏÑ±ÏùÑ Ï∂îÏ∂úÌïòÎäî ÌÅ¥ÎûòÏä§
    Îã§Íµ≠Ïñ¥ ÏßÄÏõêÏùÑ ÏúÑÌï¥ paraphrase-multilingual-MiniLM-L12-v2 Î™®Îç∏ ÏÇ¨Ïö©
    """
    
    def __init__(self, threshold=0., use_transformer=True):
        """
        Ï¥àÍ∏∞Ìôî
        
        Args:
            threshold (float): Ïú†ÏÇ¨ ÏùëÎãµÏúºÎ°ú Î∂ÑÎ•òÌï† ÏûÑÍ≥ÑÍ∞í (0~1)
            use_transformer (bool): SentenceTransformer Î™®Îç∏ ÏÇ¨Ïö© Ïó¨Î∂Ä
        """
        self.threshold = threshold
        self.use_transformer = use_transformer
        
        # Îã§Íµ≠Ïñ¥ SentenceTransformer Î™®Îç∏ Î°úÎìú
        if use_transformer:
            try:
                self.model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
                logger.info("Îã§Íµ≠Ïñ¥ SentenceTransformer Î™®Îç∏ Î°úÎìú ÏôÑÎ£å")
            except Exception as e:
                logger.error(f"SentenceTransformer Î™®Îç∏ Î°úÎìú Ïã§Ìå®: {str(e)}")
                self.use_transformer = False
                
        # FallbackÏö© TF-IDF Î≤°ÌÑ∞ÎùºÏù¥Ï†Ä
        from sklearn.feature_extraction.text import TfidfVectorizer
        self.vectorizer = TfidfVectorizer(
            min_df=1, 
            analyzer='word',
            ngram_range=(1, 2),
            stop_words=None  # Îã§Íµ≠Ïñ¥ ÏßÄÏõêÏùÑ ÏúÑÌï¥ stop_words Ï†úÍ±∞
        )
    
    def preprocess_text(self, text: str) -> str:
        """
        ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨
        
        Args:
            text (str): Ï†ÑÏ≤òÎ¶¨Ìï† ÌÖçÏä§Ìä∏
            
        Returns:
            str: Ï†ÑÏ≤òÎ¶¨Îêú ÌÖçÏä§Ìä∏
        """
        # ÏÜåÎ¨∏Ïûê Î≥ÄÌôò (ÏòÅÏñ¥ ÌÖçÏä§Ìä∏Îßå Ìï¥Îãπ)
        # Îã§Íµ≠Ïñ¥ ÏßÄÏõêÏùÑ ÏúÑÌï¥ ÏòÅÏñ¥Í∞Ä ÏïÑÎãå Í≤ΩÏö∞ ÏõêÎûò ÏºÄÏù¥Ïä§ Ïú†ÏßÄ
        if text.isascii():
            text = text.lower()
        
        # ÏΩîÎìú Î∏îÎ°ù Ï†úÍ±∞ (Î∂ÑÏÑùÏóêÏÑú Ï†úÏô∏)
        text = re.sub(r'```.*?```', ' CODE_BLOCK ', text, flags=re.DOTALL)
        
        # HTML ÌÉúÍ∑∏ Ï†úÍ±∞
        text = re.sub(r'<.*?>', '', text)
        
        # ÌäπÏàò Î¨∏Ïûê Ï≤òÎ¶¨ (Îã§Íµ≠Ïñ¥ ÏßÄÏõêÏùÑ ÏúÑÌï¥ ÏôÑÏ†Ñ Ï†úÍ±∞ÌïòÏßÄ ÏïäÏùå)
        text = re.sub(r'[^\w\s\u0080-\uFFFF]', ' ', text)
        
        # Ïó¨Îü¨ Í≥µÎ∞±ÏùÑ ÌïòÎÇòÎ°ú ÏπòÌôò
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def calculate_similarity_matrix(self, responses: Dict[str, str]) -> Dict[str, Dict[str, float]]:
        """
        Î™®Îç∏ ÏùëÎãµ Í∞ÑÏùò Ïú†ÏÇ¨ÎèÑ ÌñâÎ†¨ Í≥ÑÏÇ∞
        
        Args:
            responses (dict): Î™®Îç∏ IDÎ•º ÌÇ§Î°ú, ÏùëÎãµ ÌÖçÏä§Ìä∏Î•º Í∞íÏúºÎ°ú ÌïòÎäî ÎîïÏÖîÎÑàÎ¶¨
            
        Returns:
            dict: Î™®Îç∏ Í∞Ñ Ïú†ÏÇ¨ÎèÑ ÌñâÎ†¨
        """
        try:
            model_ids = list(responses.keys())
            
            # ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨
            preprocessed_texts = [self.preprocess_text(responses[model_id]) for model_id in model_ids]
            
            if self.use_transformer and self.model:
                # SentenceTransformerÎ•º ÏÇ¨Ïö©Ìïú ÏûÑÎ≤†Îî© ÏÉùÏÑ±
                try:
                    embeddings = self.model.encode(preprocessed_texts)
                    # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
                    similarity_matrix = cosine_similarity(embeddings)
                except Exception as e:
                    logger.error(f"SentenceTransformer ÏûÑÎ≤†Îî© ÏÉùÏÑ± Ï§ë Ïò§Î•ò: {str(e)}")
                    # Fallback: TF-IDF ÏÇ¨Ïö©
                    tfidf_matrix = self.vectorizer.fit_transform(preprocessed_texts)
                    similarity_matrix = cosine_similarity(tfidf_matrix)
            else:
                # TF-IDF Î≤°ÌÑ∞Ìôî
                tfidf_matrix = self.vectorizer.fit_transform(preprocessed_texts)
                # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
                similarity_matrix = cosine_similarity(tfidf_matrix)
            
            # Í≤∞Í≥ºÎ•º ÎîïÏÖîÎÑàÎ¶¨Î°ú Î≥ÄÌôò
            result = {}
            for i, model1 in enumerate(model_ids):
                result[model1] = {}
                for j, model2 in enumerate(model_ids):
                    result[model1][model2] = float(similarity_matrix[i][j])
            
            return result
            
        except Exception as e:
            logger.error(f"Ïú†ÏÇ¨ÎèÑ ÌñâÎ†¨ Í≥ÑÏÇ∞ Ï§ë Ïò§Î•ò: {str(e)}")
            # Ïò§Î•ò Î∞úÏÉù Ïãú Îπà ÌñâÎ†¨ Î∞òÌôò
            return {model_id: {other_id: 0.0 for other_id in responses} for model_id in responses}
    
      
    def cluster_responses(self, responses):
        """
        ÏùëÎãµÏùÑ Ïú†ÏÇ¨ÎèÑÏóê Îî∞Îùº Íµ∞ÏßëÌôî
        
        Args:
            responses (dict): Î™®Îç∏ IDÎ•º ÌÇ§Î°ú, ÏùëÎãµ ÌÖçÏä§Ìä∏Î•º Í∞íÏúºÎ°ú ÌïòÎäî ÎîïÏÖîÎÑàÎ¶¨
            
        Returns:
            dict: Íµ∞ÏßëÌôî Í≤∞Í≥º
        """
        try:
            model_ids = list(responses.keys())
            if len(model_ids) <= 1:
                return {
                    "similarGroups": [model_ids],
                    "outliers": [],
                    "similarityMatrix": {}
                }
            
            # Ïú†ÏÇ¨ÎèÑ ÌñâÎ†¨ Í≥ÑÏÇ∞
            similarity_matrix = self.calculate_similarity_matrix(responses)
            
            # Í≥ÑÏ∏µÏ†Å ÌÅ¥Îü¨Ïä§ÌÑ∞ÎßÅ ÏàòÌñâ
            clusters = [[model_id] for model_id in model_ids]
            
            merge_happened = True
            while merge_happened and len(clusters) > 1:
                merge_happened = False
                max_similarity = -1
                merge_indices = [-1, -1]
                
                # Í∞ÄÏû• Ïú†ÏÇ¨Ìïú Îëê ÌÅ¥Îü¨Ïä§ÌÑ∞ Ï∞æÍ∏∞
                for i in range(len(clusters)):
                    for j in range(i + 1, len(clusters)):
                        # Îëê ÌÅ¥Îü¨Ïä§ÌÑ∞ Í∞Ñ ÌèâÍ∑† Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
                        cluster_similarity = 0
                        pair_count = 0
                        
                        for model1 in clusters[i]:
                            for model2 in clusters[j]:
                                cluster_similarity += similarity_matrix[model1][model2]
                                pair_count += 1
                        
                        avg_similarity = cluster_similarity / max(1, pair_count)
                        
                        if avg_similarity > max_similarity:
                            max_similarity = avg_similarity
                            merge_indices = [i, j]
                
                # ÏûÑÍ≥ÑÍ∞íÎ≥¥Îã§ Ïú†ÏÇ¨ÎèÑÍ∞Ä ÎÜíÏúºÎ©¥ ÌÅ¥Îü¨Ïä§ÌÑ∞ Î≥ëÌï©
                if max_similarity >= self.threshold:
                    i, j = merge_indices
                    clusters[i].extend(clusters[j])
                    clusters.pop(j)
                    merge_happened = True
            
            # ÌÅ¥Îü¨Ïä§ÌÑ∞ ÌÅ¨Í∏∞Ïóê Îî∞Îùº Ï†ïÎ†¨
            clusters.sort(key=lambda x: -len(x))
            
            # Ï£ºÏöî Í∑∏Î£πÍ≥º Ïù¥ÏÉÅÏπò Íµ¨Î∂Ñ
            main_group = clusters[0] if clusters else []
            outliers = [model for cluster in clusters[1:] for model in cluster]
            
            # ÏùëÎãµ ÌäπÏÑ± Ï∂îÏ∂ú
            response_features = {model_id: self.extract_response_features(responses[model_id]) 
                                for model_id in model_ids}
            
            return {
                "similarGroups": clusters,
                "mainGroup": main_group,
                "outliers": outliers,
                "similarityMatrix": similarity_matrix,
                "responseFeatures": response_features
            }
            
        except Exception as e:
            logger.error(f"ÏùëÎãµ Íµ∞ÏßëÌôî Ï§ë Ïò§Î•ò: {str(e)}")
            # Ïò§Î•ò Î∞úÏÉù Ïãú Î™®Îì† Î™®Îç∏ÏùÑ ÌïòÎÇòÏùò Í∑∏Î£πÏúºÎ°ú Î∞òÌôò
            return {
                "similarGroups": [model_ids],
                "mainGroup": model_ids,
                "outliers": [],
                "similarityMatrix": {},
                "responseFeatures": {}
            }
    
    
    def extract_response_features(self, text: str) -> Dict[str, Union[int, float, bool]]:
        """
        ÏùëÎãµ ÌÖçÏä§Ìä∏ÏóêÏÑú ÌäπÏÑ± Ï∂îÏ∂ú
        
        Args:
            text (str): ÏùëÎãµ ÌÖçÏä§Ìä∏
            
        Returns:
            dict: ÏùëÎãµ ÌäπÏÑ± Ï†ïÎ≥¥
        """
        try:
            # ÏùëÎãµ Í∏∏Ïù¥
            length = len(text)
            
            # ÏΩîÎìú Î∏îÎ°ù Í∞úÏàò
            code_blocks = re.findall(r'```[\s\S]*?```', text)
            code_block_count = len(code_blocks)
            
            # ÎßÅÌÅ¨ Í∞úÏàò
            links = re.findall(r'\[.*?\]\(.*?\)', text) or re.findall(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)
            link_count = len(links)
            
            # Î™©Î°ù Ìï≠Î™© Í∞úÏàò
            list_items = re.findall(r'^[\s]*[-*+] |^[\s]*\d+\. ', text, re.MULTILINE)
            list_item_count = len(list_items)
            
            # Î¨∏Ïû• Î∂ÑÎ¶¨ (Îã§Íµ≠Ïñ¥ ÏßÄÏõê)
            sentences = re.split(r'[.!?„ÄÇÔºÅÔºü]+', text)
            sentences = [s.strip() for s in sentences if s.strip()]
            
            # ÌèâÍ∑† Î¨∏Ïû• Í∏∏Ïù¥
            avg_sentence_length = sum(len(s) for s in sentences) / max(1, len(sentences))
            
            # Ïñ¥Ìúò Îã§ÏñëÏÑ± (Í≥†Ïú† Îã®Ïñ¥ ÎπÑÏú®)
            words = re.findall(r'\b\w+\b', text.lower())
            unique_words = set(words)
            vocabulary_diversity = len(unique_words) / max(1, len(words))
            
            # Ïñ∏Ïñ¥ Í∞êÏßÄ (Ï∂îÍ∞Ä Í∏∞Îä•)
            lang_features = self.detect_language_features(text)
            
            features = {
                "length": length,
                "codeBlockCount": code_block_count,
                "linkCount": link_count,
                "listItemCount": list_item_count,
                "sentenceCount": len(sentences),
                "avgSentenceLength": avg_sentence_length,
                "vocabularyDiversity": vocabulary_diversity,
                "hasCode": code_block_count > 0
            }
            
            # Ïñ∏Ïñ¥ ÌäπÏÑ± Ï∂îÍ∞Ä
            features.update(lang_features)
            
            return features
            
        except Exception as e:
            logger.error(f"ÏùëÎãµ ÌäπÏÑ± Ï∂îÏ∂ú Ï§ë Ïò§Î•ò: {str(e)}")
            # Ïò§Î•ò Î∞úÏÉù Ïãú Í∏∞Î≥∏Í∞í Î∞òÌôò
            return {
                "length": len(text),
                "codeBlockCount": 0,
                "linkCount": 0,
                "listItemCount": 0,
                "sentenceCount": 1,
                "avgSentenceLength": len(text),
                "vocabularyDiversity": 0,
                "hasCode": False,
                "detectedLang": "unknown"
            }
    
    def detect_language_features(self, text: str) -> Dict[str, Any]:
        """
        ÌÖçÏä§Ìä∏Ïùò Ïñ∏Ïñ¥ ÌäπÏÑ± Í∞êÏßÄ
        
        Args:
            text (str): Î∂ÑÏÑùÌï† ÌÖçÏä§Ìä∏
            
        Returns:
            dict: Ïñ∏Ïñ¥ ÌäπÏÑ± Ï†ïÎ≥¥
        """
        try:
            # Ïñ∏Ïñ¥ ÌäπÏÑ± Í∞êÏßÄÎ•º ÏúÑÌïú Í∞ÑÎã®Ìïú Ìú¥Î¶¨Ïä§Ìã±
            # Ïã§Ï†ú ÌîÑÎ°úÎçïÏÖòÏóêÏÑúÎäî langdetect Îì±Ïùò ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÇ¨Ïö© Í∂åÏû•
            
            # ÌïúÍµ≠Ïñ¥ ÌäπÏÑ± (ÌïúÍ∏Ä ÎπÑÏú®)
            korean_chars = len(re.findall(r'[„Ñ±-„Öé„Öè-„Ö£Í∞Ä-Ìû£]', text))
            
            # ÏòÅÏñ¥ ÌäπÏÑ± (ÏòÅÎ¨∏ ÎπÑÏú®)
            english_chars = len(re.findall(r'[a-zA-Z]', text))
            
            # ÏùºÎ≥∏Ïñ¥ ÌäπÏÑ± (ÏùºÎ≥∏Ïñ¥ Î¨∏Ïûê ÎπÑÏú®)
            japanese_chars = len(re.findall(r'[„ÅÅ-„Çì„Ç°-„É≥‰∏Ä-ÈæØ]', text))
            
            # Ï§ëÍµ≠Ïñ¥ ÌäπÏÑ± (Ï§ëÍµ≠Ïñ¥ Î¨∏Ïûê ÎπÑÏú®)
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
            
            # Í∏∞ÌÉÄ Î¨∏Ïûê (Ïà´Ïûê, ÌäπÏàòÎ¨∏Ïûê Ï†úÏô∏)
            total_chars = len(re.findall(r'[^\d\s\W]', text))
            
            # ÎπÑÏú® Í≥ÑÏÇ∞
            total = max(1, total_chars)
            korean_ratio = korean_chars / total
            english_ratio = english_chars / total
            japanese_ratio = japanese_chars / total
            chinese_ratio = chinese_chars / total
            
            # Ï£ºÏöî Ïñ∏Ïñ¥ Í≤∞Ï†ï
            lang_ratios = {
                "ko": korean_ratio,
                "en": english_ratio,
                "ja": japanese_ratio,
                "zh": chinese_ratio,
                "other": 1.0 - (korean_ratio + english_ratio + japanese_ratio + chinese_ratio)
            }
            
            detected_lang = max(lang_ratios.items(), key=lambda x: x[1])[0]
            
            return {
                "detectedLang": detected_lang,
                "langRatios": lang_ratios
            }
            
        except Exception as e:
            logger.error(f"Ïñ∏Ïñ¥ ÌäπÏÑ± Í∞êÏßÄ Ï§ë Ïò§Î•ò: {str(e)}")
            return {
                "detectedLang": "unknown",
                "langRatios": {"unknown": 1.0}
            }
    
    def compare_responses(self, response1: str, response2: str) -> Dict[str, Any]:
        """
        Îëê ÏùëÎãµ Í∞ÑÏùò Ïú†ÏÇ¨ÎèÑÏôÄ Ï∞®Ïù¥Ï†ê Î∂ÑÏÑù
        
        Args:
            response1 (str): Ï≤´ Î≤àÏß∏ ÏùëÎãµ
            response2 (str): Îëê Î≤àÏß∏ ÏùëÎãµ
            
        Returns:
            dict: Ïú†ÏÇ¨ÎèÑ Î∞è Ï∞®Ïù¥Ï†ê Î∂ÑÏÑù Í≤∞Í≥º
        """
        try:
            # ÌÖçÏä§Ìä∏ Ï†ÑÏ≤òÎ¶¨
            text1 = self.preprocess_text(response1)
            text2 = self.preprocess_text(response2)
            
            # ÏûÑÎ≤†Îî© ÏÉùÏÑ± Î∞è Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
            if self.use_transformer and self.model:
                embeddings = self.model.encode([text1, text2])
                similarity = float(cosine_similarity([embeddings[0]], [embeddings[1]])[0][0])
            else:
                # TF-IDFÎ•º ÏÇ¨Ïö©Ìïú Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
                tfidf_matrix = self.vectorizer.fit_transform([text1, text2])
                similarity = float(cosine_similarity(tfidf_matrix)[0][1])
            
            # ÏùëÎãµ ÌäπÏÑ± ÎπÑÍµê
            features1 = self.extract_response_features(response1)
            features2 = self.extract_response_features(response2)
            
            # ÌäπÏÑ± Ï∞®Ïù¥ Í≥ÑÏÇ∞
            feature_diffs = {}
            for key in set(features1.keys()) & set(features2.keys()):
                if isinstance(features1[key], (int, float)) and isinstance(features2[key], (int, float)):
                    feature_diffs[key] = features2[key] - features1[key]
            
            # Ï£ºÏöî Ï∞®Ïù¥Ï†ê Í≥†Ïú† Îã®Ïñ¥ Î∂ÑÏÑù
            words1 = re.findall(r'\b\w+\b', text1.lower())
            words2 = re.findall(r'\b\w+\b', text2.lower())
            
            counter1 = Counter(words1)
            counter2 = Counter(words2)
            
            unique_to_1 = [word for word, count in counter1.items() if word not in counter2]
            unique_to_2 = [word for word, count in counter2.items() if word not in counter1]
            
            # Í∞ÄÏû• ÎπàÎèÑÍ∞Ä ÎÜíÏùÄ Í≥†Ïú† Îã®Ïñ¥ (ÏµúÎåÄ 10Í∞ú)
            top_unique_to_1 = sorted(
                [(word, counter1[word]) for word in unique_to_1], 
                key=lambda x: x[1], 
                reverse=True
            )[:10]
            
            top_unique_to_2 = sorted(
                [(word, counter2[word]) for word in unique_to_2], 
                key=lambda x: x[1], 
                reverse=True
            )[:10]
            
            return {
                "similarity": similarity,
                "isSimilar": similarity >= self.threshold,
                "features1": features1,
                "features2": features2,
                "featureDiffs": feature_diffs,
                "uniqueWordsTo1": top_unique_to_1,
                "uniqueWordsTo2": top_unique_to_2
            }
            
        except Exception as e:
            logger.error(f"ÏùëÎãµ ÎπÑÍµê Ï§ë Ïò§Î•ò: {str(e)}")
            return {
                "similarity": 0.0,
                "isSimilar": False,
                "error": str(e)
            }
        
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
import logging
import json
import openai
import anthropic
from groq import Groq
from django.conf import settings
import time


logger = logging.getLogger(__name__)

class TextSimplificationView(APIView):
    """
    ÌÖçÏä§Ìä∏Î•º Ïâ¨Ïö¥ ÌëúÌòÑÏúºÎ°ú Î≥ÄÌôòÌïòÎäî API Î∑∞
    ÌäπÏ†ï ÎåÄÏÉÅ(Ïñ¥Î¶∞Ïù¥, Í≥†Î†πÏûê, Ïô∏Íµ≠Ïù∏ ÌïôÏäµÏûê Îì±)Ïóê ÎßûÏ∂∞ Î≥ÄÌôò
    """
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            logger.info("Ïâ¨Ïö¥ ÌëúÌòÑ Î≥ÄÌôò ÏöîÏ≤≠ Î∞õÏùå")
            
            data = request.data
            original_text = data.get('message')
            target_audience = data.get('targetAudience', 'general')
            language = data.get('language', 'ko')
            
            if not original_text:
                return Response({'error': 'Î≥ÄÌôòÌï† ÌÖçÏä§Ìä∏Í∞Ä ÏóÜÏäµÎãàÎã§.'}, 
                               status=status.HTTP_400_BAD_REQUEST)
            
            # ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî ÏàòÌñâ
            simplifier = TextSimplifier(
                api_key=settings.OPENAI_API_KEY,
                model="gpt-4-turbo",  # ÎòêÎäî ÏÑ†Ìò∏ÌïòÎäî GPT Î™®Îç∏
                api_type="openai"
            )
            
            result = simplifier.simplify_text(
                original_text=original_text,
                target_audience=target_audience,
                language=language
            )
            
            return Response(result)
            
        except Exception as e:
            logger.error(f"ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}", exc_info=True)
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class TextSimplifier:
    """
    ÌÖçÏä§Ìä∏Î•º Ïâ¨Ïö¥ ÌëúÌòÑÏúºÎ°ú Î≥ÄÌôòÌïòÎäî ÌÅ¥ÎûòÏä§
    Îã§ÏñëÌïú AI Î™®Îç∏ÏùÑ ÌôúÏö©ÌïòÏó¨ ÎåÄÏÉÅÏûêÎ≥Ñ ÎßûÏ∂§Ìòï Îã®ÏàúÌôî ÏàòÌñâ
    """
    def __init__(self, api_key, model, api_type):
        self.model = model
        self.api_type = api_type
        self.api_key = api_key
        
        if api_type == 'openai':
            openai.api_key = api_key
        elif api_type == 'anthropic':
            self.client = anthropic.Anthropic(api_key=api_key)
        elif api_type == 'groq':
            self.client = Groq(api_key=api_key)
    
    def simplify_text(self, original_text, target_audience, language='ko'):
        """
        ÌÖçÏä§Ìä∏Î•º Îã®ÏàúÌôîÌïòÏó¨ Î∞òÌôò
        
        Args:
            original_text (str): ÏõêÎ≥∏ ÌÖçÏä§Ìä∏
            target_audience (str): ÎåÄÏÉÅÏûê Ïú†Ìòï (general, child, elderly, foreigner)
            language (str): Ïñ∏Ïñ¥ (Í∏∞Î≥∏Í∞í: ÌïúÍµ≠Ïñ¥)
            
        Returns:
            dict: Îã®ÏàúÌôî Í≤∞Í≥º
        """
        try:
            logger.info(f"ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî ÏãúÏûë: ÎåÄÏÉÅ={target_audience}, Ïñ∏Ïñ¥={language}")
            
            # ÎåÄÏÉÅÏûêÏóê ÎßûÎäî ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
            prompt = self._get_simplification_prompt(original_text, target_audience, language)
            
            # AI Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî
            simplified_text = self._generate_simplified_text(prompt)
            
            # Í≤∞Í≥º Î∞òÌôò
            result = {
                'original_text': original_text,
                'simplified_text': simplified_text,
                'target_audience': target_audience,
                'language': language,
                'timestamp': time.time()
            }
            
            logger.info("ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî ÏôÑÎ£å")
            return result
            
        except Exception as e:
            logger.error(f"ÌÖçÏä§Ìä∏ Îã®ÏàúÌôî Ïò§Î•ò: {str(e)}", exc_info=True)
            raise
    
    def _get_simplification_prompt(self, original_text, target_audience, language):
        """ÎåÄÏÉÅÏûê ÎßûÏ∂§Ìòï Îã®ÏàúÌôî ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±"""
        
        base_prompt = f"""
Îã§Ïùå ÌÖçÏä§Ìä∏Î•º Îçî Ïâ¨Ïö¥ ÌëúÌòÑÏúºÎ°ú Î≥ÄÌôòÌï¥Ï£ºÏÑ∏Ïöî:

{original_text}

ÎåÄÏÉÅÏûê: {target_audience}
Ïñ∏Ïñ¥: {language}
"""
        
        if target_audience == 'child':
            base_prompt += """
[Ïñ¥Î¶∞Ïù¥Ïö© Î≥ÄÌôò ÏßÄÏπ®]
1. 7-12ÏÑ∏ Ïñ¥Î¶∞Ïù¥Í∞Ä Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî Îã®Ïñ¥ÏôÄ ÌëúÌòÑÏúºÎ°ú Î≥ÄÌôòÌïòÏÑ∏Ïöî.
2. ÏßßÍ≥† Í∞ÑÎã®Ìïú Î¨∏Ïû•ÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
3. Ï∂îÏÉÅÏ†ÅÏù∏ Í∞úÎÖêÏùÄ Íµ¨Ï≤¥Ï†ÅÏù∏ ÏòàÏãúÏôÄ Ìï®Íªò ÏÑ§Î™ÖÌïòÏÑ∏Ïöî.
4. Ïû¨ÎØ∏ÏûàÍ≥† Ìù•ÎØ∏Î°úÏö¥ ÌëúÌòÑÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
5. Ïñ¥Î†§Ïö¥ Îã®Ïñ¥Îäî Í∞ÑÎã®Ìïú ÎèôÏùòÏñ¥Î°ú ÎåÄÏ≤¥ÌïòÏÑ∏Ïöî.
6. ÌïÑÏöîÌïú Í≤ΩÏö∞ ÎπÑÏú†ÏôÄ ÏòàÏãúÎ•º ÌôúÏö©ÌïòÏÑ∏Ïöî.
7. Î¨∏Ïû• ÏÇ¨Ïù¥Ïóê Ï†ÅÏ†àÌïú Ï§ÑÎ∞îÍøàÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.
"""
        elif target_audience == 'elderly':
            base_prompt += """
[Í≥†Î†πÏûêÏö© Î≥ÄÌôò ÏßÄÏπ®]
1. Î™ÖÌôïÌïòÍ≥† ÏßÅÏ†ëÏ†ÅÏù∏ ÌëúÌòÑÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
2. Ïô∏ÎûòÏñ¥ÎÇò ÏòÅÏñ¥ ÌëúÌòÑÏùÄ Í∞ÄÎä•Ìïú ÌïúÍµ≠Ïñ¥Î°ú ÎåÄÏ≤¥ÌïòÏÑ∏Ïöî.
3. Î≥µÏû°Ìïú Î¨∏Ïû• Íµ¨Ï°∞Î•º ÌîºÌïòÍ≥† Í∞ÑÍ≤∞ÌïòÍ≤å ÏûëÏÑ±ÌïòÏÑ∏Ïöî.
4. Ï†ÑÎ¨∏ Ïö©Ïñ¥Îäî ÏùºÏÉÅÏ†ÅÏù∏ Ïö©Ïñ¥Î°ú ÏÑ§Î™ÖÌïòÏÑ∏Ïöî.
5. ÏπúÏàôÌïú ÎπÑÏú†ÏôÄ ÏòàÏãúÎ•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
6. Ï§ëÏöîÌïú Ï†ïÎ≥¥Îäî Î∞òÎ≥µÌï¥ÏÑú Í∞ïÏ°∞ÌïòÏÑ∏Ïöî.
7. Î¨∏Ïû• ÏÇ¨Ïù¥Ïóê Ï†ÅÏ†àÌïú Ï§ÑÎ∞îÍøàÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.
"""
        elif target_audience == 'foreigner':
            base_prompt += """
[Ïô∏Íµ≠Ïù∏ ÌïôÏäµÏûêÏö© Î≥ÄÌôò ÏßÄÏπ®]
1. ÌïúÍµ≠Ïñ¥ ÌïôÏäµÏûê(Ï¥àÍ∏â~Ï§ëÍ∏â)Í∞Ä Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî Í∏∞Î≥∏ Ïñ¥ÌúòÎ•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
2. Í¥ÄÏö©Ïñ¥, ÏÜçÎã¥, ÏùÄÏú†Ï†Å ÌëúÌòÑÏùÑ ÌîºÌïòÏÑ∏Ïöî.
3. ÌïúÏûêÏñ¥Îäî Í∞ÄÎä•Ìïú ÏàúÏö∞Î¶¨ÎßêÎ°ú ÎåÄÏ≤¥ÌïòÏÑ∏Ïöî.
4. Î¨∏Î≤ïÏ†ÅÏúºÎ°ú Îã®ÏàúÌïú Î¨∏Ïû• Íµ¨Ï°∞Î•º ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
5. Î≥µÏû°Ìïú Ïó∞Í≤∞Ïñ¥ÎØ∏ÎÇò Ï°∞ÏÇ¨ ÏÇ¨Ïö©ÏùÑ ÏµúÏÜåÌôîÌïòÏÑ∏Ïöî.
6. Ï§ëÏöîÌïú Í∞úÎÖêÏùÄ Í¥ÑÌò∏ ÏïàÏóê ÏòÅÏñ¥Î°ú Î≥ëÍ∏∞ÌïòÏÑ∏Ïöî.
7. Î¨∏Ïû• ÏÇ¨Ïù¥Ïóê Ï†ÅÏ†àÌïú Ï§ÑÎ∞îÍøàÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.
"""
        else:  # general
            base_prompt += """
[ÏùºÎ∞òÏù∏Ïö© Î≥ÄÌôò ÏßÄÏπ®]
1. Î≥¥Ìé∏Ï†ÅÏù∏ ÍµêÏñë ÏàòÏ§ÄÏùò Ïñ¥ÌúòÏôÄ ÌëúÌòÑÏùÑ ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
2. Î∂àÌïÑÏöîÌïòÍ≤å Î≥µÏû°Ìïú Î¨∏Ïû• Íµ¨Ï°∞Î•º Îã®ÏàúÌôîÌïòÏÑ∏Ïöî.
3. Ï†ÑÎ¨∏ Ïö©Ïñ¥Îäî Í∞ÑÎã®Ìïú ÏÑ§Î™ÖÍ≥º Ìï®Íªò ÏÇ¨Ïö©ÌïòÏÑ∏Ïöî.
4. ÎÖºÎ¶¨Ï†Å ÌùêÎ¶ÑÏùÑ Ïú†ÏßÄÌïòÎ©∞ Î™ÖÌôïÌïòÍ≤å ÌëúÌòÑÌïòÏÑ∏Ïöî.
5. ÎπÑÏú†ÏôÄ ÏòàÏãúÎ•º Ï†ÅÏ†àÌûà ÌôúÏö©ÌïòÏÑ∏Ïöî.
6. Ï§ëÏöîÌïú ÎÇ¥Ïö©ÏùÑ Í∞ïÏ°∞ÌïòÍ≥† ÌïµÏã¨ÏùÑ Î®ºÏ†Ä Ï†úÏãúÌïòÏÑ∏Ïöî.
7. Î¨∏Ïû• ÏÇ¨Ïù¥Ïóê Ï†ÅÏ†àÌïú Ï§ÑÎ∞îÍøàÏùÑ Ï∂îÍ∞ÄÌïòÏÑ∏Ïöî.
"""
            
        return base_prompt
    
    def _generate_simplified_text(self, prompt):
        """AI Î™®Îç∏ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Îã®ÏàúÌôîÎêú ÌÖçÏä§Ìä∏ ÏÉùÏÑ±"""
        try:
            # API Ïú†ÌòïÏóê Îî∞Î•∏ Î∂ÑÍ∏∞
            if self.api_type == 'openai':
                response = openai.ChatCompletion.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ÎãπÏã†ÏùÄ Î≥µÏû°Ìïú ÌÖçÏä§Ìä∏Î•º Îçî ÏâΩÍ≤å Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî ÌòïÌÉúÎ°ú Î≥ÄÌôòÌï¥Ï£ºÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=2000
                )
                simplified_text = response['choices'][0]['message']['content']
                
            elif self.api_type == 'anthropic':
                message = self.client.messages.create(
                    model=self.model,
                    max_tokens=2000,
                    temperature=0.5,
                    system="ÎãπÏã†ÏùÄ Î≥µÏû°Ìïú ÌÖçÏä§Ìä∏Î•º Îçî ÏâΩÍ≤å Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî ÌòïÌÉúÎ°ú Î≥ÄÌôòÌï¥Ï£ºÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§.",
                    messages=[{
                        "role": "user", 
                        "content": prompt
                    }]
                )
                simplified_text = message.content[0].text
                
            elif self.api_type == 'groq':
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ÎãπÏã†ÏùÄ Î≥µÏû°Ìïú ÌÖçÏä§Ìä∏Î•º Îçî ÏâΩÍ≤å Ïù¥Ìï¥Ìï† Ïàò ÏûàÎäî ÌòïÌÉúÎ°ú Î≥ÄÌôòÌï¥Ï£ºÎäî Ï†ÑÎ¨∏Í∞ÄÏûÖÎãàÎã§."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.5,
                    max_tokens=2000
                )
                simplified_text = response.choices[0].message.content
            
            return simplified_text
            
        except Exception as e:
            logger.error(f"ÌÖçÏä§Ìä∏ ÏÉùÏÑ± Ïò§Î•ò: {str(e)}", exc_info=True)
            raise




    
import logging
import json
import os
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.permissions import AllowAny
from PIL import Image, ImageFilter, ImageEnhance
import pytesseract
from .models import OCRResult
from .serializers import OCRResultSerializer

import PyPDF2
import tempfile
from pdf2image import convert_from_path
import re

logger = logging.getLogger(__name__)

# OllamaClientÏôÄ GPTTranslator ÌÅ¥ÎûòÏä§ Í∞ÄÏ†∏Ïò§Í∏∞
from .ollama_client import OllamaClient
from .gpt_translator import GPTTranslator 

@method_decorator(csrf_exempt, name='dispatch')
class ProcessFileView(APIView):
    permission_classes = [AllowAny]
    
    def post(self, request):
        try:
            logger.info("ProcessFileView ÏöîÏ≤≠ ÏàòÏã†: %s %s", request.method, request.path)
            
            # ÏöîÏ≤≠ Îç∞Ïù¥ÌÑ∞ ÌôïÏù∏
            if 'file' not in request.FILES:
                logger.error("ÌååÏùºÏù¥ Ï†úÍ≥µÎêòÏßÄ ÏïäÏùå")
                return Response({'error': 'ÌååÏùºÏù¥ Ï†úÍ≥µÎêòÏßÄ ÏïäÏïòÏäµÎãàÎã§'}, status=status.HTTP_400_BAD_REQUEST)
            
            file_obj = request.FILES['file']
            file_name = file_obj.name.lower()
            logger.info("ÌååÏùº ÏóÖÎ°úÎìú: %s, ÌÅ¨Í∏∞: %s bytes", file_name, file_obj.size)
            
            # Ollama ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî
            ollama_base_url = os.environ.get('OLLAMA_API_URL', 'http://localhost:11434')
            ollama_client = OllamaClient(base_url=ollama_base_url)
            
            # GPT Î≤àÏó≠Í∏∞ Ï¥àÍ∏∞Ìôî
            gpt_translator = GPTTranslator()
            
            # Î≤àÏó≠ ÏòµÏÖò ÌôïÏù∏ (Í∏∞Î≥∏Í∞í: True)
            enable_translation = request.data.get('enable_translation', 'true').lower() == 'true'
            
            # ÌååÏùº Ïú†Ìòï ÌôïÏù∏
            if file_name.endswith(('.pdf')):
                file_type = 'pdf'
                
                # PDF ÌéòÏù¥ÏßÄ Î≤îÏúÑ ÌôïÏù∏
                start_page = int(request.data.get('start_page', 1))
                end_page = int(request.data.get('end_page', 0))  # 0ÏùÄ Ï†ÑÏ≤¥ ÌéòÏù¥ÏßÄÎ•º ÏùòÎØ∏
                
                logger.info("PDF Ï≤òÎ¶¨ Î≤îÏúÑ: %s ~ %s ÌéòÏù¥ÏßÄ", start_page, end_page if end_page > 0 else "ÎÅù")
                
            elif file_name.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')):
                file_type = 'image'
            else:
                logger.error("ÏßÄÏõêÎêòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãù: %s", file_name)
                return Response({'error': 'ÏßÄÏõêÎêòÏßÄ ÏïäÎäî ÌååÏùº ÌòïÏãùÏûÖÎãàÎã§. Ïù¥ÎØ∏ÏßÄÎÇò PDF ÌååÏùºÏùÑ ÏóÖÎ°úÎìúÌï¥Ï£ºÏÑ∏Ïöî.'},
                              status=status.HTTP_400_BAD_REQUEST)
            
            # OCR Í≤∞Í≥º Í∞ùÏ≤¥ ÏÉùÏÑ±
            ocr_result = OCRResult.objects.create(file=file_obj, file_type=file_type)
            logger.info("OCRResult Í∞ùÏ≤¥ ÏÉùÏÑ±: %s", ocr_result.id)
            
            # OCR Ï≤òÎ¶¨
            try:
                ocr_text = ""
                page_texts = []  # ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ Ï†ÄÏû•
                
                if file_type == 'image':
                    # Ïù¥ÎØ∏ÏßÄ ÌååÏùº Ï≤òÎ¶¨ - Í∞úÏÑ†Îêú OCR Ï†ÅÏö©
                    img = Image.open(ocr_result.file.path)
                    # Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥ Î°úÍπÖ
                    logger.info(f"Ïù¥ÎØ∏ÏßÄ Ï†ïÎ≥¥: ÌÅ¨Í∏∞={img.size}, Î™®Îìú={img.mode}, Ìè¨Îß∑={img.format}")
                    
                    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ Î∞è OCR ÏàòÌñâ - OllamaClient Î©îÏÑúÎìú ÏÇ¨Ïö©
                    preprocessed_img = ollama_client.preprocess_image_for_ocr(img)
                    ocr_text = ollama_client.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    page_texts.append({"page": 1, "text": ocr_text})
                    logger.info("Ïù¥ÎØ∏ÏßÄ OCR Ï≤òÎ¶¨ ÏôÑÎ£å, Ï∂îÏ∂ú ÌÖçÏä§Ìä∏ Í∏∏Ïù¥: %s", len(ocr_text))
                    logger.info("Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏ ÏÉòÌîå: %s", ocr_text[:200] if ocr_text else "ÌÖçÏä§Ìä∏ ÏóÜÏùå")
                
                elif file_type == 'pdf':
                    # PDF Ï≤òÎ¶¨ - ÏßÅÏ†ë Ï∂îÏ∂ú ÌõÑ ÌïÑÏöîÏãú OCR
                    logger.info("PDF Ï≤òÎ¶¨ ÏãúÏûë: %s", ocr_result.file.path)
                    
                    # ÏßÅÏ†ë ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú ÏãúÎèÑ (ÌéòÏù¥ÏßÄÎ≥Ñ)
                    direct_extract_success = False
                    try:
                        all_page_texts = self.extract_text_from_pdf_by_pages(ocr_result.file.path)
                        
                        # ÌéòÏù¥ÏßÄ Î≤îÏúÑ Ï≤òÎ¶¨
                        if start_page > 1 or (end_page > 0 and end_page < len(all_page_texts)):
                            if start_page <= len(all_page_texts):
                                if end_page > 0 and end_page >= start_page:
                                    page_texts = all_page_texts[start_page-1:end_page]
                                else:
                                    page_texts = all_page_texts[start_page-1:]
                            else:
                                page_texts = []
                        else:
                            page_texts = all_page_texts
                        
                        combined_text = "\n".join([page["text"] for page in page_texts])
                        
                        # Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏ Í∏∏Ïù¥Í∞Ä Ï∂©Î∂ÑÌïúÏßÄ ÌôïÏù∏ (Îçî ÏóÑÍ≤©Ìïú Ï°∞Í±¥)
                        if combined_text.strip() and len(combined_text.strip()) >= 50:
                            meaningful_chars = sum(1 for c in combined_text if c.isalnum())
                            if meaningful_chars > 30:  # ÏùòÎØ∏ÏûàÎäî Í∏ÄÏûêÍ∞Ä 30Ïûê Ïù¥ÏÉÅÏù¥Î©¥ ÏÑ±Í≥µÏúºÎ°ú Í∞ÑÏ£º
                                ocr_text = combined_text
                                direct_extract_success = True
                                logger.info("PDF ÏßÅÏ†ë ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú ÏÑ±Í≥µ, Ï¥ù %s ÌéòÏù¥ÏßÄ, ÌÖçÏä§Ìä∏ Í∏∏Ïù¥: %s", 
                                          len(page_texts), len(ocr_text))
                                logger.info("Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏ ÏÉòÌîå: %s", ocr_text[:200] if ocr_text else "ÌÖçÏä§Ìä∏ ÏóÜÏùå")
                    except Exception as e:
                        logger.error(f"PDF ÏßÅÏ†ë ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú Ïã§Ìå®: {str(e)}")
                    
                    # ÏßÅÏ†ë ÌÖçÏä§Ìä∏ Ï∂îÏ∂úÏù¥ Ïã§Ìå®Ìïú Í≤ΩÏö∞, OCR ÏãúÎèÑ
                    if not direct_extract_success:
                        logger.info("PDF OCR Ï≤òÎ¶¨ ÏãúÏûë (ÏßÅÏ†ë Ï∂îÏ∂ú Ïã§Ìå® ÎòêÎäî ÌÖçÏä§Ìä∏ Î∂àÏ∂©Î∂Ñ)")
                        
                        # ÌéòÏù¥ÏßÄ Î≤îÏúÑ ÏÑ§Ï†ïÏúºÎ°ú OCR
                        all_page_texts = self.ocr_pdf_by_pages(ocr_result.file.path, ollama_client, start_page, end_page)
                        
                        # ÌéòÏù¥ÏßÄ Î≤îÏúÑ Ï≤òÎ¶¨ - ocr_pdf_by_pagesÏóêÏÑú Ï≤òÎ¶¨ÌñàÏúºÎØÄÎ°ú Ï†ÑÏ≤¥ ÏÇ¨Ïö©
                        page_texts = all_page_texts
                        
                        ocr_text = "\n".join([page["text"] for page in page_texts])
                        logger.info("PDF OCR Ï≤òÎ¶¨ ÏôÑÎ£å, Ï¥ù %s ÌéòÏù¥ÏßÄ, ÌÖçÏä§Ìä∏ Í∏∏Ïù¥: %s", 
                                  len(page_texts), len(ocr_text))
                        logger.info("Ï∂îÏ∂úÎêú ÌÖçÏä§Ìä∏ ÏÉòÌîå: %s", ocr_text[:200] if ocr_text else "ÌÖçÏä§Ìä∏ ÏóÜÏùå")
                
                # ÌÖçÏä§Ìä∏ Ï†ïÌôî - Í∞úÏÑ†Îêú Ìï®Ïàò ÏÇ¨Ïö©
                ocr_result.ocr_text = self.clean_text(ocr_text)
                
                # PDF ÌååÏùºÏùÄ Ìï≠ÏÉÅ ÌÖçÏä§Ìä∏ Í¥ÄÎ†® ÏûàÏùåÏúºÎ°ú ÏÑ§Ï†ï
                if file_type == 'pdf':
                    text_relevant = True
                
                # Î∂ÑÏÑù Ïú†Ìòï ÌôïÏù∏ (Í∏∞Î≥∏Í∞í: both)
                analysis_type = request.data.get('analysis_type', 'both')
                logger.info("Î∂ÑÏÑù Ïú†Ìòï: %s", analysis_type)
                
                # Í≤∞Í≥º Î≥ÄÏàò Ï¥àÍ∏∞Ìôî
                image_analysis = ""
                text_analysis = ""
                combined_analysis = ""
                
                # Î≤àÏó≠ Í≤∞Í≥º Î≥ÄÏàò Ï¥àÍ∏∞Ìôî
                translated_analysis = ""
                translation_success = False
                translation_error = ""
                
                # ÌéòÏù¥ÏßÄ Î∂ÑÌï† Î∂ÑÏÑù Ïó¨Î∂Ä ÌôïÏù∏
                analyze_by_page = request.data.get('analyze_by_page', 'true').lower() == 'true'
                
                # ÏÑ†ÌÉùÎêú Î∂ÑÏÑù Ïú†ÌòïÏóê Îî∞Îùº Ï≤òÎ¶¨
                if analysis_type in ['ollama', 'both']:
                    # Ïù¥ÎØ∏ÏßÄ ÌååÏùºÏù∏ Í≤ΩÏö∞
                    if file_type == 'image':
                        # ÏÇ¨Ïö©Ïûê Ï†ïÏùò ÌîÑÎ°¨ÌîÑÌä∏ ÏÑ§Ï†ï (ÏöîÏïΩÎêú Í∞ÑÍ≤∞Ìïú ÏÑ§Î™ÖÏùÑ ÏúÑÌï¥)
                        custom_prompt = f"""Ïù¥ÎØ∏ÏßÄÎ•º Í∞ùÍ¥ÄÏ†ÅÏúºÎ°ú Í¥ÄÏ∞∞ÌïòÍ≥† Îã§Ïùå ÏßÄÏπ®Ïóê Îî∞Îùº ÏùëÎãµÌïòÏÑ∏Ïöî:

ÌïÑÏàò Ìè¨Ìï® ÏÇ¨Ìï≠:
- Ïù¥ÎØ∏ÏßÄÏóê Ïã§Ï†úÎ°ú Î≥¥Ïù¥Îäî ÏÇ¨Îûå, ÎèôÎ¨º, Î¨ºÏ≤¥Îßå Ïñ∏Í∏â (ÏóÜÏúºÎ©¥ Ïñ∏Í∏âÌïòÏßÄ ÏïäÏùå)
- ÎßåÏïΩ ÎèôÎ¨ºÏù¥ÎùºÎ©¥, Ïñ¥Îñ§ Ï¢ÖÏùò ÎèôÎ¨ºÏù∏ÏßÄÎèÑ Ï∂úÎ†•
- ÌôïÏã§Ìûà Î≥¥Ïù¥Îäî ÏÉâÏÉÅÎßå Ïñ∏Í∏â (Î∞∞Í≤ΩÏÉâ, Ïò∑ ÏÉâÏÉÅ Îì±)
- Î™ÖÌôïÌûà Î≥¥Ïù¥Îäî ÏûêÏÑ∏ÎÇò ÏúÑÏπò Í¥ÄÍ≥Ñ (Ï†ïÎ©¥, Ï∏°Î©¥ Îì±)

Ï†àÎåÄ Ìè¨Ìï®ÌïòÏßÄ Îßê Í≤É:
- Ï∂îÏ∏°Ïù¥ÎÇò Ìï¥ÏÑù ("~Î°ú Î≥¥ÏûÖÎãàÎã§", "~Í∞ôÏäµÎãàÎã§" ÌëúÌòÑ Í∏àÏßÄ)
- Î≥¥Ïù¥ÏßÄ ÏïäÎäî Î∂ÄÎ∂ÑÏóê ÎåÄÌïú Ïñ∏Í∏â ("Î≥¥Ïù¥ÏßÄ ÏïäÎäîÎã§", "ÏóÜÎã§" Îì±Ïùò ÌëúÌòÑ Í∏àÏßÄ)
- Î∞òÎ≥µÏ†ÅÏù∏ ÏÑ§Î™Ö
- Í∞êÏ†ïÏù¥ÎÇò Î∂ÑÏúÑÍ∏∞ Î¨òÏÇ¨

ÌòïÏãù:
- 1-2Î¨∏Ïû•ÏúºÎ°ú Îß§Ïö∞ Í∞ÑÍ≤∞ÌïòÍ≤å ÏûëÏÑ±
- Îã®Ïàú ÏÇ¨Ïã§ ÎÇòÏó¥ ÌòïÏãù (Ïòà: "Ïù¥ÎØ∏ÏßÄÏóêÎäî Í≤ÄÏùÄ Î®∏Î¶¨ Ïó¨ÏÑ±Ïù¥ ÏûàÍ≥†, Î∞∞Í≤ΩÏùÄ Ìù∞ÏÉâÏù¥Îã§.")

OCR ÌÖçÏä§Ìä∏ (Ï∞∏Í≥†Ïö©, Ïã§Ï†ú Ïù¥ÎØ∏ÏßÄÏóê Î≥¥Ïù¥Îäî Í≤ΩÏö∞Îßå Ïñ∏Í∏â): {ocr_result.ocr_text}

ÏòÅÏñ¥Î°ú Í∞ÑÍ≤∞ÌïòÍ≤å ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî."""

                        
                        # OCR ÌÖçÏä§Ìä∏Î•º Ï†ÑÎã¨ (analyze_image ÎÇ¥Î∂ÄÏóêÏÑú Í¥ÄÎ†®ÏÑ± ÌåêÎã®)
                        image_analysis = ollama_client.analyze_image(
                            ocr_result.file.path, 
                            custom_prompt,
                            ocr_text=ocr_result.ocr_text
                        )
                        
                        # OCR ÌÖçÏä§Ìä∏ Î∂ÑÏÑù (ÌÖçÏä§Ìä∏Í∞Ä ÏûàÍ≥† both Î™®ÎìúÏù∏ Í≤ΩÏö∞)
                        if ocr_result.ocr_text and analysis_type == 'both':
                            # ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ Ï†ïÎ¶¨Î•º ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏
                            text_prompt = f"""Îã§Ïùå OCRÎ°ú Ï∂îÏ∂úÌïú ÌÖçÏä§Ìä∏Î•º ÏûêÏÑ∏Ìûà Î∂ÑÏÑùÌïòÍ≥† Î™ÖÌôïÌïòÍ≤å Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî:

{ocr_result.ocr_text}

Î∂ÑÏÑù ÏßÄÏπ®:
1. ÌÖçÏä§Ìä∏Ïùò Ï£ºÏöî ÎÇ¥Ïö©Í≥º Íµ¨Ï°∞Î•º ÌååÏïÖÌïòÏó¨ Ï†ïÎ¶¨
2. Îã®Ïàú ÏöîÏïΩÏù¥ ÏïÑÎãå, ÌÖçÏä§Ìä∏Ïùò ÌïµÏã¨ Ï†ïÎ≥¥Î•º Ï∂©Ïã§ÌïòÍ≤å Ï†ïÎ¶¨
3. Ï§ëÏöîÌïú ÏÑ∏Î∂Ä Ï†ïÎ≥¥Î•º Ìè¨Ìï®
4. ÎÇ¥Ïö©Ïù¥ Ïù¥ÎØ∏ÏßÄÏôÄ Í¥ÄÎ†®Ïù¥ ÏûàÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú Î¨∏Îß•ÏùÑ Í≥†Î†§ÌïòÏó¨ Ï†ïÎ¶¨

Î∞òÎìúÏãú "ÏòÅÏñ¥(En)"Î°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî."""
                            
                            try:
                                text_analysis = ollama_client.analyze_text(ocr_result.ocr_text, text_prompt)
                            except Exception as e:
                                logger.error(f"ÌÖçÏä§Ìä∏ Î∂ÑÏÑù Ïò§Î•ò: {str(e)}")
                                text_analysis = f"ÌÖçÏä§Ìä∏ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}"
                            
                            # Îëê Î∂ÑÏÑù Í≤∞Í≥º Í≤∞Ìï©
                            combined_analysis = f"Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑù Í≤∞Í≥º:\n{image_analysis}\n\nÌÖçÏä§Ìä∏ Î∂ÑÏÑù Í≤∞Í≥º:\n{text_analysis}"
                        else:
                            # OCR ÏóÜÏù¥ Ïù¥ÎØ∏ÏßÄ Î∂ÑÏÑùÎßå ÏàòÌñâ
                            combined_analysis = image_analysis
                        
                    else:  # PDF ÌååÏùºÏù∏ Í≤ΩÏö∞
                        if ocr_result.ocr_text:
                            if analyze_by_page and len(page_texts) > 1:
                                # Í∞úÏÑ†Îêú ÌéòÏù¥ÏßÄÎ≥Ñ Î∂ÑÏÑù ÏàòÌñâ - OllamaClientÏùò Î∂ÑÏÑù Í∏∞Îä• ÌôúÏö©
                                try:
                                    combined_analysis = ollama_client.analyze_text(ocr_result.ocr_text, None, page_texts)
                                    logger.info("ÌéòÏù¥ÏßÄÎ≥Ñ Î∂ÑÏÑù ÏôÑÎ£å")
                                except Exception as e:
                                    logger.error(f"ÌéòÏù¥ÏßÄÎ≥Ñ Î∂ÑÏÑù Ïò§Î•ò: {str(e)}")
                                    combined_analysis = f"ÌéòÏù¥ÏßÄÎ≥Ñ Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}"
                            else:
                                # Î¨∏ÏÑú Ï†ÑÏ≤¥ Î∂ÑÏÑù - ÌéòÏù¥ÏßÄÎ≥Ñ Íµ¨Ï°∞Ìôî ÏöîÏ≤≠
                                text_prompt = f"""Îã§Ïùå PDFÏóêÏÑú Ï∂îÏ∂úÌïú ÌÖçÏä§Ìä∏Î•º ÌéòÏù¥ÏßÄÎ≥ÑÎ°ú Î™ÖÌôïÌïòÍ≤å Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî:

{ocr_result.ocr_text}

Î∂ÑÏÑù ÏßÄÏπ®:
1. ÌÖçÏä§Ìä∏Î•º ÌéòÏù¥ÏßÄÎÇò ÏÑπÏÖò Îã®ÏúÑÎ°ú Íµ¨Î∂ÑÌïòÏó¨ Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî.
2. ÎÇ¥Ïö©ÏùÑ ÏöîÏïΩÌïòÏßÄ ÎßêÍ≥†, Í∞Å ÏÑπÏÖòÏùò ÌïµÏã¨ Ï†ïÎ≥¥Î•º Ï∂©Ïã§ÌïòÍ≤å Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî.
3. Î™®Îì† Ï§ëÏöîÌïú ÏÑ∏Î∂Ä Ï†ïÎ≥¥Î•º Ìè¨Ìï®Ìï¥Ï£ºÏÑ∏Ïöî.
4. ÎÇ¥Ïö©ÏùÑ Îã®Ïàú ÏöîÏïΩÌïòÏßÄ ÎßêÍ≥†, Íµ¨Ï°∞ÌôîÎêú ÌòïÏãùÏúºÎ°ú Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî.

Îã§ÏùåÍ≥º Í∞ôÏùÄ ÌòïÏãùÏúºÎ°ú Ï†ïÎ¶¨Ìï¥Ï£ºÏÑ∏Ïöî:
===== ÌéòÏù¥ÏßÄ 1 (ÎòêÎäî ÏÑπÏÖò 1) =====
- Ï£ºÏöî ÎÇ¥Ïö© Ï†ïÎ¶¨
- Ï§ëÏöî Í∞úÎÖê ÏÑ§Î™Ö
- ÌïµÏã¨ Ï†ïÎ≥¥ ÎÇòÏó¥

===== ÌéòÏù¥ÏßÄ 2 (ÎòêÎäî ÏÑπÏÖò 2) =====
- Ï£ºÏöî ÎÇ¥Ïö© Ï†ïÎ¶¨
...

Î∞òÎìúÏãú "ÏòÅÏñ¥Î°ú" ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî."""
                                
                                try:
                                    text_analysis = ollama_client.analyze_text(ocr_result.ocr_text, text_prompt)
                                    combined_analysis = text_analysis
                                except Exception as e:
                                    logger.error(f"Î¨∏ÏÑú Ï†ÑÏ≤¥ Î∂ÑÏÑù Ïò§Î•ò: {str(e)}")
                                    combined_analysis = f"Î¨∏ÏÑú Î∂ÑÏÑù Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}\n\nOCR Í≤∞Í≥º: {ocr_result.ocr_text[:500]}..."
                    
                    logger.info("Ïù¥ÎØ∏ÏßÄ/ÌÖçÏä§Ìä∏ Î∂ÑÏÑù ÏôÑÎ£å")
                
                # GPT Î≤àÏó≠ ÏàòÌñâ (Î≤àÏó≠Ïù¥ ÌôúÏÑ±ÌôîÎêú Í≤ΩÏö∞)
                if enable_translation and combined_analysis and gpt_translator.is_available:
                    logger.info("GPT Î≤àÏó≠ ÏãúÏûë")
                    try:
                        # Î∂ÑÏÑù Ïú†ÌòïÏóê Îî∞Î•∏ Î≤àÏó≠
                        if file_type == 'pdf' and analyze_by_page and len(page_texts) > 1:
                            # ÌéòÏù¥ÏßÄÎ≥Ñ Î∂ÑÏÑù Í≤∞Í≥º Î≤àÏó≠
                            translation_result = gpt_translator.translate_paged_analysis(combined_analysis)
                        else:
                            # ÏùºÎ∞ò Î∂ÑÏÑù Í≤∞Í≥º Î≤àÏó≠
                            translation_result = gpt_translator.translate_analysis_result(combined_analysis, file_type)
                        
                        if translation_result and translation_result.get("success"):
                            translated_analysis = translation_result["translated_analysis"]
                            translation_success = True
                            logger.info("GPT Î≤àÏó≠ ÏÑ±Í≥µ")
                        else:
                            error_msg = translation_result.get('error', 'Unknown error') if translation_result else 'No translation result'
                            logger.error(f"GPT Î≤àÏó≠ Ïã§Ìå®: {error_msg}")
                            translated_analysis = f"Î≤àÏó≠ Ïã§Ìå®: {error_msg}"
                            translation_error = error_msg
                            
                    except Exception as e:
                        logger.error(f"GPT Î≤àÏó≠ Ï§ë ÏòàÏô∏ Î∞úÏÉù: {str(e)}")
                        translated_analysis = f"Î≤àÏó≠ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}"
                        translation_error = str(e)
                
                # Î≤àÏó≠ Í¥ÄÎ†® Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†ÄÏû•
                ocr_result.translation_enabled = enable_translation
                ocr_result.translation_success = translation_success
                ocr_result.analysis_type = analysis_type
                ocr_result.analyze_by_page = analyze_by_page
                
                # MySQL Ï†ÄÏû•ÏùÑ ÏúÑÌïú ÌÖçÏä§Ìä∏ Ï†ïÌôî
                ocr_result.llm_response = self.clean_text(combined_analysis)
                
                # Î≤àÏó≠ Í≤∞Í≥ºÎèÑ Ï†ÄÏû•
                if enable_translation and translated_analysis:
                    if translation_success:
                        # ÏÑ±Í≥µÌïú Î≤àÏó≠ Í≤∞Í≥º Ï†ÄÏû•
                        ocr_result.llm_response_korean = self.clean_text(translated_analysis)
                        ocr_result.translation_model = gpt_translator.model if gpt_translator else "unknown"
                    else:
                        # Ïã§Ìå®Ìïú Í≤ΩÏö∞ Ïò§Î•ò Î©îÏãúÏßÄ Ï†ÄÏû• (ÎîîÎ≤ÑÍπÖÏö©)
                        ocr_result.llm_response_korean = f"Î≤àÏó≠ Ïã§Ìå®: {translation_error}"
                
                # ÌÖçÏä§Ìä∏ Í¥ÄÎ†®ÏÑ± Ï†ïÎ≥¥ Ï†ÄÏû• - PDFÎäî Ìï≠ÏÉÅ True, Ïù¥ÎØ∏ÏßÄÎäî Î∂ÑÏÑù Í≥ºÏ†ïÏóêÏÑú Í≤∞Ï†ï
                if file_type == 'pdf':
                    ocr_result.text_relevant = True
                
            except Exception as e:
                logger.error("Ï≤òÎ¶¨ Ïã§Ìå®: %s", str(e), exc_info=True)
                return Response({'error': f'Ï≤òÎ¶¨ Ïã§Ìå®: {str(e)}'}, 
                               status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # Í≤∞Í≥º Ï†ÄÏû•
            try:
                ocr_result.save()
                logger.info("OCRResult Ï†ÄÏû• ÏôÑÎ£å (ID: %s)", ocr_result.id)
            except Exception as e:
                logger.error(f"Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï†ÄÏû• Ïã§Ìå®: {str(e)}")
                return Response({'error': f'Í≤∞Í≥º Ï†ÄÏû• Ïã§Ìå®: {str(e)}'}, 
                            status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ÏùëÎãµ Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ± - Î™ÖÏãúÏ†ÅÏúºÎ°ú ÌïÑÎìú ÏßÄÏ†ï
            try:
                # Í∏∞Î≥∏ ÏãúÎ¶¨ÏñºÎùºÏù¥Ï†Ä Îç∞Ïù¥ÌÑ∞
                response_data = OCRResultSerializer(ocr_result).data
                
                # Î≤àÏó≠ Í¥ÄÎ†® Ï†ïÎ≥¥ Î™ÖÏãúÏ†Å Ï∂îÍ∞Ä
                response_data['translation_enabled'] = enable_translation
                response_data['translation_success'] = translation_success
                
                # ÏòÅÏñ¥ ÏõêÎ¨∏Í≥º ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ÏùÑ Î™ÖÌôïÌûà Íµ¨Î∂Ñ
                response_data['llm_response'] = ocr_result.llm_response  # ÏòÅÏñ¥ ÏõêÎ¨∏
                
                if enable_translation and translation_success:
                    # Î≤àÏó≠ ÏÑ±Í≥µ Ïãú ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ Ï∂îÍ∞Ä
                    response_data['llm_response_korean'] = ocr_result.llm_response_korean
                    logger.info("ÏùëÎãµÏóê ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ Ìè¨Ìï®")
                elif enable_translation and not translation_success:
                    # Î≤àÏó≠ Ïã§Ìå® Ïãú Ïò§Î•ò Ï†ïÎ≥¥ Ï∂îÍ∞Ä
                    response_data['llm_response_korean'] = None
                    response_data['translation_error'] = translation_error if translation_error else "Î≤àÏó≠ Ïã§Ìå®"
                    logger.info("Î≤àÏó≠ Ïã§Ìå® - ÏòÅÏñ¥ ÏõêÎ¨∏Îßå Ìè¨Ìï®")
                else:
                    # Î≤àÏó≠ ÎπÑÌôúÏÑ±Ìôî Ïãú
                    response_data['llm_response_korean'] = None
                    logger.info("Î≤àÏó≠ ÎπÑÌôúÏÑ±Ìôî - ÏòÅÏñ¥ ÏõêÎ¨∏Îßå Ìè¨Ìï®")
                
                # ÎîîÎ≤ÑÍπÖÏö© Î°úÍ∑∏
                logger.info(f"ÏùëÎãµ Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ± ÏôÑÎ£å:")
                logger.info(f"  - ÏòÅÏñ¥ ÏõêÎ¨∏ Í∏∏Ïù¥: {len(response_data.get('llm_response', ''))}")
                logger.info(f"  - ÌïúÍµ≠Ïñ¥ Î≤àÏó≠ Í∏∏Ïù¥: {len(response_data.get('llm_response_korean', '') or '')}")
                logger.info(f"  - Î≤àÏó≠ ÏÑ±Í≥µ: {response_data.get('translation_success', False)}")
                
            except Exception as e:
                logger.error(f"ÏùëÎãµ Îç∞Ïù¥ÌÑ∞ Íµ¨ÏÑ± Ïã§Ìå®: {str(e)}")
                return Response({'error': f'ÏùëÎãµ Íµ¨ÏÑ± Ïã§Ìå®: {str(e)}'}, 
                            status=status.HTTP_500_INTERNAL_SERVER_ERROR)
            
            # ÏùëÎãµ Î∞òÌôò
            return Response(response_data, status=status.HTTP_201_CREATED)
                
        except Exception as e:
            logger.error("Ï≤òÎ¶¨ Ï§ë ÏòàÍ∏∞Ïπò ÏïäÏùÄ Ïò§Î•ò: %s", str(e), exc_info=True)
            return Response({'error': f'ÏÑúÎ≤Ñ Ïò§Î•ò: {str(e)}'}, 
                           status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def extract_text_from_pdf_by_pages(self, pdf_path):
        """PDFÏóêÏÑú ÏßÅÏ†ë ÌÖçÏä§Ìä∏Î•º ÌéòÏù¥ÏßÄÎ≥ÑÎ°ú Ï∂îÏ∂ú"""
        pages = []
        try:
            with open(pdf_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                total_pages = len(reader.pages)
                
                for i in range(total_pages):
                    page = reader.pages[i]
                    text = page.extract_text()
                    pages.append({"page": i + 1, "text": text})
                    
            return pages
        except Exception as e:
            logger.error(f"PDF ÌÖçÏä§Ìä∏ ÏßÅÏ†ë Ï∂îÏ∂ú Ïò§Î•ò: {str(e)}")
            raise
    
    def ocr_pdf_by_pages(self, pdf_path, ollama_client, start_page=1, end_page=0):
        """PDFÎ•º OCRÎ°ú Ï≤òÎ¶¨ÌïòÏó¨ ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú"""
        pages = []
        
        try:
            # PDF2ImageÎ°ú Ïù¥ÎØ∏ÏßÄ Î≥ÄÌôò
            with tempfile.TemporaryDirectory() as path:
                # ÌéòÏù¥ÏßÄ Î≤àÌò∏Îäî 1Î∂ÄÌÑ∞ ÏãúÏûëÌïòÏßÄÎßå, convert_from_pathÎäî 0Î∂ÄÌÑ∞ ÏãúÏûëÌïòÎØÄÎ°ú Ï°∞Ï†ï
                first_page = start_page
                last_page = None if end_page <= 0 else end_page
                
                images = convert_from_path(
                    pdf_path, 
                    dpi=300, 
                    output_folder=path, 
                    first_page=first_page,
                    last_page=last_page
                )
                
                # Í∞Å ÌéòÏù¥ÏßÄ Ïù¥ÎØ∏ÏßÄ OCR Ï≤òÎ¶¨
                for i, image in enumerate(images):
                    # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
                    preprocessed_img = ollama_client.preprocess_image_for_ocr(image)
                    # OCR ÏàòÌñâ
                    text = ollama_client.get_optimized_ocr_text(preprocessed_img, lang='kor+eng')
                    
                    # ÌéòÏù¥ÏßÄ Î≤àÌò∏ Í≥ÑÏÇ∞ (ÏãúÏûë ÌéòÏù¥ÏßÄ Í≥†Î†§)
                    page_num = start_page + i
                    pages.append({"page": page_num, "text": text})
                    
            return pages
        except Exception as e:
            logger.error(f"PDF OCR Ï≤òÎ¶¨ Ïò§Î•ò: {str(e)}")
            raise
    
    def clean_text(self, text):
        """ÌÖçÏä§Ìä∏ Ï†ïÌôî Ìï®Ïàò"""
        if not text:
            return ""
            
        # Ïó∞ÏÜçÎêú Í≥µÎ∞± Ï†úÍ±∞
        text = re.sub(r'\s+', ' ', text)
        # Ïó∞ÏÜçÎêú Ï§ÑÎ∞îÍøà Ï†úÍ±∞
        text = re.sub(r'\n\s*\n', '\n\n', text)
        # ÏïûÎí§ Í≥µÎ∞± Ï†úÍ±∞
        text = text.strip()
        
        return text
    
# chat/views.pyÏóê Ï∂îÍ∞ÄÌï† Î∑∞Îì§

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from django.shortcuts import get_object_or_404
from datetime import datetime, timedelta
import json
import re
from .models import Schedule, ScheduleRequest, ConflictResolution
from .serializers import (
    ScheduleSerializer, ScheduleRequestSerializer, 
    ConflictResolutionSerializer, ScheduleRequestInputSerializer
)

# Í∏∞Ï°¥ ChatBot ÌÅ¥ÎûòÏä§ÏôÄ ChatViewÎäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ...
# chat/views.py ÏàòÏ†ï Î≤ÑÏ†Ñ

# from rest_framework.views import APIView
# from rest_framework.response import Response
# from rest_framework import status
# from rest_framework.decorators import api_view, permission_classes
# from rest_framework.permissions import IsAuthenticated, AllowAny
# from django.shortcuts import get_object_or_404
# from datetime import datetime, timedelta
# import json
# import re
# from .models import Schedule, ScheduleRequest, ConflictResolution
# from .serializers import (
#     ScheduleSerializer, ScheduleRequestSerializer, 
#     ConflictResolutionSerializer, ScheduleRequestInputSerializer
# )

# # Í∏∞Ï°¥ ChatBot ÌÅ¥ÎûòÏä§Îäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ...
# OPENAI_API_KEY = "***REMOVED***"
# ANTHROPIC_API_KEY = "***REMOVED***"
# GROQ_API_KEY = "***REMOVED***"


# chatbots = {
#     'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
#     'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
#     'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
# }

# # Î∞±ÏóîÎìú views.pyÏóê Ï∂îÍ∞ÄÌï† Ìï®ÏàòÎì§

# def parse_date_from_request(request_text):
#     """ÏûêÏó∞Ïñ¥ ÎÇ†ÏßúÎ•º Ïã§Ï†ú ÎÇ†ÏßúÎ°ú Î≥ÄÌôò"""
#     today = datetime.now().date()
    
#     # Ïò§Îäò/ÎÇ¥Ïùº/Î™®Î†à Îì± ÌïúÍµ≠Ïñ¥ ÎÇ†Ïßú ÌëúÌòÑ Ï≤òÎ¶¨
#     if 'Ïò§Îäò' in request_text:
#         return today
#     elif 'ÎÇ¥Ïùº' in request_text:
#         return today + timedelta(days=1)
#     elif 'Î™®Î†à' in request_text or 'Î™®Îûò' in request_text:
#         return today + timedelta(days=2)
#     elif 'Ïù¥Î≤à Ï£º' in request_text:
#         # Ïù¥Î≤à Ï£º Í∏àÏöîÏùºÎ°ú ÏÑ§Ï†ï
#         days_until_friday = (4 - today.weekday()) % 7
#         if days_until_friday == 0:  # Ïò§ÎäòÏù¥ Í∏àÏöîÏùºÏù¥Î©¥ Îã§Ïùå Ï£º Í∏àÏöîÏùº
#             days_until_friday = 7
#         return today + timedelta(days=days_until_friday)
#     elif 'Îã§Ïùå Ï£º' in request_text:
#         return today + timedelta(days=7)
#     else:
#         # Í∏∞Î≥∏Í∞í: ÎÇ¥Ïùº
#         return today + timedelta(days=1)

# def parse_multiple_schedules_backend(request_text):
#     """Î∞±ÏóîÎìúÏóêÏÑú Ïó¨Îü¨ ÏùºÏ†ï ÌååÏã±"""
#     # ÏâºÌëú, "Í∑∏Î¶¨Í≥†", "Î∞è" Îì±ÏúºÎ°ú Î∂ÑÎ¶¨
#     separators = [',', 'Ôºå', 'Í∑∏Î¶¨Í≥†', 'Î∞è', 'ÏôÄ', 'Í≥º']
    
#     parts = [request_text]
#     for sep in separators:
#         new_parts = []
#         for part in parts:
#             new_parts.extend(part.split(sep))
#         parts = new_parts
    
#     # Ï†ïÎ¶¨Îêú ÏöîÏ≤≠Îì§ Î∞òÌôò
#     cleaned_requests = []
#     for part in parts:
#         cleaned = part.strip()
#         if cleaned and len(cleaned) > 2:  # ÎÑàÎ¨¥ ÏßßÏùÄ ÌÖçÏä§Ìä∏ Ï†úÏô∏
#             cleaned_requests.append(cleaned)
    
#     return cleaned_requests if len(cleaned_requests) > 1 else [request_text]
# class ScheduleOptimizerBot:
#     """ÏùºÏ†ï ÏµúÏ†ÅÌôîÎ•º ÏúÑÌïú AI Î¥á ÌÅ¥ÎûòÏä§ - Ïó¨Îü¨ AI Î™®Îç∏ Ïó∞Îèô"""
    
#     def __init__(self):
#         self.chatbots = {
#                 'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
#                 'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
#                 'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
#             }
        
#     def create_schedule_prompt(self, request_text, user_context=None, existing_schedules=None):
#         """ÏùºÏ†ï ÏÉùÏÑ±ÏùÑ ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ± - Îπà ÏãúÍ∞Ñ Î∂ÑÏÑù Ìè¨Ìï®"""
#         base_prompt = f"""
#         ÏÇ¨Ïö©ÏûêÏùò ÏùºÏ†ï ÏöîÏ≤≠ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏµúÏ†ÅÏùò Îπà ÏãúÍ∞ÑÏùÑ Ï∞æÏïÑ Ï†úÏïàÌï¥Ï£ºÏÑ∏Ïöî.

#         ÏöîÏ≤≠ ÎÇ¥Ïö©: {request_text}
        
#         Í∏∞Ï°¥ ÏùºÏ†ïÎì§: {existing_schedules or []}
        
#         Î∂ÑÏÑù Î∞©Î≤ï:
#         1. Í∏∞Ï°¥ ÏùºÏ†ïÎì§Ïùò ÏãúÍ∞ÑÎåÄÎ•º ÌôïÏù∏ÌïòÏó¨ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÎÇ†Ïùò Îπà ÏãúÍ∞ÑÏùÑ Ï∞æÏïÑÏ£ºÏÑ∏Ïöî
#         2. ÏöîÏ≤≠Îêú ÏùºÏ†ïÏùò ÏÑ±Í≤©Ïóê ÎßûÎäî ÏµúÏ†ÅÏùò ÏãúÍ∞ÑÎåÄÎ•º Ï∂îÏ≤úÌï¥Ï£ºÏÑ∏Ïöî
#         3. ÏùºÏ†ï Í∞Ñ Ïó¨Ïú† ÏãúÍ∞ÑÎèÑ Í≥†Î†§Ìï¥Ï£ºÏÑ∏Ïöî
        
#         Îã§Ïùå ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî:
#         {{
#             "title": "ÏùºÏ†ï Ï†úÎ™©",
#             "description": "ÏÉÅÏÑ∏ ÏÑ§Î™Ö",
#             "suggested_date": "YYYY-MM-DD",
#             "suggested_start_time": "HH:MM",
#             "suggested_end_time": "HH:MM",
#             "location": "Ïû•ÏÜå (ÏÑ†ÌÉùÏÇ¨Ìï≠)",
#             "priority": "HIGH/MEDIUM/LOW/URGENT",
#             "attendees": ["Ï∞∏ÏÑùÏûê1", "Ï∞∏ÏÑùÏûê2"],
#             "reasoning": "Ïù¥ ÏãúÍ∞ÑÏùÑ Ï†úÏïàÌïòÎäî Ïù¥Ïú† (Îπà ÏãúÍ∞Ñ Î∂ÑÏÑù Í≤∞Í≥º Ìè¨Ìï®)"
#         }}
        
#         ÏÇ¨Ïö©ÏûêÏùò Îß•ÎùΩ Ï†ïÎ≥¥: {user_context or "ÏóÜÏùå"}
#         """
#         return base_prompt

#     def create_conflict_resolution_prompt(self, conflicting_schedules, new_request):
#         """ÏùºÏ†ï Ï∂©Îèå Ìï¥Í≤∞ÏùÑ ÏúÑÌïú ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±"""
#         prompt = f"""
#         Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º ÏÉàÎ°úÏö¥ ÏùºÏ†ï ÏöîÏ≤≠ ÏÇ¨Ïù¥Ïóê Ï∂©ÎèåÏù¥ Î∞úÏÉùÌñàÏäµÎãàÎã§. 
#         Ïó¨Îü¨ AIÏùò Í¥ÄÏ†êÏóêÏÑú ÏµúÏ†ÅÏùò Ìï¥Í≤∞ Î∞©ÏïàÏùÑ Ï†úÏïàÌï¥Ï£ºÏÑ∏Ïöî.

#         Í∏∞Ï°¥ Ï∂©Îèå ÏùºÏ†ïÎì§:
#         {json.dumps(conflicting_schedules, ensure_ascii=False, indent=2)}

#         ÏÉàÎ°úÏö¥ ÏùºÏ†ï ÏöîÏ≤≠: {new_request}

#         Îã§Ïùå ÌòïÏãùÏúºÎ°ú Ìï¥Í≤∞ Î∞©ÏïàÏùÑ Ï†úÏïàÌï¥Ï£ºÏÑ∏Ïöî:
#         {{
#             "resolution_options": [
#                 {{
#                     "option": "Î∞©Ïïà 1",
#                     "description": "ÏÉÅÏÑ∏ ÏÑ§Î™Ö",
#                     "impact": "ÏòÅÌñ•ÎèÑ Î∂ÑÏÑù",
#                     "recommended": true/false
#                 }},
#                 {{
#                     "option": "Î∞©Ïïà 2", 
#                     "description": "ÏÉÅÏÑ∏ ÏÑ§Î™Ö",
#                     "impact": "ÏòÅÌñ•ÎèÑ Î∂ÑÏÑù",
#                     "recommended": true/false
#                 }}
#             ],
#             "best_recommendation": "Í∞ÄÏû• Ï∂îÏ≤úÌïòÎäî Î∞©ÏïàÍ≥º Ïù¥Ïú†"
#         }}
#         """
#         return prompt
    
#     def get_ai_suggestions(self, prompt, suggestion_type="schedule"):
#         """Ïó¨Îü¨ AI Î™®Îç∏Î°úÎ∂ÄÌÑ∞ Ï†úÏïàÎ∞õÍ∏∞"""
#         suggestions = {}
        
#         for model_name, chatbot in self.chatbots.items():
#             try:
#                 response = chatbot.chat(prompt)
#                 suggestions[f"{model_name}_suggestion"] = response
#             except Exception as e:
#                 suggestions[f"{model_name}_suggestion"] = f"Ïò§Î•ò Î∞úÏÉù: {str(e)}"
        
#         return suggestions
    
#     def analyze_and_optimize_suggestions(self, suggestions, query, selected_models=['GPT', 'Claude', 'Mixtral']):
#         """Ïó¨Îü¨ AI Ï†úÏïàÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏµúÏ†ÅÌôîÎêú Í≤∞Í≥º ÏÉùÏÑ± - Í∏∞Ï°¥ analyze_responses ÌôúÏö©"""
#         try:
#             # ChatBotÏùò analyze_responses Í∏∞Îä• ÌôúÏö©
#             analyzer = self.chatbots['claude']  # ClaudeÎ•º Î∂ÑÏÑùÏö©ÏúºÎ°ú ÏÇ¨Ïö©
            
#             # Ï†úÏïàÏùÑ Î∂ÑÏÑùÏö© ÌòïÌÉúÎ°ú Î≥ÄÌôò
#             responses_for_analysis = {}
#             for key, suggestion in suggestions.items():
#                 model_name = key.replace('_suggestion', '')
#                 responses_for_analysis[model_name] = suggestion
            
#             # Í∏∞Ï°¥ analyze_responses Î©îÏÑúÎìú ÌôúÏö©
#             analysis_result = analyzer.analyze_responses(
#                 responses_for_analysis, 
#                 query, 
#                 'Korean',  # Í∏∞Î≥∏ Ïñ∏Ïñ¥
#                 selected_models
#             )
            
#             # JSON ÏùëÎãµÏóêÏÑú ÏµúÏ†ÅÌôîÎêú ÏùºÏ†ï Ï†ïÎ≥¥ Ï∂îÏ∂ú
#             try:
#                 # best_responseÏóêÏÑú JSON Î∂ÄÎ∂Ñ Ï∂îÏ∂ú
#                 json_match = re.search(r'\{.*\}', analysis_result.get('best_response', ''), re.DOTALL)
#                 if json_match:
#                     optimized = json.loads(json_match.group())
#                 else:
#                     # fallback: Ï≤´ Î≤àÏß∏ Ïú†Ìö®Ìïú Ï†úÏïà ÏÇ¨Ïö©
#                     optimized = self._extract_first_valid_suggestion(suggestions)
#             except:
#                 optimized = self._extract_first_valid_suggestion(suggestions)
            
#             confidence = self._calculate_confidence_from_analysis(analysis_result)
            
#             return {
#                 "optimized_suggestion": optimized,
#                 "confidence_score": confidence,
#                 "ai_analysis": analysis_result,
#                 "individual_suggestions": self._parse_individual_suggestions(suggestions)
#             }
            
#         except Exception as e:
#             print(f"Analysis error: {str(e)}")
#             return {"error": f"ÏµúÏ†ÅÌôî Í≥ºÏ†ïÏóêÏÑú Ïò§Î•ò Î∞úÏÉù: {str(e)}"}
    
#     def _extract_first_valid_suggestion(self, suggestions):
#         """Ï≤´ Î≤àÏß∏ Ïú†Ìö®Ìïú Ï†úÏïà Ï∂îÏ∂ú"""
#         for key, suggestion in suggestions.items():
#             try:
#                 json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
#                 if json_match:
#                     return json.loads(json_match.group())
#             except:
#                 continue
        
#         # Í∏∞Î≥∏ Ï†úÏïà Î∞òÌôò
#         return {
#             "title": "ÏÉà ÏùºÏ†ï",
#             "description": "AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§",
#             "suggested_date": datetime.now().strftime('%Y-%m-%d'),
#             "suggested_start_time": "09:00",
#             "suggested_end_time": "10:00",
#             "location": "",
#             "priority": "MEDIUM",
#             "attendees": [],
#             "reasoning": "Ïó¨Îü¨ AI Î™®Îç∏Ïùò Ï†úÏïàÏùÑ Ï¢ÖÌï©Ìïú Í≤∞Í≥ºÏûÖÎãàÎã§."
#         }
    
#     def _calculate_confidence_from_analysis(self, analysis_result):
#         """Î∂ÑÏÑù Í≤∞Í≥ºÏóêÏÑú Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞"""
#         reasoning = analysis_result.get('reasoning', '')
        
#         # ÌÇ§ÏõåÎìú Í∏∞Î∞ò Ïã†Î¢∞ÎèÑ Í≥ÑÏÇ∞
#         confidence_keywords = ['ÏùºÏπò', 'Í≥µÌÜµ', 'Ï†ïÌôï', 'ÏµúÏ†Å', 'Ï∂îÏ≤ú']
#         uncertainty_keywords = ['Î∂àÌôïÏã§', 'Ï∂îÏ†ï', 'Í∞ÄÎä•ÏÑ±', 'Ïñ¥Î†§ÏõÄ']
        
#         confidence_score = 0.5  # Í∏∞Î≥∏Í∞í
        
#         for keyword in confidence_keywords:
#             if keyword in reasoning:
#                 confidence_score += 0.1
        
#         for keyword in uncertainty_keywords:
#             if keyword in reasoning:
#                 confidence_score -= 0.1
        
#         return max(0.1, min(1.0, confidence_score))
    
#     def _parse_individual_suggestions(self, suggestions):
#         """Í∞úÎ≥Ñ Ï†úÏïàÎì§ÏùÑ ÌååÏã±"""
#         parsed = []
#         for key, suggestion in suggestions.items():
#             try:
#                 json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
#                 if json_match:
#                     parsed_suggestion = json.loads(json_match.group())
#                     parsed_suggestion['source'] = key.replace('_suggestion', '')
#                     parsed.append(parsed_suggestion)
#             except:
#                 continue
#         return parsed

# class ScheduleManagementView(APIView):
#     """ÏùºÏ†ï Í¥ÄÎ¶¨ Î©îÏù∏ Î∑∞ - Í∂åÌïú ÏàòÏ†ï"""
#     # ÏûÑÏãúÎ°ú AllowAnyÎ°ú Î≥ÄÍ≤Ω (Í∞úÎ∞ú/ÌÖåÏä§Ìä∏Ïö©)
#     permission_classes = [IsAuthenticated]
    
#     def __init__(self):
#         super().__init__()
#         self.optimizer = ScheduleOptimizerBot()
    
#     def get(self, request):
#         """ÏÇ¨Ïö©ÏûêÏùò ÏùºÏ†ï Î™©Î°ù Ï°∞Ìöå"""
#         # üö´ Í∏∞Ï°¥ ÎçîÎØ∏ ÏÇ¨Ïö©Ïûê Î°úÏßÅ Ï†úÍ±∞
#         if not request.user.is_authenticated:
#             return Response({'error': 'Ïù∏Ï¶ùÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.'}, status=status.HTTP_401_UNAUTHORIZED)
        
#         schedules = Schedule.objects.filter(user=request.user).order_by('start_time')
        
#         # ÎÇ†Ïßú ÌïÑÌÑ∞ÎßÅ (Í∏∞Ï°¥ ÏΩîÎìú Ïú†ÏßÄ)
#         start_date = request.query_params.get('start_date')
#         end_date = request.query_params.get('end_date')
        
#         if start_date:
#             schedules = schedules.filter(start_time__date__gte=start_date)
#         if end_date:
#             schedules = schedules.filter(end_time__date__lte=end_date)
        
#         serializer = ScheduleSerializer(schedules, many=True)
#         return Response(serializer.data)
#     def post(self, request):
#         """ÏÉàÎ°úÏö¥ ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ - Ïó¨Îü¨ ÏùºÏ†ï ÏßÄÏõê Í∞úÏÑ†"""
#         try:
#             request_text = request.data.get('request_text', '')
#             existing_schedules = request.data.get('existing_schedules', [])
            
#             if not request_text:
#                 return Response({'error': 'ÏöîÏ≤≠ ÌÖçÏä§Ìä∏Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.'}, 
#                             status=status.HTTP_400_BAD_REQUEST)
#             if not request.user.is_authenticated:
#                 return Response({'error': 'Ïù∏Ï¶ùÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.'}, status=status.HTTP_401_UNAUTHORIZED)
        
#             user = request.user

         
            
#             # Ïó¨Îü¨ ÏùºÏ†ï ÏöîÏ≤≠Ïù∏ÏßÄ ÌôïÏù∏
#             schedule_requests = parse_multiple_schedules_backend(request_text)
#             target_date = parse_date_from_request(request_text)
            
#             if len(schedule_requests) > 1:
#                 # Ïó¨Îü¨ ÏùºÏ†ï Ï≤òÎ¶¨
#                 multiple_schedules = []
#                 all_individual_suggestions = []
                
#                 for i, single_request in enumerate(schedule_requests):
#                     # Í∞Å ÏùºÏ†ïÏùò ÏãúÏûë ÏãúÍ∞ÑÏùÑ Îã§Î•¥Í≤å ÏÑ§Ï†ï
#                     schedule_date = target_date
#                     if i > 0:  # Îëê Î≤àÏß∏ ÏùºÏ†ïÎ∂ÄÌÑ∞Îäî 2ÏãúÍ∞ÑÏî© Îí§Î°ú
#                         base_hour = 9 + (i * 2)
#                     else:
#                         base_hour = 9
                    
#                     # Í∞úÎ≥Ñ ÏùºÏ†ï ÏÉùÏÑ±
#                     optimized_schedule = {
#                         "title": self._extract_schedule_title(single_request),
#                         "description": f"AIÍ∞Ä Î∂ÑÏÑùÌïú {self._extract_schedule_title(single_request)} ÏùºÏ†ïÏûÖÎãàÎã§.",
#                         "suggested_date": schedule_date.strftime('%Y-%m-%d'),
#                         "suggested_start_time": f"{base_hour:02d}:00",
#                         "suggested_end_time": f"{base_hour + 2:02d}:00",
#                         "location": self._extract_schedule_location(single_request),
#                         "priority": "HIGH",
#                         "attendees": [],
#                         "reasoning": f"{i + 1}Î≤àÏß∏ ÏùºÏ†ï: {single_request}. Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏãúÍ∞ÑÏúºÎ°ú Î∞∞Ï†ïÌñàÏäµÎãàÎã§."
#                     }
#                     multiple_schedules.append(optimized_schedule)
                    
#                     # Í∞Å AIÎ≥Ñ Í∞úÎ≥Ñ Ï†úÏïà ÏÉùÏÑ±
#                     for ai_type in ['gpt', 'claude', 'mixtral']:
#                         individual_suggestion = optimized_schedule.copy()
#                         individual_suggestion['source'] = ai_type
#                         individual_suggestion['reasoning'] = f"{ai_type.upper()}Í∞Ä Î∂ÑÏÑùÌïú {self._extract_schedule_title(single_request)} ÏµúÏ†Å ÏãúÍ∞ÑÏûÖÎãàÎã§."
#                         all_individual_suggestions.append(individual_suggestion)
                
#                 # Ïó¨Îü¨ ÏùºÏ†ï ÏùëÎãµ ÏÉùÏÑ±
#                 response_data = {
#                     'request_id': int(datetime.now().timestamp()),
#                     'multiple_schedules': multiple_schedules,
#                     'optimized_suggestion': multiple_schedules[0],
#                     'confidence_score': 0.92,
#                     'individual_suggestions': all_individual_suggestions,
#                     'ai_analysis': {
#                         'analysis_summary': f"Ï¥ù {len(schedule_requests)}Í∞úÏùò ÏùºÏ†ïÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏµúÏ†ÅÏùò ÏãúÍ∞ÑÎåÄÎ°ú Î∞∞Ï†ïÌñàÏäµÎãàÎã§.",
#                         'reasoning': f"Ïó¨Îü¨ ÏùºÏ†ïÏùÑ {target_date.strftime('%YÎÖÑ %mÏõî %dÏùº')}Ïóê ÏãúÍ∞Ñ ÏàúÏÑúÎåÄÎ°ú Î∞∞ÏπòÌïòÏó¨ Ï∂©ÎèåÏùÑ Î∞©ÏßÄÌñàÏäµÎãàÎã§.",
#                         'models_used': ["gpt", "claude", "mixtral"]
#                     },
#                     'has_conflicts': False,
#                     'conflicts': [],
#                     'analysis_summary': f"{len(schedule_requests)}Í∞ú ÏùºÏ†ïÏóê ÎåÄÌï¥ 3Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.",
#                     'is_multiple_schedule': True
#                 }
                
#             else:
#                 # Îã®Ïùº ÏùºÏ†ï Ï≤òÎ¶¨ (Í∏∞Ï°¥ Î°úÏßÅ ÏÇ¨Ïö©ÌïòÎêò ÎÇ†Ïßú Î∞òÏòÅ)
#                 user_context = self._get_user_context(user)
                
#                 # ÎÇ†ÏßúÍ∞Ä Î∞òÏòÅÎêú ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ±
#                 enhanced_prompt = f"""
#                 ÏÇ¨Ïö©ÏûêÏùò ÏùºÏ†ï ÏöîÏ≤≠ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏµúÏ†ÅÏùò Îπà ÏãúÍ∞ÑÏùÑ Ï∞æÏïÑ Ï†úÏïàÌï¥Ï£ºÏÑ∏Ïöî.
                
#                 ÏöîÏ≤≠ ÎÇ¥Ïö©: {request_text}
#                 Î™©Ìëú ÎÇ†Ïßú: {target_date.strftime('%YÎÖÑ %mÏõî %dÏùº')} ({self._get_weekday_korean(target_date)})
#                 Í∏∞Ï°¥ ÏùºÏ†ïÎì§: {existing_schedules or []}
                
#                 Îã§Ïùå ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî:
#                 {{
#                     "title": "ÏùºÏ†ï Ï†úÎ™©",
#                     "description": "ÏÉÅÏÑ∏ ÏÑ§Î™Ö",
#                     "suggested_date": "{target_date.strftime('%Y-%m-%d')}",
#                     "suggested_start_time": "HH:MM",
#                     "suggested_end_time": "HH:MM",
#                     "location": "Ïû•ÏÜå",
#                     "priority": "HIGH/MEDIUM/LOW/URGENT",
#                     "attendees": [],
#                     "reasoning": "Ïù¥ ÏãúÍ∞ÑÏùÑ Ï†úÏïàÌïòÎäî Ïù¥Ïú†"
#                 }}
#                 """
                
#                 # Í∏∞Ï°¥ Îã®Ïùº ÏùºÏ†ï Î°úÏßÅ Í≥ÑÏÜç...
#                 suggestions = self.optimizer.get_ai_suggestions(enhanced_prompt)
#                 optimized_result = self.optimizer.analyze_and_optimize_suggestions(
#                     suggestions, f"ÏùºÏ†ï ÏöîÏ≤≠: {request_text}"
#                 )
                
#                 response_data = {
#                     'request_id': int(datetime.now().timestamp()),
#                     'optimized_suggestion': optimized_result.get('optimized_suggestion', {}),
#                     'confidence_score': optimized_result.get('confidence_score', 0.0),
#                     'ai_analysis': optimized_result.get('ai_analysis', {}),
#                     'individual_suggestions': optimized_result.get('individual_suggestions', []),
#                     'has_conflicts': False,
#                     'conflicts': [],
#                     'analysis_summary': "3Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.",
#                     'is_multiple_schedule': False
#                 }
            
#             return Response(response_data, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#                     return Response({
#                         'error': f'ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}'
#                     }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

#     def _extract_schedule_title(self, request):
#             """ÏöîÏ≤≠ÏóêÏÑú ÏùºÏ†ï Ï†úÎ™© Ï∂îÏ∂ú"""
#             if 'Ïö¥Îèô' in request:
#                 return 'Ïö¥Îèô'
#             elif 'ÎØ∏ÌåÖ' in request or 'ÌöåÏùò' in request:
#                 return 'ÌåÄ ÎØ∏ÌåÖ'
#             elif 'Í≥µÎ∂Ä' in request or 'ÌïôÏäµ' in request:
#                 return 'ÌïôÏäµ ÏãúÍ∞Ñ'
#             elif 'ÏûëÏóÖ' in request or 'ÏóÖÎ¨¥' in request:
#                 return 'ÏßëÏ§ë ÏûëÏóÖ'
#             elif 'ÏïΩÏÜç' in request:
#                 return 'ÏïΩÏÜç'
#             else:
#                 return 'ÏÉà ÏùºÏ†ï'

#     def _extract_schedule_location(self, request):
#             """ÏöîÏ≤≠ÏóêÏÑú Ïû•ÏÜå Ï∂îÏ∂ú"""
#             if 'Ïö¥Îèô' in request:
#                 return 'Ìó¨Ïä§Ïû•'
#             elif 'ÎØ∏ÌåÖ' in request or 'ÌöåÏùò' in request:
#                 return 'ÌöåÏùòÏã§'
#             elif 'Í≥µÎ∂Ä' in request or 'ÌïôÏäµ' in request:
#                 return 'ÎèÑÏÑúÍ¥Ä'
#             elif 'Ïª§Ìîº' in request:
#                 return 'Ïπ¥Ìéò'
#             else:
#                 return 'ÏÇ¨Î¨¥Ïã§'

#     def _get_weekday_korean(self, date):
#             """ÏöîÏùºÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Î∞òÌôò"""
#             weekdays = ['ÏõîÏöîÏùº', 'ÌôîÏöîÏùº', 'ÏàòÏöîÏùº', 'Î™©ÏöîÏùº', 'Í∏àÏöîÏùº', 'ÌÜ†ÏöîÏùº', 'ÏùºÏöîÏùº']
#             return weekdays[date.weekday()]
            
   
#     def _check_schedule_conflicts(self, user, suggestion):
#         """ÏùºÏ†ï Ï∂©Îèå Í≤ÄÏÇ¨"""
#         if not suggestion or 'suggested_date' not in suggestion:
#             return []
        
#         try:
#             suggested_date = datetime.strptime(suggestion['suggested_date'], '%Y-%m-%d').date()
#             start_time = datetime.strptime(suggestion.get('suggested_start_time', '09:00'), '%H:%M').time()
#             end_time = datetime.strptime(suggestion.get('suggested_end_time', '10:00'), '%H:%M').time()
            
#             suggested_start = datetime.combine(suggested_date, start_time)
#             suggested_end = datetime.combine(suggested_date, end_time)
            
#             conflicts = Schedule.objects.filter(
#                 user=user,
#                 start_time__date=suggested_date,
#                 start_time__lt=suggested_end,
#                 end_time__gt=suggested_start
#             )
            
#             return [ScheduleSerializer(conflict).data for conflict in conflicts]
            
#         except Exception as e:
#             return []

# # Í∂åÌïú ÏàòÏ†ïÎêú Ìï®ÏàòÎì§
# @api_view(['POST'])
# @permission_classes([IsAuthenticated])  # üîß Í∂åÌïú Î≥ÄÍ≤Ω
# def confirm_schedule(request, request_id):
#     """AI Ï†úÏïàÎêú ÏùºÏ†ïÏùÑ ÌôïÏ†ïÌïòÏó¨ Ïã§Ï†ú ÏùºÏ†ïÏúºÎ°ú ÏÉùÏÑ±"""
#     try:
#         user = request.user
        
#         # üö´ ScheduleRequest.DoesNotExistÏóêÏÑú ÎçîÎØ∏ Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Ï†úÍ±∞
#         try:
#             schedule_request = ScheduleRequest.objects.get(id=request_id, user=user)
#             optimized_suggestion = json.loads(schedule_request.optimized_suggestion)
#         except ScheduleRequest.DoesNotExist:
#             return Response({
#                 'error': f'ÏöîÏ≤≠ ID {request_id}Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§.'
#             }, status=status.HTTP_404_NOT_FOUND)
#                 # ÎÇ†Ïßú/ÏãúÍ∞Ñ ÌååÏã± Í∞úÏÑ†
#         try:
#             suggested_date = optimized_suggestion.get('suggested_date')
#             suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
#             suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
            
#             # ÎÇ†Ïßú ÌòïÏãù ÌôïÏù∏ Î∞è Î≥ÄÌôò
#             if isinstance(suggested_date, str):
#                 if 'T' in suggested_date:  # ISO ÌòïÏãùÏù∏ Í≤ΩÏö∞
#                     suggested_date = suggested_date.split('T')[0]
                
#                 start_datetime = datetime.strptime(
#                     f"{suggested_date} {suggested_start_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#                 end_datetime = datetime.strptime(
#                     f"{suggested_date} {suggested_end_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#             else:
#                 # ÎÇ†ÏßúÍ∞Ä ÏóÜÏúºÎ©¥ Ïò§ÎäòÎ°ú ÏÑ§Ï†ï
#                 today = datetime.now().date()
#                 start_datetime = datetime.strptime(
#                     f"{today} {suggested_start_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
#                 end_datetime = datetime.strptime(
#                     f"{today} {suggested_end_time}",
#                     '%Y-%m-%d %H:%M'
#                 )
                
#         except (ValueError, TypeError) as e:
#             print(f"DateTime parsing error: {e}")
#             # Í∏∞Î≥∏Í∞íÏúºÎ°ú Ìè¥Î∞±
#             now = datetime.now()
#             start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
#             end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
        
#         # Schedule Í∞ùÏ≤¥ ÏÉùÏÑ±
#         schedule_data = {
#             'user': user,
#             'title': optimized_suggestion.get('title', 'ÏÉà ÏùºÏ†ï'),
#             'description': optimized_suggestion.get('description', 'AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§.'),
#             'start_time': start_datetime,
#             'end_time': end_datetime,
#             'location': optimized_suggestion.get('location', ''),
#             'priority': optimized_suggestion.get('priority', 'MEDIUM'),
#             'attendees': json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
#         }
        
#         schedule = Schedule.objects.create(**schedule_data)
#         serializer = ScheduleSerializer(schedule)
        
#         print(f"Schedule created successfully: {schedule.id}")
        
#         return Response({
#             'message': 'Ïó¨Îü¨ AIÏùò Î∂ÑÏÑùÏùÑ ÌÜµÌï¥ ÏµúÏ†ÅÌôîÎêú ÏùºÏ†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.',
#             'schedule': serializer.data
#         }, status=status.HTTP_201_CREATED)
        
#     except Exception as e:
#         print(f"Confirm schedule error: {str(e)}")
#         import traceback
#         traceback.print_exc()
        
#         return Response({
#             'error': f'ÏùºÏ†ï ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}'
#         }, status=status.HTTP_400_BAD_REQUEST)


# # Alternative solution: Convert to Class-Based View
# class ConfirmScheduleView(APIView):
#     """AI Ï†úÏïàÎêú ÏùºÏ†ïÏùÑ ÌôïÏ†ïÌïòÏó¨ Ïã§Ï†ú ÏùºÏ†ïÏúºÎ°ú ÏÉùÏÑ±"""
#     permission_classes = [AllowAny]  # ÏûÑÏãúÎ°ú AllowAny
    
#     def post(self, request, request_id):
#         try:
#             # ÏÇ¨Ïö©Ïûê Ï≤òÎ¶¨
#             if not request.user.is_authenticated:
#                 return Response({'error': 'Ïù∏Ï¶ùÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.'}, status=status.HTTP_401_UNAUTHORIZED)

#             user = request.user
            
#             # request_idÎ°ú ScheduleRequestÎ•º Ï∞æÍ±∞ÎÇò ÎçîÎØ∏ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
#             try:
#                 schedule_request = ScheduleRequest.objects.get(id=request_id, user=user)
#                 optimized_suggestion = json.loads(schedule_request.optimized_suggestion)
#             except ScheduleRequest.DoesNotExist:
#                 # ÎçîÎØ∏ Î™®Îìú: request_idÎ•º Í∏∞Î∞òÏúºÎ°ú Í∏∞Î≥∏ ÏùºÏ†ï ÏÉùÏÑ±
#                 print(f"ScheduleRequest {request_id} not found, creating dummy schedule")
#                 optimized_suggestion = {
#                     'title': 'AI Ï†úÏïà ÏùºÏ†ï',
#                     'description': 'AIÍ∞Ä Ï†úÏïàÌïú ÏµúÏ†ÅÏùò ÏùºÏ†ïÏûÖÎãàÎã§.',
#                     'suggested_date': datetime.now().strftime('%Y-%m-%d'),
#                     'suggested_start_time': '09:00',
#                     'suggested_end_time': '10:00',
#                     'location': 'ÏÇ¨Î¨¥Ïã§',
#                     'priority': 'MEDIUM',
#                     'attendees': []
#                 }
#             except json.JSONDecodeError as e:
#                 print(f"JSON decode error: {e}")
#                 return Response({
#                     'error': f'ÏùºÏ†ï Îç∞Ïù¥ÌÑ∞ ÌååÏã± Ïò§Î•ò: {str(e)}'
#                 }, status=status.HTTP_400_BAD_REQUEST)
            
#             # ÎÇ†Ïßú/ÏãúÍ∞Ñ ÌååÏã±
#             try:
#                 suggested_date = optimized_suggestion.get('suggested_date')
#                 suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
#                 suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
                
#                 # ÎÇ†Ïßú ÌòïÏãù ÌôïÏù∏ Î∞è Î≥ÄÌôò
#                 if isinstance(suggested_date, str):
#                     if 'T' in suggested_date:  # ISO ÌòïÏãùÏù∏ Í≤ΩÏö∞
#                         suggested_date = suggested_date.split('T')[0]
                    
#                     start_datetime = datetime.strptime(
#                         f"{suggested_date} {suggested_start_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                     end_datetime = datetime.strptime(
#                         f"{suggested_date} {suggested_end_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                 else:
#                     # ÎÇ†ÏßúÍ∞Ä ÏóÜÏúºÎ©¥ Ïò§ÎäòÎ°ú ÏÑ§Ï†ï
#                     today = datetime.now().date()
#                     start_datetime = datetime.strptime(
#                         f"{today} {suggested_start_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
#                     end_datetime = datetime.strptime(
#                         f"{today} {suggested_end_time}",
#                         '%Y-%m-%d %H:%M'
#                     )
                    
#             except (ValueError, TypeError) as e:
#                 print(f"DateTime parsing error: {e}")
#                 # Í∏∞Î≥∏Í∞íÏúºÎ°ú Ìè¥Î∞±
#                 now = datetime.now()
#                 start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
#                 end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
            
#             # Schedule Í∞ùÏ≤¥ ÏÉùÏÑ±
#             schedule_data = {
#                 'user': user,
#                 'title': optimized_suggestion.get('title', 'ÏÉà ÏùºÏ†ï'),
#                 'description': optimized_suggestion.get('description', 'AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§.'),
#                 'start_time': start_datetime,
#                 'end_time': end_datetime,
#                 'location': optimized_suggestion.get('location', ''),
#                 'priority': optimized_suggestion.get('priority', 'MEDIUM'),
#                 'attendees': json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
#             }
            
#             schedule = Schedule.objects.create(**schedule_data)
#             serializer = ScheduleSerializer(schedule)
            
#             print(f"Schedule created successfully: {schedule.id}")
            
#             return Response({
#                 'message': 'Ïó¨Îü¨ AIÏùò Î∂ÑÏÑùÏùÑ ÌÜµÌï¥ ÏµúÏ†ÅÌôîÎêú ÏùºÏ†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.',
#                 'schedule': serializer.data
#             }, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#             print(f"Confirm schedule error: {str(e)}")
#             import traceback
#             traceback.print_exc()
            
#             return Response({
#                 'error': f'ÏùºÏ†ï ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}'
#             }, status=status.HTTP_400_BAD_REQUEST)


# # Fix for resolve_schedule_conflict function
# @api_view(['POST'])
# @permission_classes([IsAuthenticated])  # üîß Í∂åÌïú Î≥ÄÍ≤Ω
# def resolve_schedule_conflict(request):
#     """ÏùºÏ†ï Ï∂©Îèå Ìï¥Í≤∞ Î∞©Ïïà Ï†úÍ≥µ"""
#     # üö´ ÎçîÎØ∏ ÏÇ¨Ïö©Ïûê Î°úÏßÅ Ï†úÍ±∞
#     user = request.user
    
#     conflicting_schedule_ids = request.data.get('conflicting_schedule_ids', [])
#     new_request = request.data.get('new_request', '')
    
#     # ÎÇòÎ®∏ÏßÄ Î°úÏßÅÏùÄ Í∑∏ÎåÄÎ°ú...
    
#     if not conflicting_schedule_ids or not new_request:
#         return Response({
#             'error': 'Ï∂©Îèå ÏùºÏ†ï IDÏôÄ ÏÉàÎ°úÏö¥ ÏöîÏ≤≠Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.'
#         }, status=status.HTTP_400_BAD_REQUEST)
    
#     try:
#         # ÏÇ¨Ïö©Ïûê Ï≤òÎ¶¨
#         if request.user.is_authenticated:
#             user = request.user
#         else:
#             from django.contrib.auth.models import User
#             user, created = User.objects.get_or_create(
#                 username='dummy_user',
#                 defaults={'email': 'dummy@example.com'}
#             )
        
#         # Ï∂©Îèå ÏùºÏ†ïÎì§ Ï°∞Ìöå
#         conflicting_schedules = Schedule.objects.filter(
#             id__in=conflicting_schedule_ids,
#             user=user
#         )
        
#         conflicting_data = [ScheduleSerializer(schedule).data for schedule in conflicting_schedules]
        
#         # Îã§Ï§ë AI Î™®Îç∏Îì§Î°úÎ∂ÄÌÑ∞ Ìï¥Í≤∞ Î∞©Ïïà Î∞õÍ∏∞
#         optimizer = ScheduleOptimizerBot()
#         prompt = optimizer.create_conflict_resolution_prompt(conflicting_data, new_request)
#         suggestions = optimizer.get_ai_suggestions(prompt, "conflict_resolution")
        
#         # AI Î∂ÑÏÑùÏùÑ ÌÜµÌïú ÏµúÏ†Å Ìï¥Í≤∞Î∞©Ïïà ÎèÑÏ∂ú
#         analysis_result = optimizer.analyze_and_optimize_suggestions(
#             suggestions,
#             f"Ï∂©Îèå Ìï¥Í≤∞: {new_request}"
#         )
        
#         # Ìï¥Í≤∞ Î∞©Ïïà Ï†ÄÏû•
#         conflict_resolution = ConflictResolution.objects.create(
#             user=user,
#             conflicting_schedules=json.dumps(conflicting_data, ensure_ascii=False),
#             resolution_options=json.dumps(suggestions, ensure_ascii=False),
#             ai_recommendations=json.dumps(analysis_result, ensure_ascii=False)
#         )
        
#         return Response({
#             'resolution_id': conflict_resolution.id,
#             'conflicting_schedules': conflicting_data,
#             'ai_suggestions': suggestions,
#             'optimized_resolution': analysis_result,
#             'message': f'{len(suggestions)}Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Ï∂©Îèå Ìï¥Í≤∞ Î∞©ÏïàÏù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.'
#         }, status=status.HTTP_201_CREATED)
        
#     except Exception as e:
#         return Response({
#             'error': f'Ï∂©Îèå Ìï¥Í≤∞ Î∞©Ïïà ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}'
#         }, status=status.HTTP_400_BAD_REQUEST)


# # Alternative Class-Based View for conflict resolution
# class ResolveScheduleConflictView(APIView):
#     """ÏùºÏ†ï Ï∂©Îèå Ìï¥Í≤∞ Î∞©Ïïà Ï†úÍ≥µ - Îã§Ï§ë AI Î∂ÑÏÑù"""
#     permission_classes = [IsAuthenticated]
    
#     def post(self, request):
#         conflicting_schedule_ids = request.data.get('conflicting_schedule_ids', [])
#         new_request = request.data.get('new_request', '')
        
#         if not conflicting_schedule_ids or not new_request:
#             return Response({
#                 'error': 'Ï∂©Îèå ÏùºÏ†ï IDÏôÄ ÏÉàÎ°úÏö¥ ÏöîÏ≤≠Ïù¥ ÌïÑÏöîÌï©ÎãàÎã§.'
#             }, status=status.HTTP_400_BAD_REQUEST)
        
#         try:
#             # ÏÇ¨Ïö©Ïûê Ï≤òÎ¶¨
#             if request.user.is_authenticated:
#                 user = request.user
#             else:
#                 from django.contrib.auth.models import User
#                 user, created = User.objects.get_or_create(
#                     username='dummy_user',
#                     defaults={'email': 'dummy@example.com'}
#                 )
            
#             # Ï∂©Îèå ÏùºÏ†ïÎì§ Ï°∞Ìöå
#             conflicting_schedules = Schedule.objects.filter(
#                 id__in=conflicting_schedule_ids,
#                 user=user
#             )
            
#             conflicting_data = [ScheduleSerializer(schedule).data for schedule in conflicting_schedules]
            
#             # Îã§Ï§ë AI Î™®Îç∏Îì§Î°úÎ∂ÄÌÑ∞ Ìï¥Í≤∞ Î∞©Ïïà Î∞õÍ∏∞
#             optimizer = ScheduleOptimizerBot()
#             prompt = optimizer.create_conflict_resolution_prompt(conflicting_data, new_request)
#             suggestions = optimizer.get_ai_suggestions(prompt, "conflict_resolution")
            
#             # AI Î∂ÑÏÑùÏùÑ ÌÜµÌïú ÏµúÏ†Å Ìï¥Í≤∞Î∞©Ïïà ÎèÑÏ∂ú
#             analysis_result = optimizer.analyze_and_optimize_suggestions(
#                 suggestions,
#                 f"Ï∂©Îèå Ìï¥Í≤∞: {new_request}"
#             )
            
#             # Ìï¥Í≤∞ Î∞©Ïïà Ï†ÄÏû•
#             conflict_resolution = ConflictResolution.objects.create(
#                 user=user,
#                 conflicting_schedules=json.dumps(conflicting_data, ensure_ascii=False),
#                 resolution_options=json.dumps(suggestions, ensure_ascii=False),
#                 ai_recommendations=json.dumps(analysis_result, ensure_ascii=False)
#             )
            
#             return Response({
#                 'resolution_id': conflict_resolution.id,
#                 'conflicting_schedules': conflicting_data,
#                 'ai_suggestions': suggestions,
#                 'optimized_resolution': analysis_result,
#                 'message': f'{len(suggestions)}Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Ï∂©Îèå Ìï¥Í≤∞ Î∞©ÏïàÏù¥ ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.'
#             }, status=status.HTTP_201_CREATED)
            
#         except Exception as e:
#             return Response({
#                 'error': f'Ï∂©Îèå Ìï¥Í≤∞ Î∞©Ïïà ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}'
#             }, status=status.HTTP_400_BAD_REQUEST)

from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.decorators import api_view, permission_classes, authentication_classes
from rest_framework.permissions import IsAuthenticated, AllowAny
from rest_framework.authentication import TokenAuthentication, SessionAuthentication
from django.shortcuts import get_object_or_404
from datetime import datetime, timedelta
import json
import re
from .models import Schedule, ScheduleRequest, ConflictResolution
from .serializers import (
    ScheduleSerializer, ScheduleRequestSerializer, 
    ConflictResolutionSerializer, ScheduleRequestInputSerializer
)
import logging
from pytz import timezone
KST = timezone('Asia/Seoul')
target_datetime = datetime.now(KST)
logger = logging.getLogger(__name__)

# Í∏∞Ï°¥ ChatBot ÌÅ¥ÎûòÏä§ÏôÄ API ÌÇ§Îì§ÏùÄ Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ...
OPENAI_API_KEY = "***REMOVED***"
ANTHROPIC_API_KEY = "***REMOVED***"
GROQ_API_KEY = "***REMOVED***"


# üîß ÌÜ†ÌÅ∞ ÎîîÎ≤ÑÍπÖÏùÑ ÏúÑÌïú Ïª§Ïä§ÌÖÄ Ïù∏Ï¶ù ÌÅ¥ÎûòÏä§
class DebugTokenAuthentication(TokenAuthentication):
    """ÎîîÎ≤ÑÍπÖÏù¥ Ìè¨Ìï®Îêú ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÌÅ¥ÎûòÏä§"""
    
    def authenticate(self, request):
        logger.info("=== Í∞úÏÑ†Îêú ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÎîîÎ≤ÑÍπÖ ÏãúÏûë ===")
        
        # Authorization Ìó§Îçî ÌôïÏù∏
        auth_header = request.META.get('HTTP_AUTHORIZATION', '')
        logger.info(f"Authorization Ìó§Îçî: '{auth_header}'")
        
        if not auth_header:
            logger.warning("‚ùå Authorization Ìó§ÎçîÍ∞Ä ÏóÜÏäµÎãàÎã§")
            return None
            
        if not auth_header.startswith('Bearer '):
            logger.warning(f"‚ùå Bearer ÌÜ†ÌÅ∞ ÌòïÏãùÏù¥ ÏïÑÎãôÎãàÎã§: {auth_header}")
            return None
            
        token = auth_header.split(' ')[1]
        logger.info(f"üì± Ï∂îÏ∂úÎêú ÌÜ†ÌÅ∞: {token[:10]}...{token[-10:]}")
        
        # Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÌÜ†ÌÅ∞ ÌôïÏù∏
        try:
            token_obj = Token.objects.select_related('user').get(key=token)
            logger.info(f"‚úÖ DBÏóêÏÑú ÌÜ†ÌÅ∞ Î∞úÍ≤¨: {token_obj.key[:10]}...{token_obj.key[-10:]}")
            logger.info(f"üë§ ÌÜ†ÌÅ∞ ÏÜåÏú†Ïûê: {token_obj.user.username} (ID: {token_obj.user.id})")
            logger.info(f"üîÑ ÏÇ¨Ïö©Ïûê ÌôúÏÑ± ÏÉÅÌÉú: {token_obj.user.is_active}")
            
            if not token_obj.user.is_active:
                logger.warning(f"‚ùå ÏÇ¨Ïö©ÏûêÍ∞Ä ÎπÑÌôúÏÑ±ÌôîÎê®: {token_obj.user.username}")
                raise exceptions.AuthenticationFailed('User inactive or deleted.')
            
            logger.info("‚úÖ ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÏÑ±Í≥µ!")
            logger.info("=== Í∞úÏÑ†Îêú ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÎîîÎ≤ÑÍπÖ Ï¢ÖÎ£å ===")
            return (token_obj.user, token_obj)
            
        except Token.DoesNotExist:
            logger.error(f"‚ùå DBÏóê Ìï¥Îãπ ÌÜ†ÌÅ∞Ïù¥ Ï°¥Ïû¨ÌïòÏßÄ ÏïäÏùå: {token[:10]}...{token[-10:]}")
            
            # Î™®Îì† ÌÜ†ÌÅ∞ Î™©Î°ù Ï∂úÎ†• (ÎîîÎ≤ÑÍπÖÏö©)
            all_tokens = Token.objects.all()[:5]  # Ï≤òÏùå 5Í∞úÎßå
            logger.info(f"üóÉÔ∏è DBÏùò Í∏∞Ï°¥ ÌÜ†ÌÅ∞Îì§:")
            for i, t in enumerate(all_tokens):
                logger.info(f"  {i+1}. {t.key[:10]}...{t.key[-10:]} (ÏÇ¨Ïö©Ïûê: {t.user.username})")
            
            logger.info("=== Í∞úÏÑ†Îêú ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÎîîÎ≤ÑÍπÖ Ï¢ÖÎ£å ===")
            raise exceptions.AuthenticationFailed('Invalid token.')
        
        except Exception as e:
            logger.error(f"‚ùå ÏòàÏÉÅÏπò Î™ªÌïú Ïò§Î•ò: {str(e)}")
            logger.info("=== Í∞úÏÑ†Îêú ÌÜ†ÌÅ∞ Ïù∏Ï¶ù ÎîîÎ≤ÑÍπÖ Ï¢ÖÎ£å ===")
            raise exceptions.AuthenticationFailed('Authentication error.')


# üîß ÏùºÏ†ï Í¥ÄÎ¶¨ Î∑∞ - Ïù∏Ï¶ù Î¨∏Ï†ú Ìï¥Í≤∞
class ScheduleManagementView(APIView):
    """ÏùºÏ†ï Í¥ÄÎ¶¨ Î©îÏù∏ Î∑∞ - ÌÜ†ÌÅ∞ Ïù∏Ï¶ù Ï†ÅÏö©"""
    authentication_classes = [DebugTokenAuthentication, SessionAuthentication]
    permission_classes = [IsAuthenticated]
    
    def __init__(self):
        super().__init__()
        # ScheduleOptimizerBot Ï¥àÍ∏∞ÌôîÎäî Î©îÏÑúÎìú ÎÇ¥ÏóêÏÑú ÏàòÌñâ
    
    def get_optimizer(self):
        """ÌïÑÏöîÌï† ÎïåÎßå optimizer Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±"""
        if not hasattr(self, '_optimizer'):
            self._optimizer = ScheduleOptimizerBot()
        return self._optimizer
    
    def get(self, request):
        """ÏÇ¨Ïö©ÏûêÏùò ÏùºÏ†ï Î™©Î°ù Ï°∞Ìöå"""
        logger.info(f"ÏùºÏ†ï Ï°∞Ìöå ÏöîÏ≤≠ - ÏÇ¨Ïö©Ïûê: {request.user.username if request.user.is_authenticated else 'Anonymous'}")
        
        try:
            schedules = Schedule.objects.filter(user=request.user).order_by('start_time')
            
            # ÎÇ†Ïßú ÌïÑÌÑ∞ÎßÅ
            start_date = request.query_params.get('start_date')
            end_date = request.query_params.get('end_date')
            
            if start_date:
                schedules = schedules.filter(start_time__date__gte=start_date)
            if end_date:
                schedules = schedules.filter(end_time__date__lte=end_date)
            
            serializer = ScheduleSerializer(schedules, many=True)
            logger.info(f"ÏùºÏ†ï Ï°∞Ìöå ÏÑ±Í≥µ: {len(serializer.data)}Í∞ú ÏùºÏ†ï Î∞òÌôò")
            return Response(serializer.data)
            
        except Exception as e:
            logger.error(f"ÏùºÏ†ï Ï°∞Ìöå Ïã§Ìå®: {str(e)}")
            return Response(
                {'error': f'ÏùºÏ†ï Ï°∞Ìöå Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}'}, 
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )
    def _get_ai_generated_title(self, prompt):
        """AIÎ•º ÌÜµÌï¥ ÏùºÏ†ï Ï†úÎ™© ÏÉùÏÑ±"""
        try:
            optimizer = self.get_optimizer()
            suggestions = optimizer.get_ai_suggestions(prompt, "title")
            
            # Ï≤´ Î≤àÏß∏ ÏùëÎãµÏóêÏÑú Ï†úÎ™© Ï∂îÏ∂ú
            for key, response in suggestions.items():
                if response and len(response.strip()) > 0:
                    # Í∞ÑÎã®Ìïú Ï†úÎ™©Îßå Ï∂îÏ∂ú (Ï≤´ Ï§ÑÎßå)
                    title = response.strip().split('\n')[0]
                    # Îî∞Ïò¥Ìëú Ï†úÍ±∞
                    title = title.strip('"\'')
                    if len(title) > 0 and len(title) < 50:  # Ï†ÅÏ†àÌïú Í∏∏Ïù¥ ÌôïÏù∏
                        return title
            
            return None
        except Exception as e:
            logger.warning(f"AI Ï†úÎ™© ÏÉùÏÑ± Ïã§Ìå®: {str(e)}")
            return None
    
    def post(self, request):
        """ÏÉàÎ°úÏö¥ ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠"""
        logger.info(f"ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ - ÏÇ¨Ïö©Ïûê: {request.user.username}")
        
        try:
            request_text = request.data.get('request_text', '')
            existing_schedules = request.data.get('existing_schedules', [])
            
            if not request_text:
                return Response({'error': 'ÏöîÏ≤≠ ÌÖçÏä§Ìä∏Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.'}, 
                            status=status.HTTP_400_BAD_REQUEST)
            
            user = request.user
            
            # Ïó¨Îü¨ ÏùºÏ†ï ÏöîÏ≤≠Ïù∏ÏßÄ ÌôïÏù∏
            schedule_requests = parse_multiple_schedules_backend(request_text)
            target_date = parse_date_from_request(request_text)
            
            logger.info(f"ÌååÏã±Îêú ÏùºÏ†ï ÏöîÏ≤≠: {len(schedule_requests)}Í∞ú")
            logger.info(f"üìå KST Í∏∞Ï§Ä Î™©Ìëú ÎÇ†Ïßú: {target_date} (ÏöîÏ≤≠ ÌÖçÏä§Ìä∏: '{request_text}')")

            
            if len(schedule_requests) > 1:
                # Ïó¨Îü¨ ÏùºÏ†ï Ï≤òÎ¶¨
                multiple_schedules = []
                all_individual_suggestions = []
                
                def extract_time_info(text):
                    import re
                    start_hour = None
                    duration_hours = 1

                    is_pm = 'Ïò§ÌõÑ' in text
                    is_am = 'Ïò§Ï†Ñ' in text

                    # üîç "Ïò§ÌõÑ 3-5Ïãú"ÏôÄ Í∞ôÏùÄ Í≤ΩÏö∞ Ï≤òÎ¶¨
                    time_range = re.search(r'(\d{1,2})\s*[-~]\s*(\d{1,2})\s*Ïãú', text)
                    if time_range:
                        start = int(time_range.group(1))
                        end = int(time_range.group(2))

                        if is_pm:
                            if start < 12:
                                start += 12
                            if end < 12:
                                end += 12
                        elif is_am:
                            if start == 12:
                                start = 0
                            if end == 12:
                                end = 0

                        start_hour = start
                        duration_hours = end - start
                        return start_hour, duration_hours

                    # üîç "2ÏãúÍ∞Ñ"Îßå ÏûàÎäî Í≤ΩÏö∞
                    dur_match = re.search(r'(\d{1,2})\s*ÏãúÍ∞Ñ', text)
                    if dur_match:
                        duration_hours = int(dur_match.group(1))

                    # üîç Îã®Ïùº ÏãúÍ∞Å: "Ïò§ÌõÑ 3Ïãú"
                    single_time_match = re.search(r'(Ïò§Ï†Ñ|Ïò§ÌõÑ)?\s*(\d{1,2})\s*Ïãú', text)
                    if single_time_match:
                        hour = int(single_time_match.group(2))
                        if single_time_match.group(1) == 'Ïò§ÌõÑ' and hour < 12:
                            hour += 12
                        elif single_time_match.group(1) == 'Ïò§Ï†Ñ' and hour == 12:
                            hour = 0
                        start_hour = hour

                    return start_hour, duration_hours

                def find_non_conflicting_time(existing_schedules, start_hour, duration_hours, date):
                    """
                    Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Í≤πÏπòÏßÄ ÏïäÎäî ÏãúÍ∞ÑÎåÄÎ•º ÌÉêÏÉâÌï©ÎãàÎã§.
                    """
                    from datetime import datetime, timedelta, time

                    def is_conflicting(new_start, new_end, schedules):
                        for s in schedules:
                            s_start = datetime.strptime(s['start_time'], '%Y-%m-%dT%H:%M:%S')
                            s_end = datetime.strptime(s['end_time'], '%Y-%m-%dT%H:%M:%S')
                            if not (new_end <= s_start or new_start >= s_end):
                                return True
                        return False

                    attempt = 0
                    max_attempts = 10
                    while attempt < max_attempts:
                        candidate_start = datetime.combine(date, time(start_hour))
                        candidate_end = candidate_start + timedelta(hours=duration_hours)
                        if not is_conflicting(candidate_start, candidate_end, existing_schedules):
                            return candidate_start, candidate_end
                        start_hour += 1
                        attempt += 1

                    # fallback
                    return datetime.combine(date, time(start_hour)), datetime.combine(date, time(start_hour + duration_hours))



                # ÏùºÏ†ï Î£®ÌîÑ ÏàòÏ†ï
                for i, single_request in enumerate(schedule_requests):
                    title_prompt = f"""Îã§Ïùå ÏùºÏ†ï ÏöîÏ≤≠ÏóêÏÑú Ï†ÅÏ†àÌïú ÏùºÏ†ï Ï†úÎ™©ÏùÑ Ìïú Ï§ÑÎ°ú ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî: {single_request}
                    Î∂ÑÏÑù Î∞©Î≤ï:
                    1. Í∏∞Ï°¥ ÏùºÏ†ïÎì§Ïùò ÏãúÍ∞ÑÎåÄÎ•º ÌôïÏù∏ÌïòÏó¨ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÏãúÍ∞ÑÏóê ÏùºÏ†ïÏù¥ ÏóÜÎã§Î©¥, ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÏùºÏ†ïÏùÑ Ï∂îÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî.
                    2. ÏöîÏ≤≠Îêú ÏùºÏ†ïÏùò ÏÑ±Í≤©Ïóê ÎßûÎäî ÏµúÏ†ÅÏùò ÏãúÍ∞ÑÎåÄÎ•º Ï∂îÏ≤úÌï¥Ï£ºÏÑ∏Ïöî
                    3. ÏùºÏ†ï Í∞Ñ Ïó¨Ïú† ÏãúÍ∞ÑÎèÑ Í≥†Î†§Ìï¥Ï£ºÏÑ∏Ïöî
                    4. ÎêòÎèÑÎ°ùÏù¥Î©¥ ÏÉàÎ≤ΩÏãúÍ∞ÑÏùÄ ÌîºÌï¥Ï£ºÏÑ∏Ïöî.
                    5. ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏãúÍ∞ÑÏù¥ ÏûàÎã§Î©¥, Í∑∏ ÏãúÍ∞ÑÏúºÎ°ú Î∞∞Ï†ïÌï¥Ï£ºÏÑ∏Ïöî. Îã®, Í∑∏ ÏãúÍ∞ÑÏóê Ïù¥ÎØ∏ ÏùºÏ†ïÏù¥ ÏûàÎã§Î©¥ Îã§Î•∏ ÏãúÍ∞ÑÏùÑ Î∞∞Ï†ïÌïòÍ≥† ÏùºÏ†ïÏù¥ ÏûàÏùåÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî
                    """
                    ai_title = self._get_ai_generated_title(title_prompt) or "ÏÉà ÏùºÏ†ï"

                    # ÏãúÍ∞Ñ Ï†ïÎ≥¥ Ï∂îÏ∂ú
                    parsed_start, parsed_duration = extract_time_info(single_request)

                    if parsed_start is not None:
                        start_hour = parsed_start
                    else:
                        start_hour = 9 + i * 2  # Í∏∞Î≥∏Í∞í fallback

                    duration_hours = parsed_duration or 1

                    existing = request.data.get("existing_schedules", [])
                    schedule_start_dt, schedule_end_dt = find_non_conflicting_time(existing, start_hour, duration_hours, target_date)

                    optimized_schedule = {
                        "title": ai_title,
                        "description": f"AIÍ∞Ä Î∂ÑÏÑùÌïú {self._extract_schedule_title(single_request)} ÏùºÏ†ïÏûÖÎãàÎã§.",
                        "suggested_date": target_datetime.strftime('%Y-%m-%d'),
                        "suggested_start_time": schedule_start_dt.strftime('%H:%M'),
                        "suggested_end_time": schedule_end_dt.strftime('%H:%M'),
                        "location": self._extract_schedule_location(single_request),
                        "priority": "HIGH",
                        "attendees": [],
                        "reasoning": f"{i + 1}Î≤àÏß∏ ÏùºÏ†ï: {single_request}. Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏãúÍ∞ÑÏúºÎ°ú Î∞∞Ï†ïÌñàÏäµÎãàÎã§."
                    }

                
                # for i, single_request in enumerate(schedule_requests):
                #     # Í∞Å ÏùºÏ†ïÏùò ÏãúÏûë ÏãúÍ∞ÑÏùÑ Îã§Î•¥Í≤å ÏÑ§Ï†ï
                #     base_hour = 9 + (i * 2)

                #     title_prompt = f"Îã§Ïùå ÏùºÏ†ï ÏöîÏ≤≠ÏóêÏÑú Ï†ÅÏ†àÌïú ÏùºÏ†ï Ï†úÎ™©ÏùÑ Ìïú Ï§ÑÎ°ú ÏÉùÏÑ±Ìï¥Ï£ºÏÑ∏Ïöî: {single_request}"
                #     ai_title = self._get_ai_generated_title(title_prompt) or "ÏÉà ÏùºÏ†ï"
                    
                #     optimized_schedule = {
                #         "title": ai_title,  # ‚úÖ AIÍ∞Ä ÏÉùÏÑ±Ìïú Ï†úÎ™© ÏÇ¨Ïö©
                #         "description": f"AIÍ∞Ä Î∂ÑÏÑùÌïú {self._extract_schedule_title(single_request)} ÏùºÏ†ïÏûÖÎãàÎã§.",
                #         "suggested_date": target_date.strftime('%Y-%m-%d'),
                #         "suggested_start_time": f"{base_hour:02d}:00",
                #         "suggested_end_time": f"{base_hour + 2:02d}:00",
                #         "location": self._extract_schedule_location(single_request),
                #         "priority": "HIGH",
                #         "attendees": [],
                #         "reasoning": f"{i + 1}Î≤àÏß∏ ÏùºÏ†ï: {single_request}. Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏãúÍ∞ÑÏúºÎ°ú Î∞∞Ï†ïÌñàÏäµÎãàÎã§."
                #     }
                    multiple_schedules.append(optimized_schedule)
                    existing_schedules.append({
    'start_time': schedule_start_dt.isoformat(),
    'end_time': schedule_end_dt.isoformat()
})
                    
                    # Í∞Å AIÎ≥Ñ Í∞úÎ≥Ñ Ï†úÏïà ÏÉùÏÑ±
                    for ai_type in ['gpt', 'claude', 'mixtral']:
                        individual_suggestion = optimized_schedule.copy()
                        individual_suggestion['source'] = ai_type
                        individual_suggestion['reasoning'] = f"{ai_type.upper()}Í∞Ä Î∂ÑÏÑùÌïú {self._extract_schedule_title(single_request)} ÏµúÏ†Å ÏãúÍ∞ÑÏûÖÎãàÎã§."
                        all_individual_suggestions.append(individual_suggestion)
                
                response_data = {
                    'request_id': int(datetime.now().timestamp()),
                    'multiple_schedules': multiple_schedules,
                    'optimized_suggestion': multiple_schedules[0],
                    'confidence_score': 0.92,
                    'individual_suggestions': all_individual_suggestions,
                    'ai_analysis': {
                        'analysis_summary': f"Ï¥ù {len(schedule_requests)}Í∞úÏùò ÏùºÏ†ïÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏµúÏ†ÅÏùò ÏãúÍ∞ÑÎåÄÎ°ú Î∞∞Ï†ïÌñàÏäµÎãàÎã§.",
                        'reasoning': f"Ïó¨Îü¨ ÏùºÏ†ïÏùÑ {target_date.strftime('%YÎÖÑ %mÏõî %dÏùº')}Ïóê ÏãúÍ∞Ñ ÏàúÏÑúÎåÄÎ°ú Î∞∞ÏπòÌïòÏó¨ Ï∂©ÎèåÏùÑ Î∞©ÏßÄÌñàÏäµÎãàÎã§.",
                        'models_used': ["gpt", "claude", "mixtral"]
                    },
                    'has_conflicts': False,
                    'conflicts': [],
                    'analysis_summary': f"{len(schedule_requests)}Í∞ú ÏùºÏ†ïÏóê ÎåÄÌï¥ 3Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.",
                    'is_multiple_schedule': True
                }
                
            else:
                # Îã®Ïùº ÏùºÏ†ï Ï≤òÎ¶¨
                optimizer = self.get_optimizer()
                user_context = self._get_user_context(user)
                
                enhanced_prompt = f"""
                ÏÇ¨Ïö©ÏûêÏùò ÏùºÏ†ï ÏöîÏ≤≠ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Í∏∞Ï°¥ ÏùºÏ†ïÍ≥º Ï∂©ÎèåÌïòÏßÄ ÏïäÎäî ÏµúÏ†ÅÏùò Îπà ÏãúÍ∞ÑÏùÑ Ï∞æÏïÑ Ï†úÏïàÌï¥Ï£ºÏÑ∏Ïöî.
                ÎßåÏïΩ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏãúÍ∞ÑÏù¥ ÏûàÎã§Î©¥, Í∑∏ ÏãúÍ∞ÑÏóê ÏùºÏ†ïÏùÑ ÎÑ£Ïñ¥Ï£ºÏÑ∏Ïöî.
                
                ÏöîÏ≤≠ ÎÇ¥Ïö©: {request_text}
                Î™©Ìëú ÎÇ†Ïßú: {target_date.strftime('%YÎÖÑ %mÏõî %dÏùº')} ({self._get_weekday_korean(target_date)})
                Í∏∞Ï°¥ ÏùºÏ†ïÎì§: {existing_schedules or []}
                Î∂ÑÏÑù Î∞©Î≤ï:
                1. Í∏∞Ï°¥ ÏùºÏ†ïÎì§Ïùò ÏãúÍ∞ÑÎåÄÎ•º ÌôïÏù∏ÌïòÏó¨ ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÏãúÍ∞ÑÏóê ÏùºÏ†ïÏù¥ ÏóÜÎã§Î©¥, ÏÇ¨Ïö©ÏûêÍ∞Ä ÏûÖÎ†•Ìïú ÏùºÏ†ïÏùÑ Ï∂îÍ∞ÄÌï¥Ï£ºÏÑ∏Ïöî.
                2. ÏöîÏ≤≠Îêú ÏùºÏ†ïÏùò ÏÑ±Í≤©Ïóê ÎßûÎäî ÏµúÏ†ÅÏùò ÏãúÍ∞ÑÎåÄÎ•º Ï∂îÏ≤úÌï¥Ï£ºÏÑ∏Ïöî
                3. ÏùºÏ†ï Í∞Ñ Ïó¨Ïú† ÏãúÍ∞ÑÎèÑ Í≥†Î†§Ìï¥Ï£ºÏÑ∏Ïöî
                4. ÏÉàÎ≤ΩÏãúÍ∞ÑÏùÄ ÌîºÌï¥Ï£ºÏÑ∏Ïöî.
                5. ÏÇ¨Ïö©ÏûêÍ∞Ä ÏßÄÏ†ïÌïú ÏãúÍ∞ÑÏù¥ ÏûàÎã§Î©¥, Í∑∏ ÏãúÍ∞ÑÏúºÎ°ú Î∞∞Ï†ïÌï¥Ï£ºÏÑ∏Ïöî. Îã®, Í∑∏ ÏãúÍ∞ÑÏóê Ïù¥ÎØ∏ ÏùºÏ†ïÏù¥ ÏûàÎã§Î©¥ Îã§Î•∏ ÏãúÍ∞ÑÏùÑ Î∞∞Ï†ïÌïòÍ≥† ÏùºÏ†ïÏù¥ ÏûàÏùåÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî


                
                Îã§Ïùå ÌòïÏãùÏúºÎ°ú ÏùëÎãµÌï¥Ï£ºÏÑ∏Ïöî:
                {{
                    "title": "ÏöîÏ≤≠ ÎÇ¥Ïö©Ïóê ÎßûÎäî Íµ¨Ï≤¥Ï†ÅÏù¥Í≥† ÏùòÎØ∏ÏûàÎäî ÏùºÏ†ï Ï†úÎ™©ÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî", 
                    "description": "ÏÉÅÏÑ∏ ÏÑ§Î™Ö",
                    "suggested_date": "%Y-%m-%d",
                    "suggested_start_time": "HH:MM",
                    "suggested_end_time": "HH:MM",
                    "location": "Ïû•ÏÜå",
                    "priority": "HIGH/MEDIUM/LOW/URGENT",
                    "attendees": [],
                    "reasoning": "Ïù¥ ÏãúÍ∞ÑÏùÑ Ï†úÏïàÌïòÎäî Ïù¥Ïú†"
                }}
                """
                
                suggestions = optimizer.get_ai_suggestions(enhanced_prompt)
                optimized_result = optimizer.analyze_and_optimize_suggestions(
                    suggestions, f"ÏùºÏ†ï ÏöîÏ≤≠: {request_text}"
                )
                
                response_data = {
                    'request_id': int(datetime.now().timestamp()),
                    'optimized_suggestion': optimized_result.get('optimized_suggestion', {}),
                    'confidence_score': optimized_result.get('confidence_score', 0.0),
                    'ai_analysis': optimized_result.get('ai_analysis', {}),
                    'individual_suggestions': optimized_result.get('individual_suggestions', []),
                    'has_conflicts': False,
                    'conflicts': [],
                    'analysis_summary': "3Í∞ú AI Î™®Îç∏Ïù¥ Î∂ÑÏÑùÌïú Í≤∞Í≥ºÏûÖÎãàÎã§.",
                    'is_multiple_schedule': False
                }
            
            logger.info("ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ Ï≤òÎ¶¨ ÏôÑÎ£å")
            return Response(response_data, status=status.HTTP_201_CREATED)
            
        except Exception as e:
            logger.error(f"ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ Ï≤òÎ¶¨ Ïã§Ìå®: {str(e)}")
            return Response({
                'error': f'ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _get_user_context(self, user):
        """ÏÇ¨Ïö©Ïûê Ïª®ÌÖçÏä§Ìä∏ Ï†ïÎ≥¥ ÏÉùÏÑ±"""
        return {
            'username': user.username,
            'timezone': 'Asia/Seoul',  # Í∏∞Î≥∏ ÌÉÄÏûÑÏ°¥
            'preferences': {}
        }
    
    def _extract_schedule_title(self, request):
        """ÏöîÏ≤≠ÏóêÏÑú ÏùºÏ†ï Ï†úÎ™© Ï∂îÏ∂ú"""
        if 'Ïö¥Îèô' in request:
            return 'Ïö¥Îèô'
        elif 'ÎØ∏ÌåÖ' in request or 'ÌöåÏùò' in request:
            return 'ÌåÄ ÎØ∏ÌåÖ'
        elif 'Í≥µÎ∂Ä' in request or 'ÌïôÏäµ' in request:
            return 'ÌïôÏäµ ÏãúÍ∞Ñ'
        elif 'ÏûëÏóÖ' in request or 'ÏóÖÎ¨¥' in request:
            return 'ÏßëÏ§ë ÏûëÏóÖ'
        elif 'ÏïΩÏÜç' in request:
            return 'ÏïΩÏÜç'
        else:
            return 'ÏÉà ÏùºÏ†ï'

    def _extract_schedule_location(self, request):
        """ÏöîÏ≤≠ÏóêÏÑú Ïû•ÏÜå Ï∂îÏ∂ú"""
        if 'Ïö¥Îèô' in request:
            return 'Ìó¨Ïä§Ïû•'
        elif 'ÎØ∏ÌåÖ' in request or 'ÌöåÏùò' in request:
            return 'ÌöåÏùòÏã§'
        elif 'Í≥µÎ∂Ä' in request or 'ÌïôÏäµ' in request:
            return 'ÎèÑÏÑúÍ¥Ä'
        elif 'Ïª§Ìîº' in request:
            return 'Ïπ¥Ìéò'
        else:
            return 'ÏÇ¨Î¨¥Ïã§'

    def _get_weekday_korean(self, date):
        """ÏöîÏùºÏùÑ ÌïúÍµ≠Ïñ¥Î°ú Î∞òÌôò"""
        weekdays = ['ÏõîÏöîÏùº', 'ÌôîÏöîÏùº', 'ÏàòÏöîÏùº', 'Î™©ÏöîÏùº', 'Í∏àÏöîÏùº', 'ÌÜ†ÏöîÏùº', 'ÏùºÏöîÏùº']
        return weekdays[date.weekday()]

@api_view(['POST'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def confirm_schedule(request, request_id):
    """AI Ï†úÏïàÎêú ÏùºÏ†ïÏùÑ ÌôïÏ†ïÌïòÏó¨ Ïã§Ï†ú ÏùºÏ†ïÏúºÎ°ú ÏÉùÏÑ±"""
    logger.info(f"ÏùºÏ†ï ÌôïÏ†ï ÏöîÏ≤≠ - ÏÇ¨Ïö©Ïûê: {request.user.username}, request_id: {request_id}")
    
    try:
        user = request.user
        
        # ‚úÖ ÌîÑÎ°†Ìä∏ÏóîÎìúÏóêÏÑú Ï†ÑÏÜ°Îêú Ïã§Ï†ú AI Ï†úÏïà Îç∞Ïù¥ÌÑ∞ ÏÇ¨Ïö©
        ai_suggestion_data = request.data.get('ai_suggestion')
        if not ai_suggestion_data:
            return Response({
                'error': 'AI Ï†úÏïà Îç∞Ïù¥ÌÑ∞Í∞Ä ÌïÑÏöîÌï©ÎãàÎã§.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # Ïó¨Îü¨ ÏùºÏ†ïÏù∏ÏßÄ Îã®Ïùº ÏùºÏ†ïÏù∏ÏßÄ ÌôïÏù∏
        is_multiple = ai_suggestion_data.get('is_multiple_schedule', False)
        
        if is_multiple and ai_suggestion_data.get('multiple_schedules'):
            # Ïó¨Îü¨ ÏùºÏ†ï Ï≤òÎ¶¨
            created_schedules = []
            
            for schedule_data in ai_suggestion_data['multiple_schedules']:
                try:
                    # ÎÇ†Ïßú/ÏãúÍ∞Ñ ÌååÏã±
                    suggested_date = schedule_data.get('suggested_date')
                    suggested_start_time = schedule_data.get('suggested_start_time', '09:00')
                    suggested_end_time = schedule_data.get('suggested_end_time', '10:00')
                    
                    start_datetime = datetime.strptime(
                        f"{suggested_date} {suggested_start_time}",
                        '%Y-%m-%d %H:%M'
                    )
                    end_datetime = datetime.strptime(
                        f"{suggested_date} {suggested_end_time}",
                        '%Y-%m-%d %H:%M'
                    )
                    
                    # Schedule Í∞ùÏ≤¥ ÏÉùÏÑ±
                    schedule = Schedule.objects.create(
                        user=user,
                        title=schedule_data.get('title', 'ÏÉà ÏùºÏ†ï'),
                        description=schedule_data.get('description', 'AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§.'),
                        start_time=start_datetime,
                        end_time=end_datetime,
                        location=schedule_data.get('location', ''),
                        priority=schedule_data.get('priority', 'MEDIUM'),
                        attendees=json.dumps(schedule_data.get('attendees', []), ensure_ascii=False)
                    )
                    
                    created_schedules.append(schedule)
                    logger.info(f"Îã§Ï§ë ÏùºÏ†ï ÏÉùÏÑ± ÏÑ±Í≥µ: {schedule.id} - {schedule.title}")
                    
                except Exception as e:
                    logger.error(f"Í∞úÎ≥Ñ ÏùºÏ†ï ÏÉùÏÑ± Ïã§Ìå®: {str(e)}")
                    continue
            
            if created_schedules:
                serializer = ScheduleSerializer(created_schedules, many=True)
                return Response({
                    'message': f'{len(created_schedules)}Í∞úÏùò ÏùºÏ†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.',
                    'schedules': serializer.data
                }, status=status.HTTP_201_CREATED)
            else:
                return Response({
                    'error': 'ÏùºÏ†ï ÏÉùÏÑ±Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.'
                }, status=status.HTTP_400_BAD_REQUEST)
        
        else:
            # Îã®Ïùº ÏùºÏ†ï Ï≤òÎ¶¨
            optimized_suggestion = ai_suggestion_data.get('optimized_suggestion')
            if not optimized_suggestion:
                return Response({
                    'error': 'ÏµúÏ†ÅÌôîÎêú Ï†úÏïà Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ÎÇ†Ïßú/ÏãúÍ∞Ñ ÌååÏã±
            try:
                suggested_date = optimized_suggestion.get('suggested_date')
                suggested_start_time = optimized_suggestion.get('suggested_start_time', '09:00')
                suggested_end_time = optimized_suggestion.get('suggested_end_time', '10:00')
                
                if 'T' in suggested_date:
                    suggested_date = suggested_date.split('T')[0]
                
                start_datetime = datetime.strptime(
                    f"{suggested_date} {suggested_start_time}",
                    '%Y-%m-%d %H:%M'
                )
                end_datetime = datetime.strptime(
                    f"{suggested_date} {suggested_end_time}",
                    '%Y-%m-%d %H:%M'
                )
                
            except (ValueError, TypeError) as e:
                logger.error(f"DateTime parsing error: {e}")
                now = datetime.now()
                start_datetime = now.replace(hour=9, minute=0, second=0, microsecond=0)
                end_datetime = now.replace(hour=10, minute=0, second=0, microsecond=0)
            
            # Schedule Í∞ùÏ≤¥ ÏÉùÏÑ±
            schedule = Schedule.objects.create(
                user=user,
                title=optimized_suggestion.get('title', 'ÏÉà ÏùºÏ†ï'),
                description=optimized_suggestion.get('description', 'AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§.'),
                start_time=start_datetime,
                end_time=end_datetime,
                location=optimized_suggestion.get('location', ''),
                priority=optimized_suggestion.get('priority', 'MEDIUM'),
                attendees=json.dumps(optimized_suggestion.get('attendees', []), ensure_ascii=False)
            )
            
            serializer = ScheduleSerializer(schedule)
            logger.info(f"Îã®Ïùº ÏùºÏ†ï ÏÉùÏÑ± ÏÑ±Í≥µ: {schedule.id} - {schedule.title}")
            
            return Response({
                'message': 'AIÏùò Î∂ÑÏÑùÏùÑ ÌÜµÌï¥ ÏµúÏ†ÅÌôîÎêú ÏùºÏ†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.',
                'schedule': serializer.data
            }, status=status.HTTP_201_CREATED)
            
    except Exception as e:
        logger.error(f"ÏùºÏ†ï ÌôïÏ†ï Ïã§Ìå®: {str(e)}")
        return Response({
            'error': f'ÏùºÏ†ï ÏÉùÏÑ± Ï§ë Ïò§Î•òÍ∞Ä Î∞úÏÉùÌñàÏäµÎãàÎã§: {str(e)}'
        }, status=status.HTTP_400_BAD_REQUEST)
# üîß ÏàòÎèô ÏùºÏ†ï ÏÉùÏÑ± Î∑∞
@api_view(['POST'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def create_manual_schedule(request):
    """ÏàòÎèôÏúºÎ°ú ÏùºÏ†ï ÏÉùÏÑ±"""
    logger.info(f"ÏàòÎèô ÏùºÏ†ï ÏÉùÏÑ± ÏöîÏ≤≠ - ÏÇ¨Ïö©Ïûê: {request.user.username}")
    
    try:
        data = request.data.copy()
        data['user'] = request.user.id
        
        serializer = ScheduleSerializer(data=data)
        if serializer.is_valid():
            schedule = serializer.save(user=request.user)
            logger.info(f"ÏàòÎèô ÏùºÏ†ï ÏÉùÏÑ± ÏÑ±Í≥µ: {schedule.id}")
            return Response(serializer.data, status=status.HTTP_201_CREATED)
        else:
            logger.warning(f"ÏàòÎèô ÏùºÏ†ï ÏÉùÏÑ± Ïã§Ìå® - Ïú†Ìö®ÏÑ± Í≤ÄÏ¶ù Ïò§Î•ò: {serializer.errors}")
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
            
    except Exception as e:
        logger.error(f"ÏàòÎèô ÏùºÏ†ï ÏÉùÏÑ± Ïã§Ìå®: {str(e)}")
        return Response({
            'error': f'ÏùºÏ†ï ÏÉùÏÑ± Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# üîß ÏùºÏ†ï ÏàòÏ†ï/ÏÇ≠Ï†ú Î∑∞
@api_view(['PUT', 'DELETE'])
@authentication_classes([DebugTokenAuthentication, SessionAuthentication])
@permission_classes([IsAuthenticated])
def manage_schedule(request, schedule_id):
    """ÏùºÏ†ï ÏàòÏ†ï ÎòêÎäî ÏÇ≠Ï†ú"""
    try:
        schedule = get_object_or_404(Schedule, id=schedule_id, user=request.user)
        
        if request.method == 'PUT':
            # ÏùºÏ†ï ÏàòÏ†ï
            serializer = ScheduleSerializer(schedule, data=request.data, partial=True)
            if serializer.is_valid():
                serializer.save()
                logger.info(f"ÏùºÏ†ï ÏàòÏ†ï ÏÑ±Í≥µ: {schedule_id}")
                return Response(serializer.data)
            else:
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
        
        elif request.method == 'DELETE':
            # ÏùºÏ†ï ÏÇ≠Ï†ú
            schedule.delete()
            logger.info(f"ÏùºÏ†ï ÏÇ≠Ï†ú ÏÑ±Í≥µ: {schedule_id}")
            return Response({'message': 'ÏùºÏ†ïÏù¥ ÏÑ±Í≥µÏ†ÅÏúºÎ°ú ÏÇ≠Ï†úÎêòÏóàÏäµÎãàÎã§.'}, 
                          status=status.HTTP_204_NO_CONTENT)
            
    except Exception as e:
        logger.error(f"ÏùºÏ†ï Í¥ÄÎ¶¨ Ïã§Ìå®: {str(e)}")
        return Response({
            'error': f'ÏùºÏ†ï Í¥ÄÎ¶¨ Ï§ë Ïò§Î•ò Î∞úÏÉù: {str(e)}'
        }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

# Ïú†Ìã∏Î¶¨Ìã∞ Ìï®ÏàòÎì§

from pytz import timezone

def parse_date_from_request(request_text):
    korea_now = datetime.now(timezone('Asia/Seoul')).date()

    if 'Ïò§Îäò' in request_text:
        return korea_now
    elif 'ÎÇ¥Ïùº' in request_text:
        return korea_now + timedelta(days=1)
    elif 'Î™®Î†à' in request_text or 'Î™®Îûò' in request_text:
        return korea_now + timedelta(days=2)
    elif 'Ïù¥Î≤à Ï£º' in request_text:
        days_until_friday = (4 - korea_now.weekday()) % 7
        days_until_friday = 7 if days_until_friday == 0 else days_until_friday
        return korea_now + timedelta(days=days_until_friday)
    elif 'Îã§Ïùå Ï£º' in request_text:
        return korea_now + timedelta(days=7)
    else:
        return korea_now + timedelta(days=1)

def parse_multiple_schedules_backend(request_text):
    """Î∞±ÏóîÎìúÏóêÏÑú Ïó¨Îü¨ ÏùºÏ†ï ÌååÏã±"""
    separators = [',', 'Ôºå', 'Í∑∏Î¶¨Í≥†', 'Î∞è', 'ÏôÄ', 'Í≥º']
    
    parts = [request_text]
    for sep in separators:
        new_parts = []
        for part in parts:
            new_parts.extend(part.split(sep))
        parts = new_parts
    
    cleaned_requests = []
    for part in parts:
        cleaned = part.strip()
        if cleaned and len(cleaned) > 2:
            cleaned_requests.append(cleaned)
    
    return cleaned_requests if len(cleaned_requests) > 1 else [request_text]

# üîß ScheduleOptimizerBot ÌÅ¥ÎûòÏä§ (Í∏∞Ï°¥Í≥º ÎèôÏùºÌïòÏßÄÎßå import Ïò§Î•ò ÏàòÏ†ï)
class ScheduleOptimizerBot:
    """ÏùºÏ†ï ÏµúÏ†ÅÌôîÎ•º ÏúÑÌïú AI Î¥á ÌÅ¥ÎûòÏä§"""
    
    def __init__(self):
        # ChatBot ÌÅ¥ÎûòÏä§Í∞Ä Ï†ïÏùòÎêòÏñ¥ ÏûàÎã§Í≥† Í∞ÄÏ†ï
        try:
            self.chatbots = {
                'gpt': ChatBot(OPENAI_API_KEY, 'gpt-3.5-turbo', 'openai'),
                'claude': ChatBot(ANTHROPIC_API_KEY, 'claude-3-5-haiku-20241022', 'anthropic'), 
                'mixtral': ChatBot(GROQ_API_KEY, 'llama3-8b-8192', 'groq'),
            }
        except NameError:
            # ChatBot ÌÅ¥ÎûòÏä§Í∞Ä ÏóÜÏúºÎ©¥ ÎçîÎØ∏ ÌÅ¥ÎûòÏä§ ÏÇ¨Ïö©
            logger.warning("ChatBot ÌÅ¥ÎûòÏä§Î•º Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§. ÎçîÎØ∏ ÌÅ¥ÎûòÏä§Î•º ÏÇ¨Ïö©Ìï©ÎãàÎã§.")
            self.chatbots = {
                'gpt': DummyChatBot(),
                'claude': DummyChatBot(),
                'mixtral': DummyChatBot(),
            }
    
    def get_ai_suggestions(self, prompt, suggestion_type="schedule"):
        """Ïó¨Îü¨ AI Î™®Îç∏Î°úÎ∂ÄÌÑ∞ Ï†úÏïàÎ∞õÍ∏∞"""
        suggestions = {}
        
        for model_name, chatbot in self.chatbots.items():
            try:
                if hasattr(chatbot, 'chat'):
                    response = chatbot.chat(prompt)
                else:
                    response = f"ÎçîÎØ∏ ÏùëÎãµ: {model_name}ÏóêÏÑú {suggestion_type} Î∂ÑÏÑù ÏôÑÎ£å"
                suggestions[f"{model_name}_suggestion"] = response
            except Exception as e:
                suggestions[f"{model_name}_suggestion"] = f"Ïò§Î•ò Î∞úÏÉù: {str(e)}"
        
        return suggestions
    
    def analyze_and_optimize_suggestions(self, suggestions, query, selected_models=['GPT', 'Claude', 'Mixtral']):
        """Ïó¨Îü¨ AI Ï†úÏïàÏùÑ Î∂ÑÏÑùÌïòÏó¨ ÏµúÏ†ÅÌôîÎêú Í≤∞Í≥º ÏÉùÏÑ±"""
        try:
            # Í∏∞Î≥∏ Ï†úÏïà ÏÉùÏÑ±
            optimized = self._extract_first_valid_suggestion(suggestions)
            confidence = 0.85
            
            return {
                "optimized_suggestion": optimized,
                "confidence_score": confidence,
                "ai_analysis": {
                    "analysis_summary": "AI Î™®Îç∏Îì§Ïùò Ï†úÏïàÏùÑ Ï¢ÖÌï© Î∂ÑÏÑùÌñàÏäµÎãàÎã§.",
                    "reasoning": "Ïó¨Îü¨ Î™®Îç∏Ïùò Í≥µÌÜµÏ†êÏùÑ Î∞îÌÉïÏúºÎ°ú ÏµúÏ†ÅÌôîÌñàÏäµÎãàÎã§.",
                    "models_used": selected_models
                },
                "individual_suggestions": self._parse_individual_suggestions(suggestions)
            }
            
        except Exception as e:
            logger.error(f"Analysis error: {str(e)}")
            return {"error": f"ÏµúÏ†ÅÌôî Í≥ºÏ†ïÏóêÏÑú Ïò§Î•ò Î∞úÏÉù: {str(e)}"}
    
    def _extract_first_valid_suggestion(self, suggestions):
        """Ï≤´ Î≤àÏß∏ Ïú†Ìö®Ìïú Ï†úÏïà Ï∂îÏ∂ú"""
        for key, suggestion in suggestions.items():
            try:
                json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except:
                continue
        
        return {
            "title": "ÏÉà ÏùºÏ†ï",
            "description": "AIÍ∞Ä Ï†úÏïàÌïú ÏùºÏ†ïÏûÖÎãàÎã§",
            "suggested_date": "{target_datetime.strftime('%Y-%m-%d')}",
            "suggested_start_time": "09:00",
            "suggested_end_time": "10:00",
            "location": "",
            "priority": "MEDIUM",
            "attendees": [],
            "reasoning": "Ïó¨Îü¨ AI Î™®Îç∏Ïùò Ï†úÏïàÏùÑ Ï¢ÖÌï©Ìïú Í≤∞Í≥ºÏûÖÎãàÎã§."
        }
    
    def _parse_individual_suggestions(self, suggestions):
        """Í∞úÎ≥Ñ Ï†úÏïàÎì§ÏùÑ ÌååÏã±"""
        parsed = []
        for key, suggestion in suggestions.items():
            try:
                json_match = re.search(r'\{.*\}', suggestion, re.DOTALL)
                if json_match:
                    parsed_suggestion = json.loads(json_match.group())
                    parsed_suggestion['source'] = key.replace('_suggestion', '')
                    parsed.append(parsed_suggestion)
            except:
                continue
        return parsed
