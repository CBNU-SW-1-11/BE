# chat/db_builder.py - ì°¸ê³  ëª¨ë¸ í†µí•©ëœ ê°œì„  ë²„ì „
import os
import json
import unicodedata
from datetime import datetime
from typing import List, Dict, Any
import torch
from tqdm import tqdm
from dotenv import load_dotenv
from django.conf import settings

# LangChain ê´€ë ¨ import
try:
    from langchain_community.document_loaders import JSONLoader
    from langchain_community.vectorstores import FAISS
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain.schema import Document
    from langchain.retrievers import EnsembleRetriever
    from langchain_community.retrievers import BM25Retriever
    from langchain_openai import ChatOpenAI
    LANGCHAIN_AVAILABLE = True
except ImportError:
    print("âš ï¸ LangChain ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ - RAG ê¸°ëŠ¥ ë¹„í™œì„±í™”")
    LANGCHAIN_AVAILABLE = False

# Transformers ê´€ë ¨ import (ì°¸ê³  ëª¨ë¸ì—ì„œ ê°€ì ¸ì˜´)
try:
    from transformers import (
        AutoTokenizer,
        AutoModelForCausalLM,
        pipeline,
        BitsAndBytesConfig
    )
    from accelerate import Accelerator
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    print("âš ï¸ Transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜")
    TRANSFORMERS_AVAILABLE = False

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì°¸ê³  ëª¨ë¸ ê¸°ë°˜)
os.environ["CUDA_DEVICE_ORDER"] = "PCI_BUS_ID"
# .env íŒŒì¼ì„ ì°¾ì•„ í™˜ê²½ë³€ìˆ˜ë¡œ ë¡œë“œ

load_dotenv()  
# í•„ìˆ˜ í‚¤ í™•ì¸
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ GROQ_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
# ì„¤ì •ê°’ (ì°¸ê³  ëª¨ë¸ì—ì„œ ê°€ì ¸ì˜´)
CHUNK_SIZE = 256
CHUNK_OVERLAP = 128
EMBEDDING_MODEL = "intfloat/e5-large"
K = 3
LLM = "gemma2-9b-it"  # ê¸°ë³¸ ëª¨ë¸
QUANTIZATION = "bf16"  # "qlora", "bf16", "fp16"
MAX_NEW_TOKENS = 512

PROMPT_TEMPLATE = """
You are an AI visual assistant that can analyze video content and provide detailed insights.

Using the provided video analysis information, answer the user's question accurately.
Be careful not to answer with false information.

Context from video analysis:
{context}

Question: {question}

Answer:
"""

class EnhancedVideoRAGSystem:
    """ê°œì„ ëœ ë¹„ë””ì˜¤ ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•œ RAG ì‹œìŠ¤í…œ"""
    
    def __init__(self, use_gpu=False):
        self.use_gpu = use_gpu and torch.cuda.is_available()
        self.device = "cuda" if self.use_gpu else "cpu"
        
        # ì´ˆê¸°í™” ìƒíƒœ ì¶”ì 
        self._embeddings_initialized = False
        self._llm_initialized = False
        
        print(f"ğŸš€ Enhanced VideoRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë””ë°”ì´ìŠ¤: {self.device})")
        
        # LangChain ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        if not LANGCHAIN_AVAILABLE:
            print("âš ï¸ LangChain ë¯¸ì„¤ì¹˜ - ê¸°ë³¸ RAG ê¸°ëŠ¥ë§Œ ì‚¬ìš©")
            return
        
        try:
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            self._init_embeddings()
            # LLM ì´ˆê¸°í™”
            self._init_llm()
        except Exception as e:
            print(f"âš ï¸ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ë¶€ë¶„ ì‹¤íŒ¨: {e}")
        
        self.video_databases = {}
        print("âœ… Enhanced VideoRAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _init_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            model_kwargs = {"device": self.device}
            encode_kwargs = {'normalize_embeddings': True}
            
            self.embeddings = HuggingFaceEmbeddings(
                model_name=EMBEDDING_MODEL,
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs
            )
            self._embeddings_initialized = True
            print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {EMBEDDING_MODEL}")
        except Exception as e:
            print(f"âš ï¸ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._embeddings_initialized = False
    
    def _init_llm(self):
        """LLM ì´ˆê¸°í™” (ì°¸ê³  ëª¨ë¸ ë°©ì‹ ì ìš©)"""
        try:
            self.llm = ChatOpenAI(
                model=LLM,
                openai_api_key=os.environ["GROQ_API_KEY"],
                openai_api_base="https://api.groq.com/openai/v1",
                temperature=0.2,
                max_tokens=MAX_NEW_TOKENS
            )
            self._llm_initialized = True
            print(f"âœ… LLM ì´ˆê¸°í™” ì™„ë£Œ: {LLM}")
        except Exception as e:
            print(f"âš ï¸ LLM ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._llm_initialized = False
    
    def process_json(self, file_path, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):
        """JSON íŒŒì¼ ì²˜ë¦¬ (ì°¸ê³  ëª¨ë¸ ê¸°ë°˜)"""
        try:
            loader = JSONLoader(
                file_path=file_path,
                jq_schema=".frame_results.[].caption",  # ìˆ˜ì •ëœ ìŠ¤í‚¤ë§ˆ
                text_content=False,
            )
            docs = loader.load()
            chunks = docs.copy()
            return chunks
        except Exception as e:
            print(f"âš ï¸ JSON ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []
    
    def process_total_json(self, file_path, chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP):
        """ì „ì²´ JSONì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ ì²˜ë¦¬ (ì°¸ê³  ëª¨ë¸ ê¸°ë°˜)"""
        try:
            # ì§ì ‘ JSON íŒŒì¼ ì½ì–´ì„œ ì²˜ë¦¬
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # í”„ë ˆì„ ê²°ê³¼ì—ì„œ ìº¡ì…˜ ì¶”ì¶œ
            video_doc = ""
            frame_results = data.get('frame_results', [])
            
            for i, frame in enumerate(frame_results):
                caption = frame.get('caption', '') or frame.get('final_caption', '') or frame.get('enhanced_caption', '')
                if caption:
                    video_doc += f"Frame {i}: {caption}\n"
                
                # ê°ì²´ ì •ë³´ ì¶”ê°€
                objects = frame.get('objects', [])
                if objects:
                    object_names = [obj.get('class', '') for obj in objects]
                    video_doc += f"Objects in frame {i}: {', '.join(object_names)}\n"
            
            # ë©”íƒ€ë°ì´í„° ì„¤ì •
            meta_data = {
                'source': file_path,
                'video_id': data.get('metadata', {}).get('video_id', 'unknown'),
                'analysis_type': data.get('metadata', {}).get('analysis_type', 'unknown'),
                'total_frames': len(frame_results)
            }
            
            chunks = [Document(page_content=video_doc, metadata=meta_data)]
            return chunks
            
        except Exception as e:
            print(f"âš ï¸ ì „ì²´ JSON ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []
    
    def create_vector_db(self, chunks, model_path=EMBEDDING_MODEL):
        """FAISS ë²¡í„° DB ìƒì„± (ì°¸ê³  ëª¨ë¸ ê¸°ë°˜)"""
        if not self._embeddings_initialized or not chunks:
            print("âš ï¸ ì„ë² ë”© ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë¬¸ì„œê°€ ì—†ìŒ")
            return None
        
        try:
            db = FAISS.from_documents(chunks, embedding=self.embeddings)
            print(f"âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ: {len(chunks)}ê°œ ë¬¸ì„œ")
            return db
        except Exception as e:
            print(f"âš ï¸ ë²¡í„° DB ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def process_video_analysis_json(self, json_file_path: str, video_id: str):
        """ë¹„ë””ì˜¤ ë¶„ì„ JSONì„ ì²˜ë¦¬í•˜ì—¬ ë²¡í„° DB ìƒì„± (ê°œì„ ë¨)"""
        try:
            if not os.path.exists(json_file_path):
                print(f"âš ï¸ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {json_file_path}")
                return False
            
            print(f"ğŸ“„ JSON ë¶„ì„ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {json_file_path}")
            
            with open(json_file_path, 'r', encoding='utf-8') as f:
                analysis_data = json.load(f)
            
            documents = []
            
            # í”„ë ˆì„ë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ì„œë¡œ ë³€í™˜
            frame_results = analysis_data.get('frame_results', [])
            video_metadata = analysis_data.get('metadata', {})
            
            for frame_result in frame_results:
                frame_id = frame_result.get('image_id', 0)
                timestamp = frame_result.get('timestamp', 0)
                
                # ë‹¤ì–‘í•œ ìº¡ì…˜ ì†ŒìŠ¤ ì‹œë„
                caption = (frame_result.get('final_caption') or 
                          frame_result.get('enhanced_caption') or 
                          frame_result.get('caption') or '')
                
                objects = frame_result.get('objects', [])
                scene_analysis = frame_result.get('scene_analysis', {})
                
                # ë¬¸ì„œ ë‚´ìš© êµ¬ì„±
                content_parts = []
                
                if caption:
                    content_parts.append(f"Frame {frame_id} at {timestamp:.1f}s: {caption}")
                
                if objects:
                    object_list = [obj.get('class', '') for obj in objects if obj.get('class')]
                    if object_list:
                        content_parts.append(f"Objects detected: {', '.join(object_list)}")
                
                # Scene ë¶„ì„ ì •ë³´ ì¶”ê°€
                if scene_analysis:
                    scene_class = scene_analysis.get('scene_classification', {})
                    if scene_class:
                        location = scene_class.get('location', {}).get('label', '')
                        time_of_day = scene_class.get('time', {}).get('label', '')
                        if location or time_of_day:
                            content_parts.append(f"Scene: {location} {time_of_day}".strip())
                    
                    # OCR í…ìŠ¤íŠ¸ ì¶”ê°€
                    ocr_text = scene_analysis.get('ocr_text', '')
                    if ocr_text:
                        content_parts.append(f"Text found: {ocr_text}")
                
                # ëª¨ë“  ë‚´ìš© ê²°í•©
                content = '. '.join(content_parts)
                
                if content:  # ë¹ˆ ë‚´ìš©ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì¶”ê°€
                    metadata = {
                        'video_id': video_id,
                        'frame_id': frame_id,
                        'timestamp': timestamp,
                        'objects': [obj.get('class', '') for obj in objects],
                        'analysis_type': video_metadata.get('analysis_type', 'unknown')
                    }
                    
                    documents.append(Document(page_content=content, metadata=metadata))
            
            # ë²¡í„° DB ìƒì„±
            if documents:
                db = self.create_vector_db(documents)
                if not db:
                    return False
                
                # Retriever ì„¤ì • (ì°¸ê³  ëª¨ë¸ ë°©ì‹)
                retriever_similarity = db.as_retriever(
                    search_type="similarity",
                    search_kwargs={'k': K}
                )
                
                retriever_mmr = db.as_retriever(
                    search_type="mmr",
                    search_kwargs={'k': K}
                )
                
                try:
                    retriever_bm25 = BM25Retriever.from_documents(documents)
                    retriever_bm25.k = K
                    
                    ensemble_retriever = EnsembleRetriever(
                        retrievers=[retriever_similarity, retriever_mmr, retriever_bm25],
                        weights=[0.5, 0.3, 0.2]
                    )
                except Exception as e:
                    print(f"âš ï¸ BM25 retriever ìƒì„± ì‹¤íŒ¨, similarityë§Œ ì‚¬ìš©: {e}")
                    ensemble_retriever = retriever_similarity
                
                self.video_databases[video_id] = {
                    'db': db,
                    'retriever': ensemble_retriever,
                    'documents': documents,
                    'created_at': datetime.now(),
                    'json_path': json_file_path
                }
                
                print(f"âœ… ë¹„ë””ì˜¤ {video_id} RAG DB ìƒì„± ì™„ë£Œ: {len(documents)}ê°œ ë¬¸ì„œ")
                return True
            else:
                print(f"âš ï¸ ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŒ: {json_file_path}")
                return False
            
        except Exception as e:
            print(f"âŒ RAG DB ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            print(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")
            return False
    
    def search_video_content(self, video_id: str, query: str, top_k: int = 5):
        """ë¹„ë””ì˜¤ ë‚´ìš© ê²€ìƒ‰ (ê°œì„ ë¨)"""
        if video_id not in self.video_databases:
            print(f"âš ï¸ ë¹„ë””ì˜¤ {video_id}ì˜ RAG DBê°€ ì—†ìŒ")
            return []
        
        try:
            retriever = self.video_databases[video_id]['retriever']
            documents = retriever.get_relevant_documents(query)
            
            results = []
            for doc in documents[:top_k]:
                results.append({
                    'content': doc.page_content,
                    'metadata': doc.metadata,
                    'frame_id': doc.metadata.get('frame_id'),
                    'timestamp': doc.metadata.get('timestamp'),
                    'objects': doc.metadata.get('objects', [])
                })
            
            print(f"ğŸ” ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return results
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def answer_question(self, video_id: str, question: str):
        """ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (ê°œì„ ë¨)"""
        if not self._llm_initialized:
            return "LLMì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.search_video_content(video_id, question)
        
        if not search_results:
            return "ê´€ë ¨ëœ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì°¸ê³  ëª¨ë¸ ë°©ì‹)
        context = self.format_docs_for_prompt(search_results)
        
        # LLMì— ì§ˆë¬¸
        try:
            prompt = PROMPT_TEMPLATE.format(context=context, question=question)
            response = self.llm.invoke(prompt)
            return response.content
        except Exception as e:
            print(f"âŒ LLM ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def format_docs_for_prompt(self, search_results):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ í¬ë§· (ì°¸ê³  ëª¨ë¸ ë°©ì‹)"""
        context = ""
        for i, result in enumerate(search_results):
            frame_id = result['metadata'].get('frame_id', i)
            context += f"Frame {frame_id}: {result['content']}\n"
        return context
    
    def get_database_info(self, video_id: str = None):
        """ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ ì¡°íšŒ"""
        if video_id:
            if video_id in self.video_databases:
                db_info = self.video_databases[video_id]
                return {
                    'video_id': video_id,
                    'document_count': len(db_info['documents']),
                    'created_at': db_info['created_at'].isoformat(),
                    'json_path': db_info.get('json_path', 'unknown')
                }
            else:
                return None
        else:
            return {
                'total_videos': len(self.video_databases),
                'videos': list(self.video_databases.keys()),
                'embeddings_initialized': self._embeddings_initialized,
                'llm_initialized': self._llm_initialized
            }

# ì „ì—­ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ (ê°œì„ ë¨)
_global_rag_system = None

def get_video_rag_system():
    """ì „ì—­ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)"""
    global _global_rag_system
    if _global_rag_system is None:
        _global_rag_system = EnhancedVideoRAGSystem()
    return _global_rag_system

# í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ ë³€ìˆ˜ëª… ìœ ì§€
rag_system = get_video_rag_system()